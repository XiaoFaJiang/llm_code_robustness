{
  "best_metric": 1.453911542892456,
  "best_model_checkpoint": "Qwen2.5-Coder-0.5B-Base-LoRA/checkpoint-345",
  "epoch": 0.9985528219971056,
  "eval_steps": 500,
  "global_step": 345,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02894356005788712,
      "grad_norm": 2.127077102661133,
      "learning_rate": 2.884615384615385e-06,
      "loss": 1.9675,
      "step": 10
    },
    {
      "epoch": 0.05788712011577424,
      "grad_norm": 1.707234263420105,
      "learning_rate": 5.76923076923077e-06,
      "loss": 1.9837,
      "step": 20
    },
    {
      "epoch": 0.08683068017366136,
      "grad_norm": 1.068422794342041,
      "learning_rate": 8.653846153846153e-06,
      "loss": 1.8863,
      "step": 30
    },
    {
      "epoch": 0.11577424023154848,
      "grad_norm": 0.8923444747924805,
      "learning_rate": 1.153846153846154e-05,
      "loss": 1.9032,
      "step": 40
    },
    {
      "epoch": 0.1447178002894356,
      "grad_norm": 1.016704797744751,
      "learning_rate": 1.4423076923076924e-05,
      "loss": 1.9468,
      "step": 50
    },
    {
      "epoch": 0.1736613603473227,
      "grad_norm": 1.04364013671875,
      "learning_rate": 1.7307692307692306e-05,
      "loss": 1.8366,
      "step": 60
    },
    {
      "epoch": 0.20260492040520983,
      "grad_norm": 1.0295987129211426,
      "learning_rate": 2.0192307692307694e-05,
      "loss": 1.8603,
      "step": 70
    },
    {
      "epoch": 0.23154848046309695,
      "grad_norm": 0.8739840984344482,
      "learning_rate": 2.307692307692308e-05,
      "loss": 1.785,
      "step": 80
    },
    {
      "epoch": 0.26049204052098407,
      "grad_norm": 1.1171271800994873,
      "learning_rate": 2.5961538461538464e-05,
      "loss": 1.7933,
      "step": 90
    },
    {
      "epoch": 0.2894356005788712,
      "grad_norm": 1.116249918937683,
      "learning_rate": 2.884615384615385e-05,
      "loss": 1.7085,
      "step": 100
    },
    {
      "epoch": 0.3183791606367583,
      "grad_norm": 1.3315318822860718,
      "learning_rate": 2.9806659505907628e-05,
      "loss": 1.6736,
      "step": 110
    },
    {
      "epoch": 0.3473227206946454,
      "grad_norm": 1.12432062625885,
      "learning_rate": 2.9484425349087004e-05,
      "loss": 1.5022,
      "step": 120
    },
    {
      "epoch": 0.37626628075253254,
      "grad_norm": 1.751835823059082,
      "learning_rate": 2.916219119226638e-05,
      "loss": 1.4388,
      "step": 130
    },
    {
      "epoch": 0.40520984081041966,
      "grad_norm": 1.6557334661483765,
      "learning_rate": 2.8839957035445758e-05,
      "loss": 1.3151,
      "step": 140
    },
    {
      "epoch": 0.4341534008683068,
      "grad_norm": 1.888097882270813,
      "learning_rate": 2.8517722878625138e-05,
      "loss": 1.177,
      "step": 150
    },
    {
      "epoch": 0.4630969609261939,
      "grad_norm": 2.5296783447265625,
      "learning_rate": 2.819548872180451e-05,
      "loss": 1.063,
      "step": 160
    },
    {
      "epoch": 0.492040520984081,
      "grad_norm": 2.6248340606689453,
      "learning_rate": 2.787325456498389e-05,
      "loss": 0.9759,
      "step": 170
    },
    {
      "epoch": 0.5209840810419681,
      "grad_norm": 1.8467233180999756,
      "learning_rate": 2.7551020408163265e-05,
      "loss": 0.8254,
      "step": 180
    },
    {
      "epoch": 0.5499276410998553,
      "grad_norm": 1.4639699459075928,
      "learning_rate": 2.7228786251342642e-05,
      "loss": 0.7578,
      "step": 190
    },
    {
      "epoch": 0.5788712011577424,
      "grad_norm": 1.5573999881744385,
      "learning_rate": 2.6906552094522022e-05,
      "loss": 0.6757,
      "step": 200
    },
    {
      "epoch": 0.6078147612156295,
      "grad_norm": 1.5100064277648926,
      "learning_rate": 2.6584317937701396e-05,
      "loss": 0.6228,
      "step": 210
    },
    {
      "epoch": 0.6367583212735166,
      "grad_norm": 1.237736463546753,
      "learning_rate": 2.6262083780880776e-05,
      "loss": 0.578,
      "step": 220
    },
    {
      "epoch": 0.6657018813314037,
      "grad_norm": 0.9052610993385315,
      "learning_rate": 2.5939849624060153e-05,
      "loss": 0.5602,
      "step": 230
    },
    {
      "epoch": 0.6946454413892909,
      "grad_norm": 1.2922555208206177,
      "learning_rate": 2.5617615467239526e-05,
      "loss": 0.5347,
      "step": 240
    },
    {
      "epoch": 0.723589001447178,
      "grad_norm": 1.2612029314041138,
      "learning_rate": 2.5295381310418906e-05,
      "loss": 0.5346,
      "step": 250
    },
    {
      "epoch": 0.7525325615050651,
      "grad_norm": 1.3418116569519043,
      "learning_rate": 2.497314715359828e-05,
      "loss": 0.5117,
      "step": 260
    },
    {
      "epoch": 0.7814761215629522,
      "grad_norm": 1.2748079299926758,
      "learning_rate": 2.465091299677766e-05,
      "loss": 0.4901,
      "step": 270
    },
    {
      "epoch": 0.8104196816208393,
      "grad_norm": 1.1530855894088745,
      "learning_rate": 2.4328678839957037e-05,
      "loss": 0.4605,
      "step": 280
    },
    {
      "epoch": 0.8393632416787264,
      "grad_norm": 0.9379908442497253,
      "learning_rate": 2.400644468313641e-05,
      "loss": 0.4539,
      "step": 290
    },
    {
      "epoch": 0.8683068017366136,
      "grad_norm": 1.9313615560531616,
      "learning_rate": 2.368421052631579e-05,
      "loss": 0.4428,
      "step": 300
    },
    {
      "epoch": 0.8972503617945007,
      "grad_norm": 1.0264146327972412,
      "learning_rate": 2.3361976369495167e-05,
      "loss": 0.4493,
      "step": 310
    },
    {
      "epoch": 0.9261939218523878,
      "grad_norm": 1.6639984846115112,
      "learning_rate": 2.3039742212674544e-05,
      "loss": 0.4728,
      "step": 320
    },
    {
      "epoch": 0.9551374819102749,
      "grad_norm": 1.6793044805526733,
      "learning_rate": 2.271750805585392e-05,
      "loss": 0.4664,
      "step": 330
    },
    {
      "epoch": 0.984081041968162,
      "grad_norm": 1.0564371347427368,
      "learning_rate": 2.23952738990333e-05,
      "loss": 0.4242,
      "step": 340
    },
    {
      "epoch": 0.9985528219971056,
      "eval_loss": 1.453911542892456,
      "eval_runtime": 42.3399,
      "eval_samples_per_second": 16.344,
      "eval_steps_per_second": 8.172,
      "step": 345
    }
  ],
  "logging_steps": 10,
  "max_steps": 1035,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3043506582454272.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
