{
  "best_metric": 0.2997841238975525,
  "best_model_checkpoint": "Qwen2.5-Coder-3B-Instruct-LoRA/checkpoint-4146",
  "epoch": 2.9989150090415913,
  "eval_steps": 500,
  "global_step": 4146,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007233273056057866,
      "grad_norm": 0.5901459455490112,
      "learning_rate": 1.2048192771084338e-06,
      "loss": 2.19,
      "step": 10
    },
    {
      "epoch": 0.014466546112115732,
      "grad_norm": 0.5531205534934998,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 2.2581,
      "step": 20
    },
    {
      "epoch": 0.0216998191681736,
      "grad_norm": 0.48592814803123474,
      "learning_rate": 3.614457831325301e-06,
      "loss": 2.1487,
      "step": 30
    },
    {
      "epoch": 0.028933092224231464,
      "grad_norm": 0.6599830985069275,
      "learning_rate": 4.819277108433735e-06,
      "loss": 2.0809,
      "step": 40
    },
    {
      "epoch": 0.03616636528028933,
      "grad_norm": 0.5595484375953674,
      "learning_rate": 6.024096385542169e-06,
      "loss": 2.2179,
      "step": 50
    },
    {
      "epoch": 0.0433996383363472,
      "grad_norm": 0.5711933970451355,
      "learning_rate": 7.228915662650602e-06,
      "loss": 2.1127,
      "step": 60
    },
    {
      "epoch": 0.05063291139240506,
      "grad_norm": 0.7601075768470764,
      "learning_rate": 8.433734939759036e-06,
      "loss": 2.2491,
      "step": 70
    },
    {
      "epoch": 0.05786618444846293,
      "grad_norm": 0.5183493494987488,
      "learning_rate": 9.63855421686747e-06,
      "loss": 2.0244,
      "step": 80
    },
    {
      "epoch": 0.0650994575045208,
      "grad_norm": 0.6419873833656311,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 2.1215,
      "step": 90
    },
    {
      "epoch": 0.07233273056057866,
      "grad_norm": 0.49745818972587585,
      "learning_rate": 1.2048192771084338e-05,
      "loss": 2.0331,
      "step": 100
    },
    {
      "epoch": 0.07956600361663653,
      "grad_norm": 0.7038047313690186,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 2.0566,
      "step": 110
    },
    {
      "epoch": 0.0867992766726944,
      "grad_norm": 0.6136660575866699,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 2.0975,
      "step": 120
    },
    {
      "epoch": 0.09403254972875226,
      "grad_norm": 0.8220535516738892,
      "learning_rate": 1.566265060240964e-05,
      "loss": 2.1939,
      "step": 130
    },
    {
      "epoch": 0.10126582278481013,
      "grad_norm": 0.786357581615448,
      "learning_rate": 1.6867469879518073e-05,
      "loss": 2.0433,
      "step": 140
    },
    {
      "epoch": 0.10849909584086799,
      "grad_norm": 0.6458688974380493,
      "learning_rate": 1.8072289156626505e-05,
      "loss": 1.9406,
      "step": 150
    },
    {
      "epoch": 0.11573236889692586,
      "grad_norm": 0.5218580365180969,
      "learning_rate": 1.927710843373494e-05,
      "loss": 1.8983,
      "step": 160
    },
    {
      "epoch": 0.12296564195298372,
      "grad_norm": 0.6079786419868469,
      "learning_rate": 2.0481927710843373e-05,
      "loss": 2.0573,
      "step": 170
    },
    {
      "epoch": 0.1301989150090416,
      "grad_norm": 0.6224334239959717,
      "learning_rate": 2.168674698795181e-05,
      "loss": 1.9815,
      "step": 180
    },
    {
      "epoch": 0.13743218806509946,
      "grad_norm": 0.6713703870773315,
      "learning_rate": 2.289156626506024e-05,
      "loss": 1.8845,
      "step": 190
    },
    {
      "epoch": 0.14466546112115733,
      "grad_norm": 0.6611809134483337,
      "learning_rate": 2.4096385542168677e-05,
      "loss": 1.8319,
      "step": 200
    },
    {
      "epoch": 0.1518987341772152,
      "grad_norm": 0.6143491268157959,
      "learning_rate": 2.530120481927711e-05,
      "loss": 1.7463,
      "step": 210
    },
    {
      "epoch": 0.15913200723327306,
      "grad_norm": 0.6891828775405884,
      "learning_rate": 2.6506024096385545e-05,
      "loss": 1.7466,
      "step": 220
    },
    {
      "epoch": 0.16636528028933092,
      "grad_norm": 0.7480840086936951,
      "learning_rate": 2.7710843373493977e-05,
      "loss": 1.6338,
      "step": 230
    },
    {
      "epoch": 0.1735985533453888,
      "grad_norm": 0.8205583691596985,
      "learning_rate": 2.891566265060241e-05,
      "loss": 1.6812,
      "step": 240
    },
    {
      "epoch": 0.18083182640144665,
      "grad_norm": 0.8686198592185974,
      "learning_rate": 3.012048192771085e-05,
      "loss": 1.5308,
      "step": 250
    },
    {
      "epoch": 0.18806509945750452,
      "grad_norm": 1.6493332386016846,
      "learning_rate": 3.132530120481928e-05,
      "loss": 1.4801,
      "step": 260
    },
    {
      "epoch": 0.19529837251356238,
      "grad_norm": 1.2606158256530762,
      "learning_rate": 3.253012048192771e-05,
      "loss": 1.3222,
      "step": 270
    },
    {
      "epoch": 0.20253164556962025,
      "grad_norm": 1.436091661453247,
      "learning_rate": 3.3734939759036146e-05,
      "loss": 1.2451,
      "step": 280
    },
    {
      "epoch": 0.20976491862567812,
      "grad_norm": 1.4834010601043701,
      "learning_rate": 3.4939759036144585e-05,
      "loss": 1.1456,
      "step": 290
    },
    {
      "epoch": 0.21699819168173598,
      "grad_norm": 1.5796926021575928,
      "learning_rate": 3.614457831325301e-05,
      "loss": 0.9682,
      "step": 300
    },
    {
      "epoch": 0.22423146473779385,
      "grad_norm": 1.5376356840133667,
      "learning_rate": 3.734939759036144e-05,
      "loss": 0.8493,
      "step": 310
    },
    {
      "epoch": 0.2314647377938517,
      "grad_norm": 1.5276895761489868,
      "learning_rate": 3.855421686746988e-05,
      "loss": 0.7431,
      "step": 320
    },
    {
      "epoch": 0.23869801084990958,
      "grad_norm": 1.4039896726608276,
      "learning_rate": 3.9759036144578314e-05,
      "loss": 0.6427,
      "step": 330
    },
    {
      "epoch": 0.24593128390596744,
      "grad_norm": 1.3087407350540161,
      "learning_rate": 4.0963855421686746e-05,
      "loss": 0.5728,
      "step": 340
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.9216644763946533,
      "learning_rate": 4.2168674698795186e-05,
      "loss": 0.5289,
      "step": 350
    },
    {
      "epoch": 0.2603978300180832,
      "grad_norm": 0.7393828630447388,
      "learning_rate": 4.337349397590362e-05,
      "loss": 0.443,
      "step": 360
    },
    {
      "epoch": 0.26763110307414106,
      "grad_norm": 0.872428297996521,
      "learning_rate": 4.457831325301205e-05,
      "loss": 0.448,
      "step": 370
    },
    {
      "epoch": 0.27486437613019893,
      "grad_norm": 1.251500129699707,
      "learning_rate": 4.578313253012048e-05,
      "loss": 0.4085,
      "step": 380
    },
    {
      "epoch": 0.2820976491862568,
      "grad_norm": 1.0534710884094238,
      "learning_rate": 4.698795180722892e-05,
      "loss": 0.4456,
      "step": 390
    },
    {
      "epoch": 0.28933092224231466,
      "grad_norm": 0.6357982754707336,
      "learning_rate": 4.8192771084337354e-05,
      "loss": 0.3917,
      "step": 400
    },
    {
      "epoch": 0.2965641952983725,
      "grad_norm": 0.8440976142883301,
      "learning_rate": 4.9397590361445786e-05,
      "loss": 0.3548,
      "step": 410
    },
    {
      "epoch": 0.3037974683544304,
      "grad_norm": 1.0609335899353027,
      "learning_rate": 4.9932993835432864e-05,
      "loss": 0.3207,
      "step": 420
    },
    {
      "epoch": 0.31103074141048825,
      "grad_norm": 0.8679623603820801,
      "learning_rate": 4.979898150629858e-05,
      "loss": 0.4,
      "step": 430
    },
    {
      "epoch": 0.3182640144665461,
      "grad_norm": 1.356958031654358,
      "learning_rate": 4.96649691771643e-05,
      "loss": 0.3462,
      "step": 440
    },
    {
      "epoch": 0.325497287522604,
      "grad_norm": 0.4236278235912323,
      "learning_rate": 4.953095684803002e-05,
      "loss": 0.2993,
      "step": 450
    },
    {
      "epoch": 0.33273056057866185,
      "grad_norm": 0.5929592847824097,
      "learning_rate": 4.939694451889574e-05,
      "loss": 0.3176,
      "step": 460
    },
    {
      "epoch": 0.3399638336347197,
      "grad_norm": 0.9627223610877991,
      "learning_rate": 4.926293218976146e-05,
      "loss": 0.3143,
      "step": 470
    },
    {
      "epoch": 0.3471971066907776,
      "grad_norm": 1.0027235746383667,
      "learning_rate": 4.9128919860627184e-05,
      "loss": 0.3373,
      "step": 480
    },
    {
      "epoch": 0.35443037974683544,
      "grad_norm": 0.8163465261459351,
      "learning_rate": 4.89949075314929e-05,
      "loss": 0.3102,
      "step": 490
    },
    {
      "epoch": 0.3616636528028933,
      "grad_norm": 1.1608428955078125,
      "learning_rate": 4.886089520235862e-05,
      "loss": 0.2882,
      "step": 500
    },
    {
      "epoch": 0.3688969258589512,
      "grad_norm": 1.0043399333953857,
      "learning_rate": 4.872688287322434e-05,
      "loss": 0.2855,
      "step": 510
    },
    {
      "epoch": 0.37613019891500904,
      "grad_norm": 1.0401219129562378,
      "learning_rate": 4.859287054409006e-05,
      "loss": 0.2991,
      "step": 520
    },
    {
      "epoch": 0.3833634719710669,
      "grad_norm": 0.745921790599823,
      "learning_rate": 4.8458858214955776e-05,
      "loss": 0.2985,
      "step": 530
    },
    {
      "epoch": 0.39059674502712477,
      "grad_norm": 0.593451201915741,
      "learning_rate": 4.83248458858215e-05,
      "loss": 0.2638,
      "step": 540
    },
    {
      "epoch": 0.39783001808318263,
      "grad_norm": 0.5664033889770508,
      "learning_rate": 4.8190833556687214e-05,
      "loss": 0.3259,
      "step": 550
    },
    {
      "epoch": 0.4050632911392405,
      "grad_norm": 0.9045276641845703,
      "learning_rate": 4.805682122755294e-05,
      "loss": 0.3288,
      "step": 560
    },
    {
      "epoch": 0.41229656419529837,
      "grad_norm": 0.8219788670539856,
      "learning_rate": 4.792280889841866e-05,
      "loss": 0.3262,
      "step": 570
    },
    {
      "epoch": 0.41952983725135623,
      "grad_norm": 0.7807558178901672,
      "learning_rate": 4.778879656928438e-05,
      "loss": 0.296,
      "step": 580
    },
    {
      "epoch": 0.4267631103074141,
      "grad_norm": 0.5952144265174866,
      "learning_rate": 4.7654784240150096e-05,
      "loss": 0.3489,
      "step": 590
    },
    {
      "epoch": 0.43399638336347196,
      "grad_norm": 0.6349114775657654,
      "learning_rate": 4.752077191101582e-05,
      "loss": 0.3197,
      "step": 600
    },
    {
      "epoch": 0.4412296564195298,
      "grad_norm": 0.46354496479034424,
      "learning_rate": 4.7386759581881534e-05,
      "loss": 0.2882,
      "step": 610
    },
    {
      "epoch": 0.4484629294755877,
      "grad_norm": 0.6898710131645203,
      "learning_rate": 4.7252747252747257e-05,
      "loss": 0.3202,
      "step": 620
    },
    {
      "epoch": 0.45569620253164556,
      "grad_norm": 1.5015149116516113,
      "learning_rate": 4.711873492361297e-05,
      "loss": 0.3152,
      "step": 630
    },
    {
      "epoch": 0.4629294755877034,
      "grad_norm": 0.47272372245788574,
      "learning_rate": 4.6984722594478694e-05,
      "loss": 0.3121,
      "step": 640
    },
    {
      "epoch": 0.4701627486437613,
      "grad_norm": 0.8065205216407776,
      "learning_rate": 4.685071026534442e-05,
      "loss": 0.2737,
      "step": 650
    },
    {
      "epoch": 0.47739602169981915,
      "grad_norm": 0.6544362902641296,
      "learning_rate": 4.671669793621013e-05,
      "loss": 0.2985,
      "step": 660
    },
    {
      "epoch": 0.484629294755877,
      "grad_norm": 0.9288249015808105,
      "learning_rate": 4.6582685607075855e-05,
      "loss": 0.345,
      "step": 670
    },
    {
      "epoch": 0.4918625678119349,
      "grad_norm": 0.5485353469848633,
      "learning_rate": 4.644867327794157e-05,
      "loss": 0.267,
      "step": 680
    },
    {
      "epoch": 0.49909584086799275,
      "grad_norm": 0.6486672163009644,
      "learning_rate": 4.631466094880729e-05,
      "loss": 0.2638,
      "step": 690
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.7404216527938843,
      "learning_rate": 4.618064861967301e-05,
      "loss": 0.3207,
      "step": 700
    },
    {
      "epoch": 0.5135623869801085,
      "grad_norm": 0.8434975743293762,
      "learning_rate": 4.604663629053873e-05,
      "loss": 0.2683,
      "step": 710
    },
    {
      "epoch": 0.5207956600361664,
      "grad_norm": 0.8411067128181458,
      "learning_rate": 4.5912623961404446e-05,
      "loss": 0.2685,
      "step": 720
    },
    {
      "epoch": 0.5280289330922242,
      "grad_norm": 0.8591102361679077,
      "learning_rate": 4.577861163227017e-05,
      "loss": 0.3317,
      "step": 730
    },
    {
      "epoch": 0.5352622061482821,
      "grad_norm": 0.6661418080329895,
      "learning_rate": 4.564459930313589e-05,
      "loss": 0.2823,
      "step": 740
    },
    {
      "epoch": 0.5424954792043399,
      "grad_norm": 0.5697456002235413,
      "learning_rate": 4.551058697400161e-05,
      "loss": 0.3187,
      "step": 750
    },
    {
      "epoch": 0.5497287522603979,
      "grad_norm": 0.5610387921333313,
      "learning_rate": 4.537657464486733e-05,
      "loss": 0.3065,
      "step": 760
    },
    {
      "epoch": 0.5569620253164557,
      "grad_norm": 0.5743966102600098,
      "learning_rate": 4.524256231573305e-05,
      "loss": 0.3067,
      "step": 770
    },
    {
      "epoch": 0.5641952983725136,
      "grad_norm": 0.4823736548423767,
      "learning_rate": 4.510854998659877e-05,
      "loss": 0.2707,
      "step": 780
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.6308720111846924,
      "learning_rate": 4.497453765746449e-05,
      "loss": 0.3082,
      "step": 790
    },
    {
      "epoch": 0.5786618444846293,
      "grad_norm": 0.8201319575309753,
      "learning_rate": 4.4840525328330205e-05,
      "loss": 0.2862,
      "step": 800
    },
    {
      "epoch": 0.5858951175406871,
      "grad_norm": 0.7710482478141785,
      "learning_rate": 4.470651299919593e-05,
      "loss": 0.2692,
      "step": 810
    },
    {
      "epoch": 0.593128390596745,
      "grad_norm": 1.2001391649246216,
      "learning_rate": 4.457250067006164e-05,
      "loss": 0.2534,
      "step": 820
    },
    {
      "epoch": 0.6003616636528029,
      "grad_norm": 0.8195534944534302,
      "learning_rate": 4.443848834092737e-05,
      "loss": 0.2875,
      "step": 830
    },
    {
      "epoch": 0.6075949367088608,
      "grad_norm": 0.668710470199585,
      "learning_rate": 4.430447601179309e-05,
      "loss": 0.3033,
      "step": 840
    },
    {
      "epoch": 0.6148282097649186,
      "grad_norm": 0.7759791612625122,
      "learning_rate": 4.417046368265881e-05,
      "loss": 0.3015,
      "step": 850
    },
    {
      "epoch": 0.6220614828209765,
      "grad_norm": 0.6774949431419373,
      "learning_rate": 4.4036451353524525e-05,
      "loss": 0.2794,
      "step": 860
    },
    {
      "epoch": 0.6292947558770343,
      "grad_norm": 0.9423707723617554,
      "learning_rate": 4.390243902439025e-05,
      "loss": 0.2641,
      "step": 870
    },
    {
      "epoch": 0.6365280289330922,
      "grad_norm": 0.5444045662879944,
      "learning_rate": 4.376842669525596e-05,
      "loss": 0.2867,
      "step": 880
    },
    {
      "epoch": 0.64376130198915,
      "grad_norm": 0.9091641902923584,
      "learning_rate": 4.3634414366121686e-05,
      "loss": 0.2663,
      "step": 890
    },
    {
      "epoch": 0.650994575045208,
      "grad_norm": 0.8603604435920715,
      "learning_rate": 4.35004020369874e-05,
      "loss": 0.2808,
      "step": 900
    },
    {
      "epoch": 0.6582278481012658,
      "grad_norm": 0.8741558790206909,
      "learning_rate": 4.3366389707853124e-05,
      "loss": 0.3247,
      "step": 910
    },
    {
      "epoch": 0.6654611211573237,
      "grad_norm": 0.4904482960700989,
      "learning_rate": 4.3232377378718846e-05,
      "loss": 0.2966,
      "step": 920
    },
    {
      "epoch": 0.6726943942133815,
      "grad_norm": 0.5553473830223083,
      "learning_rate": 4.309836504958457e-05,
      "loss": 0.2676,
      "step": 930
    },
    {
      "epoch": 0.6799276672694394,
      "grad_norm": 0.8617216348648071,
      "learning_rate": 4.2964352720450284e-05,
      "loss": 0.2775,
      "step": 940
    },
    {
      "epoch": 0.6871609403254972,
      "grad_norm": 0.5488882064819336,
      "learning_rate": 4.2830340391316006e-05,
      "loss": 0.2762,
      "step": 950
    },
    {
      "epoch": 0.6943942133815552,
      "grad_norm": 1.2978962659835815,
      "learning_rate": 4.269632806218172e-05,
      "loss": 0.2788,
      "step": 960
    },
    {
      "epoch": 0.701627486437613,
      "grad_norm": 0.6175974011421204,
      "learning_rate": 4.2562315733047444e-05,
      "loss": 0.2662,
      "step": 970
    },
    {
      "epoch": 0.7088607594936709,
      "grad_norm": 2.1531264781951904,
      "learning_rate": 4.242830340391316e-05,
      "loss": 0.2825,
      "step": 980
    },
    {
      "epoch": 0.7160940325497287,
      "grad_norm": 0.7875903248786926,
      "learning_rate": 4.229429107477888e-05,
      "loss": 0.2783,
      "step": 990
    },
    {
      "epoch": 0.7233273056057866,
      "grad_norm": 0.6088120937347412,
      "learning_rate": 4.21602787456446e-05,
      "loss": 0.2944,
      "step": 1000
    },
    {
      "epoch": 0.7305605786618445,
      "grad_norm": 0.7337669730186462,
      "learning_rate": 4.202626641651033e-05,
      "loss": 0.2385,
      "step": 1010
    },
    {
      "epoch": 0.7377938517179023,
      "grad_norm": 1.2393418550491333,
      "learning_rate": 4.189225408737604e-05,
      "loss": 0.304,
      "step": 1020
    },
    {
      "epoch": 0.7450271247739603,
      "grad_norm": 0.7484510540962219,
      "learning_rate": 4.1758241758241765e-05,
      "loss": 0.2865,
      "step": 1030
    },
    {
      "epoch": 0.7522603978300181,
      "grad_norm": 0.9866767525672913,
      "learning_rate": 4.162422942910748e-05,
      "loss": 0.2827,
      "step": 1040
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.810454785823822,
      "learning_rate": 4.14902170999732e-05,
      "loss": 0.2408,
      "step": 1050
    },
    {
      "epoch": 0.7667269439421338,
      "grad_norm": 0.7513937950134277,
      "learning_rate": 4.135620477083892e-05,
      "loss": 0.2529,
      "step": 1060
    },
    {
      "epoch": 0.7739602169981917,
      "grad_norm": 0.6834530234336853,
      "learning_rate": 4.122219244170464e-05,
      "loss": 0.2903,
      "step": 1070
    },
    {
      "epoch": 0.7811934900542495,
      "grad_norm": 0.6923952102661133,
      "learning_rate": 4.1088180112570356e-05,
      "loss": 0.2949,
      "step": 1080
    },
    {
      "epoch": 0.7884267631103075,
      "grad_norm": 0.5737330913543701,
      "learning_rate": 4.095416778343608e-05,
      "loss": 0.2304,
      "step": 1090
    },
    {
      "epoch": 0.7956600361663653,
      "grad_norm": 1.1960347890853882,
      "learning_rate": 4.0820155454301794e-05,
      "loss": 0.3115,
      "step": 1100
    },
    {
      "epoch": 0.8028933092224232,
      "grad_norm": 0.6575151085853577,
      "learning_rate": 4.0686143125167516e-05,
      "loss": 0.24,
      "step": 1110
    },
    {
      "epoch": 0.810126582278481,
      "grad_norm": 0.7691327929496765,
      "learning_rate": 4.055213079603324e-05,
      "loss": 0.2505,
      "step": 1120
    },
    {
      "epoch": 0.8173598553345389,
      "grad_norm": 1.0454411506652832,
      "learning_rate": 4.0418118466898954e-05,
      "loss": 0.2816,
      "step": 1130
    },
    {
      "epoch": 0.8245931283905967,
      "grad_norm": 3.9474334716796875,
      "learning_rate": 4.028410613776468e-05,
      "loss": 0.2711,
      "step": 1140
    },
    {
      "epoch": 0.8318264014466547,
      "grad_norm": 0.6573302149772644,
      "learning_rate": 4.015009380863039e-05,
      "loss": 0.2976,
      "step": 1150
    },
    {
      "epoch": 0.8390596745027125,
      "grad_norm": 0.9770293831825256,
      "learning_rate": 4.0016081479496115e-05,
      "loss": 0.2702,
      "step": 1160
    },
    {
      "epoch": 0.8462929475587704,
      "grad_norm": 0.6508988738059998,
      "learning_rate": 3.988206915036184e-05,
      "loss": 0.2753,
      "step": 1170
    },
    {
      "epoch": 0.8535262206148282,
      "grad_norm": 0.7710347771644592,
      "learning_rate": 3.974805682122755e-05,
      "loss": 0.2839,
      "step": 1180
    },
    {
      "epoch": 0.8607594936708861,
      "grad_norm": 0.5797946453094482,
      "learning_rate": 3.9614044492093275e-05,
      "loss": 0.2702,
      "step": 1190
    },
    {
      "epoch": 0.8679927667269439,
      "grad_norm": 0.7088587880134583,
      "learning_rate": 3.9480032162959e-05,
      "loss": 0.2443,
      "step": 1200
    },
    {
      "epoch": 0.8752260397830018,
      "grad_norm": 0.6616466045379639,
      "learning_rate": 3.934601983382471e-05,
      "loss": 0.2871,
      "step": 1210
    },
    {
      "epoch": 0.8824593128390597,
      "grad_norm": 0.5884456634521484,
      "learning_rate": 3.9212007504690435e-05,
      "loss": 0.2887,
      "step": 1220
    },
    {
      "epoch": 0.8896925858951176,
      "grad_norm": 0.5147870779037476,
      "learning_rate": 3.907799517555615e-05,
      "loss": 0.2823,
      "step": 1230
    },
    {
      "epoch": 0.8969258589511754,
      "grad_norm": 0.6543043255805969,
      "learning_rate": 3.894398284642187e-05,
      "loss": 0.262,
      "step": 1240
    },
    {
      "epoch": 0.9041591320072333,
      "grad_norm": 0.6395958065986633,
      "learning_rate": 3.880997051728759e-05,
      "loss": 0.2787,
      "step": 1250
    },
    {
      "epoch": 0.9113924050632911,
      "grad_norm": 0.6997601389884949,
      "learning_rate": 3.867595818815331e-05,
      "loss": 0.2957,
      "step": 1260
    },
    {
      "epoch": 0.918625678119349,
      "grad_norm": 0.6878554821014404,
      "learning_rate": 3.854194585901903e-05,
      "loss": 0.2769,
      "step": 1270
    },
    {
      "epoch": 0.9258589511754068,
      "grad_norm": 0.6566006541252136,
      "learning_rate": 3.840793352988475e-05,
      "loss": 0.2439,
      "step": 1280
    },
    {
      "epoch": 0.9330922242314648,
      "grad_norm": 0.8046408891677856,
      "learning_rate": 3.827392120075047e-05,
      "loss": 0.2826,
      "step": 1290
    },
    {
      "epoch": 0.9403254972875226,
      "grad_norm": 1.2167083024978638,
      "learning_rate": 3.8139908871616194e-05,
      "loss": 0.2536,
      "step": 1300
    },
    {
      "epoch": 0.9475587703435805,
      "grad_norm": 0.8506438732147217,
      "learning_rate": 3.800589654248191e-05,
      "loss": 0.2834,
      "step": 1310
    },
    {
      "epoch": 0.9547920433996383,
      "grad_norm": 0.7264501452445984,
      "learning_rate": 3.787188421334763e-05,
      "loss": 0.2776,
      "step": 1320
    },
    {
      "epoch": 0.9620253164556962,
      "grad_norm": 0.6088835597038269,
      "learning_rate": 3.773787188421335e-05,
      "loss": 0.2586,
      "step": 1330
    },
    {
      "epoch": 0.969258589511754,
      "grad_norm": 1.0875388383865356,
      "learning_rate": 3.760385955507907e-05,
      "loss": 0.2762,
      "step": 1340
    },
    {
      "epoch": 0.976491862567812,
      "grad_norm": 0.5847759246826172,
      "learning_rate": 3.7469847225944785e-05,
      "loss": 0.2497,
      "step": 1350
    },
    {
      "epoch": 0.9837251356238698,
      "grad_norm": 0.8425506949424744,
      "learning_rate": 3.733583489681051e-05,
      "loss": 0.2727,
      "step": 1360
    },
    {
      "epoch": 0.9909584086799277,
      "grad_norm": 0.7505770325660706,
      "learning_rate": 3.720182256767622e-05,
      "loss": 0.2318,
      "step": 1370
    },
    {
      "epoch": 0.9981916817359855,
      "grad_norm": 0.6038647890090942,
      "learning_rate": 3.706781023854195e-05,
      "loss": 0.2613,
      "step": 1380
    },
    {
      "epoch": 0.9996383363471971,
      "eval_loss": 0.3357219696044922,
      "eval_runtime": 62.0258,
      "eval_samples_per_second": 11.157,
      "eval_steps_per_second": 11.157,
      "step": 1382
    },
    {
      "epoch": 1.0054249547920433,
      "grad_norm": 0.8641707897186279,
      "learning_rate": 3.693379790940767e-05,
      "loss": 0.2805,
      "step": 1390
    },
    {
      "epoch": 1.0126582278481013,
      "grad_norm": 0.6988569498062134,
      "learning_rate": 3.679978558027339e-05,
      "loss": 0.247,
      "step": 1400
    },
    {
      "epoch": 1.0198915009041591,
      "grad_norm": 1.1796172857284546,
      "learning_rate": 3.6665773251139106e-05,
      "loss": 0.2731,
      "step": 1410
    },
    {
      "epoch": 1.027124773960217,
      "grad_norm": 0.9274995923042297,
      "learning_rate": 3.653176092200483e-05,
      "loss": 0.2824,
      "step": 1420
    },
    {
      "epoch": 1.0343580470162748,
      "grad_norm": 0.9851164221763611,
      "learning_rate": 3.6397748592870544e-05,
      "loss": 0.3147,
      "step": 1430
    },
    {
      "epoch": 1.0415913200723328,
      "grad_norm": 0.5825101137161255,
      "learning_rate": 3.6263736263736266e-05,
      "loss": 0.2523,
      "step": 1440
    },
    {
      "epoch": 1.0488245931283906,
      "grad_norm": 0.6794624924659729,
      "learning_rate": 3.612972393460198e-05,
      "loss": 0.252,
      "step": 1450
    },
    {
      "epoch": 1.0560578661844484,
      "grad_norm": 0.9897713661193848,
      "learning_rate": 3.5995711605467704e-05,
      "loss": 0.2644,
      "step": 1460
    },
    {
      "epoch": 1.0632911392405062,
      "grad_norm": 0.8363454937934875,
      "learning_rate": 3.5861699276333426e-05,
      "loss": 0.2777,
      "step": 1470
    },
    {
      "epoch": 1.0705244122965643,
      "grad_norm": 1.05173921585083,
      "learning_rate": 3.572768694719915e-05,
      "loss": 0.2461,
      "step": 1480
    },
    {
      "epoch": 1.077757685352622,
      "grad_norm": 1.0984505414962769,
      "learning_rate": 3.5593674618064864e-05,
      "loss": 0.2542,
      "step": 1490
    },
    {
      "epoch": 1.0849909584086799,
      "grad_norm": 2.5893747806549072,
      "learning_rate": 3.545966228893059e-05,
      "loss": 0.2891,
      "step": 1500
    },
    {
      "epoch": 1.092224231464738,
      "grad_norm": 0.6701628565788269,
      "learning_rate": 3.53256499597963e-05,
      "loss": 0.2929,
      "step": 1510
    },
    {
      "epoch": 1.0994575045207957,
      "grad_norm": 0.8480632305145264,
      "learning_rate": 3.5191637630662025e-05,
      "loss": 0.2868,
      "step": 1520
    },
    {
      "epoch": 1.1066907775768535,
      "grad_norm": 0.5073283314704895,
      "learning_rate": 3.505762530152774e-05,
      "loss": 0.2687,
      "step": 1530
    },
    {
      "epoch": 1.1139240506329113,
      "grad_norm": 0.8397051095962524,
      "learning_rate": 3.492361297239346e-05,
      "loss": 0.2952,
      "step": 1540
    },
    {
      "epoch": 1.1211573236889691,
      "grad_norm": 1.0231637954711914,
      "learning_rate": 3.478960064325918e-05,
      "loss": 0.3133,
      "step": 1550
    },
    {
      "epoch": 1.1283905967450272,
      "grad_norm": 0.6883766055107117,
      "learning_rate": 3.46555883141249e-05,
      "loss": 0.2365,
      "step": 1560
    },
    {
      "epoch": 1.135623869801085,
      "grad_norm": 0.8467130661010742,
      "learning_rate": 3.452157598499062e-05,
      "loss": 0.2853,
      "step": 1570
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.8320897221565247,
      "learning_rate": 3.4387563655856345e-05,
      "loss": 0.2586,
      "step": 1580
    },
    {
      "epoch": 1.1500904159132008,
      "grad_norm": 0.9881494045257568,
      "learning_rate": 3.425355132672206e-05,
      "loss": 0.2845,
      "step": 1590
    },
    {
      "epoch": 1.1573236889692586,
      "grad_norm": 0.9196518659591675,
      "learning_rate": 3.411953899758778e-05,
      "loss": 0.2681,
      "step": 1600
    },
    {
      "epoch": 1.1645569620253164,
      "grad_norm": 0.7258828282356262,
      "learning_rate": 3.39855266684535e-05,
      "loss": 0.2973,
      "step": 1610
    },
    {
      "epoch": 1.1717902350813743,
      "grad_norm": 0.9885774850845337,
      "learning_rate": 3.385151433931922e-05,
      "loss": 0.2686,
      "step": 1620
    },
    {
      "epoch": 1.179023508137432,
      "grad_norm": 0.7771308422088623,
      "learning_rate": 3.371750201018494e-05,
      "loss": 0.277,
      "step": 1630
    },
    {
      "epoch": 1.18625678119349,
      "grad_norm": 0.8630874752998352,
      "learning_rate": 3.358348968105066e-05,
      "loss": 0.2537,
      "step": 1640
    },
    {
      "epoch": 1.193490054249548,
      "grad_norm": 0.7935311794281006,
      "learning_rate": 3.344947735191638e-05,
      "loss": 0.2519,
      "step": 1650
    },
    {
      "epoch": 1.2007233273056057,
      "grad_norm": 0.6476302742958069,
      "learning_rate": 3.33154650227821e-05,
      "loss": 0.2878,
      "step": 1660
    },
    {
      "epoch": 1.2079566003616637,
      "grad_norm": 0.8700712323188782,
      "learning_rate": 3.318145269364782e-05,
      "loss": 0.2459,
      "step": 1670
    },
    {
      "epoch": 1.2151898734177216,
      "grad_norm": 0.6052471399307251,
      "learning_rate": 3.3047440364513535e-05,
      "loss": 0.2474,
      "step": 1680
    },
    {
      "epoch": 1.2224231464737794,
      "grad_norm": 0.7579678297042847,
      "learning_rate": 3.291342803537926e-05,
      "loss": 0.267,
      "step": 1690
    },
    {
      "epoch": 1.2296564195298372,
      "grad_norm": 1.2432116270065308,
      "learning_rate": 3.277941570624497e-05,
      "loss": 0.2435,
      "step": 1700
    },
    {
      "epoch": 1.2368896925858952,
      "grad_norm": 0.7056151032447815,
      "learning_rate": 3.2645403377110695e-05,
      "loss": 0.2424,
      "step": 1710
    },
    {
      "epoch": 1.244122965641953,
      "grad_norm": 1.0150351524353027,
      "learning_rate": 3.251139104797641e-05,
      "loss": 0.3319,
      "step": 1720
    },
    {
      "epoch": 1.2513562386980108,
      "grad_norm": 0.6749945878982544,
      "learning_rate": 3.237737871884213e-05,
      "loss": 0.2567,
      "step": 1730
    },
    {
      "epoch": 1.2585895117540686,
      "grad_norm": 0.9942602515220642,
      "learning_rate": 3.224336638970785e-05,
      "loss": 0.253,
      "step": 1740
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.9052547812461853,
      "learning_rate": 3.210935406057358e-05,
      "loss": 0.2677,
      "step": 1750
    },
    {
      "epoch": 1.2730560578661845,
      "grad_norm": 0.7060429453849792,
      "learning_rate": 3.1975341731439293e-05,
      "loss": 0.2413,
      "step": 1760
    },
    {
      "epoch": 1.2802893309222423,
      "grad_norm": 1.1054975986480713,
      "learning_rate": 3.1841329402305016e-05,
      "loss": 0.2596,
      "step": 1770
    },
    {
      "epoch": 1.2875226039783003,
      "grad_norm": 0.6010391116142273,
      "learning_rate": 3.170731707317073e-05,
      "loss": 0.3021,
      "step": 1780
    },
    {
      "epoch": 1.2947558770343581,
      "grad_norm": 0.49864208698272705,
      "learning_rate": 3.1573304744036454e-05,
      "loss": 0.2255,
      "step": 1790
    },
    {
      "epoch": 1.301989150090416,
      "grad_norm": 0.8087844848632812,
      "learning_rate": 3.143929241490217e-05,
      "loss": 0.2611,
      "step": 1800
    },
    {
      "epoch": 1.3092224231464737,
      "grad_norm": 0.6747764945030212,
      "learning_rate": 3.130528008576789e-05,
      "loss": 0.239,
      "step": 1810
    },
    {
      "epoch": 1.3164556962025316,
      "grad_norm": 0.7156128883361816,
      "learning_rate": 3.117126775663361e-05,
      "loss": 0.2472,
      "step": 1820
    },
    {
      "epoch": 1.3236889692585896,
      "grad_norm": 0.7630985975265503,
      "learning_rate": 3.103725542749933e-05,
      "loss": 0.2626,
      "step": 1830
    },
    {
      "epoch": 1.3309222423146474,
      "grad_norm": 0.7335495352745056,
      "learning_rate": 3.090324309836505e-05,
      "loss": 0.2892,
      "step": 1840
    },
    {
      "epoch": 1.3381555153707052,
      "grad_norm": 1.876204490661621,
      "learning_rate": 3.0769230769230774e-05,
      "loss": 0.2594,
      "step": 1850
    },
    {
      "epoch": 1.3453887884267632,
      "grad_norm": 0.678551197052002,
      "learning_rate": 3.063521844009649e-05,
      "loss": 0.2232,
      "step": 1860
    },
    {
      "epoch": 1.352622061482821,
      "grad_norm": 0.6818243265151978,
      "learning_rate": 3.050120611096221e-05,
      "loss": 0.2317,
      "step": 1870
    },
    {
      "epoch": 1.3598553345388789,
      "grad_norm": 1.0803993940353394,
      "learning_rate": 3.0367193781827928e-05,
      "loss": 0.2354,
      "step": 1880
    },
    {
      "epoch": 1.3670886075949367,
      "grad_norm": 0.9422266483306885,
      "learning_rate": 3.023318145269365e-05,
      "loss": 0.2379,
      "step": 1890
    },
    {
      "epoch": 1.3743218806509945,
      "grad_norm": 0.7201979756355286,
      "learning_rate": 3.009916912355937e-05,
      "loss": 0.2488,
      "step": 1900
    },
    {
      "epoch": 1.3815551537070525,
      "grad_norm": 1.6224857568740845,
      "learning_rate": 2.9965156794425088e-05,
      "loss": 0.2781,
      "step": 1910
    },
    {
      "epoch": 1.3887884267631103,
      "grad_norm": 0.7916748523712158,
      "learning_rate": 2.9831144465290807e-05,
      "loss": 0.2703,
      "step": 1920
    },
    {
      "epoch": 1.3960216998191681,
      "grad_norm": 0.8648539781570435,
      "learning_rate": 2.969713213615653e-05,
      "loss": 0.2469,
      "step": 1930
    },
    {
      "epoch": 1.4032549728752262,
      "grad_norm": 0.7334338426589966,
      "learning_rate": 2.956311980702225e-05,
      "loss": 0.2843,
      "step": 1940
    },
    {
      "epoch": 1.410488245931284,
      "grad_norm": 2.0746240615844727,
      "learning_rate": 2.9429107477887967e-05,
      "loss": 0.2639,
      "step": 1950
    },
    {
      "epoch": 1.4177215189873418,
      "grad_norm": 1.1218760013580322,
      "learning_rate": 2.9295095148753686e-05,
      "loss": 0.1994,
      "step": 1960
    },
    {
      "epoch": 1.4249547920433996,
      "grad_norm": 0.7425321936607361,
      "learning_rate": 2.9161082819619405e-05,
      "loss": 0.2532,
      "step": 1970
    },
    {
      "epoch": 1.4321880650994574,
      "grad_norm": 0.9516299962997437,
      "learning_rate": 2.9027070490485124e-05,
      "loss": 0.2454,
      "step": 1980
    },
    {
      "epoch": 1.4394213381555154,
      "grad_norm": 0.5587036609649658,
      "learning_rate": 2.8893058161350843e-05,
      "loss": 0.2449,
      "step": 1990
    },
    {
      "epoch": 1.4466546112115732,
      "grad_norm": 0.6425572037696838,
      "learning_rate": 2.8759045832216562e-05,
      "loss": 0.2516,
      "step": 2000
    },
    {
      "epoch": 1.453887884267631,
      "grad_norm": 0.7540103793144226,
      "learning_rate": 2.862503350308228e-05,
      "loss": 0.2725,
      "step": 2010
    },
    {
      "epoch": 1.461121157323689,
      "grad_norm": 0.7685932517051697,
      "learning_rate": 2.8491021173948007e-05,
      "loss": 0.2752,
      "step": 2020
    },
    {
      "epoch": 1.4683544303797469,
      "grad_norm": 0.7489546537399292,
      "learning_rate": 2.8357008844813726e-05,
      "loss": 0.2554,
      "step": 2030
    },
    {
      "epoch": 1.4755877034358047,
      "grad_norm": 0.8952268362045288,
      "learning_rate": 2.8222996515679445e-05,
      "loss": 0.2556,
      "step": 2040
    },
    {
      "epoch": 1.4828209764918625,
      "grad_norm": 0.5673489570617676,
      "learning_rate": 2.8088984186545164e-05,
      "loss": 0.2316,
      "step": 2050
    },
    {
      "epoch": 1.4900542495479203,
      "grad_norm": 1.5767914056777954,
      "learning_rate": 2.7954971857410883e-05,
      "loss": 0.2418,
      "step": 2060
    },
    {
      "epoch": 1.4972875226039783,
      "grad_norm": 0.7980072498321533,
      "learning_rate": 2.7820959528276602e-05,
      "loss": 0.2226,
      "step": 2070
    },
    {
      "epoch": 1.5045207956600362,
      "grad_norm": 1.329362154006958,
      "learning_rate": 2.768694719914232e-05,
      "loss": 0.2304,
      "step": 2080
    },
    {
      "epoch": 1.511754068716094,
      "grad_norm": 0.9282525777816772,
      "learning_rate": 2.755293487000804e-05,
      "loss": 0.2167,
      "step": 2090
    },
    {
      "epoch": 1.518987341772152,
      "grad_norm": 0.962906002998352,
      "learning_rate": 2.741892254087376e-05,
      "loss": 0.2777,
      "step": 2100
    },
    {
      "epoch": 1.5262206148282098,
      "grad_norm": 1.1062206029891968,
      "learning_rate": 2.7284910211739484e-05,
      "loss": 0.2775,
      "step": 2110
    },
    {
      "epoch": 1.5334538878842676,
      "grad_norm": 1.872755527496338,
      "learning_rate": 2.7150897882605203e-05,
      "loss": 0.2513,
      "step": 2120
    },
    {
      "epoch": 1.5406871609403257,
      "grad_norm": 0.9045835733413696,
      "learning_rate": 2.7016885553470922e-05,
      "loss": 0.2601,
      "step": 2130
    },
    {
      "epoch": 1.5479204339963832,
      "grad_norm": 0.6466512084007263,
      "learning_rate": 2.688287322433664e-05,
      "loss": 0.2368,
      "step": 2140
    },
    {
      "epoch": 1.5551537070524413,
      "grad_norm": 0.8425074815750122,
      "learning_rate": 2.674886089520236e-05,
      "loss": 0.2188,
      "step": 2150
    },
    {
      "epoch": 1.562386980108499,
      "grad_norm": 0.7780395746231079,
      "learning_rate": 2.661484856606808e-05,
      "loss": 0.2511,
      "step": 2160
    },
    {
      "epoch": 1.5696202531645569,
      "grad_norm": 0.8381851315498352,
      "learning_rate": 2.6480836236933798e-05,
      "loss": 0.229,
      "step": 2170
    },
    {
      "epoch": 1.576853526220615,
      "grad_norm": 0.6304774284362793,
      "learning_rate": 2.6346823907799517e-05,
      "loss": 0.2584,
      "step": 2180
    },
    {
      "epoch": 1.5840867992766727,
      "grad_norm": 0.5333464741706848,
      "learning_rate": 2.6212811578665236e-05,
      "loss": 0.2453,
      "step": 2190
    },
    {
      "epoch": 1.5913200723327305,
      "grad_norm": 1.4820994138717651,
      "learning_rate": 2.6078799249530962e-05,
      "loss": 0.2401,
      "step": 2200
    },
    {
      "epoch": 1.5985533453887886,
      "grad_norm": 1.2044894695281982,
      "learning_rate": 2.594478692039668e-05,
      "loss": 0.236,
      "step": 2210
    },
    {
      "epoch": 1.6057866184448462,
      "grad_norm": 0.707647442817688,
      "learning_rate": 2.58107745912624e-05,
      "loss": 0.2792,
      "step": 2220
    },
    {
      "epoch": 1.6130198915009042,
      "grad_norm": 0.7419742345809937,
      "learning_rate": 2.567676226212812e-05,
      "loss": 0.2105,
      "step": 2230
    },
    {
      "epoch": 1.620253164556962,
      "grad_norm": 0.841495156288147,
      "learning_rate": 2.5542749932993838e-05,
      "loss": 0.2472,
      "step": 2240
    },
    {
      "epoch": 1.6274864376130198,
      "grad_norm": 1.4129703044891357,
      "learning_rate": 2.5408737603859557e-05,
      "loss": 0.2828,
      "step": 2250
    },
    {
      "epoch": 1.6347197106690778,
      "grad_norm": 0.7202268838882446,
      "learning_rate": 2.5274725274725276e-05,
      "loss": 0.2602,
      "step": 2260
    },
    {
      "epoch": 1.6419529837251357,
      "grad_norm": 0.8873811960220337,
      "learning_rate": 2.5140712945590995e-05,
      "loss": 0.2746,
      "step": 2270
    },
    {
      "epoch": 1.6491862567811935,
      "grad_norm": 1.2404372692108154,
      "learning_rate": 2.5006700616456714e-05,
      "loss": 0.2781,
      "step": 2280
    },
    {
      "epoch": 1.6564195298372515,
      "grad_norm": 0.5051134824752808,
      "learning_rate": 2.4872688287322436e-05,
      "loss": 0.1867,
      "step": 2290
    },
    {
      "epoch": 1.663652802893309,
      "grad_norm": 1.0007883310317993,
      "learning_rate": 2.4738675958188155e-05,
      "loss": 0.2553,
      "step": 2300
    },
    {
      "epoch": 1.6708860759493671,
      "grad_norm": 0.6341479420661926,
      "learning_rate": 2.4604663629053874e-05,
      "loss": 0.1991,
      "step": 2310
    },
    {
      "epoch": 1.678119349005425,
      "grad_norm": 0.7599827647209167,
      "learning_rate": 2.4470651299919596e-05,
      "loss": 0.2475,
      "step": 2320
    },
    {
      "epoch": 1.6853526220614827,
      "grad_norm": 0.6865144968032837,
      "learning_rate": 2.4336638970785315e-05,
      "loss": 0.255,
      "step": 2330
    },
    {
      "epoch": 1.6925858951175408,
      "grad_norm": 1.0926008224487305,
      "learning_rate": 2.4202626641651034e-05,
      "loss": 0.2463,
      "step": 2340
    },
    {
      "epoch": 1.6998191681735986,
      "grad_norm": 0.6582682728767395,
      "learning_rate": 2.4068614312516753e-05,
      "loss": 0.2634,
      "step": 2350
    },
    {
      "epoch": 1.7070524412296564,
      "grad_norm": 0.643738865852356,
      "learning_rate": 2.3934601983382472e-05,
      "loss": 0.2361,
      "step": 2360
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.5920677185058594,
      "learning_rate": 2.380058965424819e-05,
      "loss": 0.2368,
      "step": 2370
    },
    {
      "epoch": 1.721518987341772,
      "grad_norm": 0.9505865573883057,
      "learning_rate": 2.366657732511391e-05,
      "loss": 0.2716,
      "step": 2380
    },
    {
      "epoch": 1.72875226039783,
      "grad_norm": 0.6623713970184326,
      "learning_rate": 2.353256499597963e-05,
      "loss": 0.2379,
      "step": 2390
    },
    {
      "epoch": 1.7359855334538878,
      "grad_norm": 0.8425636887550354,
      "learning_rate": 2.3398552666845348e-05,
      "loss": 0.2572,
      "step": 2400
    },
    {
      "epoch": 1.7432188065099457,
      "grad_norm": 0.9610317945480347,
      "learning_rate": 2.326454033771107e-05,
      "loss": 0.2832,
      "step": 2410
    },
    {
      "epoch": 1.7504520795660037,
      "grad_norm": 0.7268164157867432,
      "learning_rate": 2.313052800857679e-05,
      "loss": 0.2263,
      "step": 2420
    },
    {
      "epoch": 1.7576853526220615,
      "grad_norm": 1.0514193773269653,
      "learning_rate": 2.299651567944251e-05,
      "loss": 0.2513,
      "step": 2430
    },
    {
      "epoch": 1.7649186256781193,
      "grad_norm": 0.6645162105560303,
      "learning_rate": 2.2862503350308227e-05,
      "loss": 0.2397,
      "step": 2440
    },
    {
      "epoch": 1.7721518987341773,
      "grad_norm": 0.6703301072120667,
      "learning_rate": 2.272849102117395e-05,
      "loss": 0.2405,
      "step": 2450
    },
    {
      "epoch": 1.779385171790235,
      "grad_norm": 0.994327962398529,
      "learning_rate": 2.259447869203967e-05,
      "loss": 0.2327,
      "step": 2460
    },
    {
      "epoch": 1.786618444846293,
      "grad_norm": 0.7007495760917664,
      "learning_rate": 2.2460466362905388e-05,
      "loss": 0.231,
      "step": 2470
    },
    {
      "epoch": 1.7938517179023508,
      "grad_norm": 0.7429206967353821,
      "learning_rate": 2.2326454033771107e-05,
      "loss": 0.2473,
      "step": 2480
    },
    {
      "epoch": 1.8010849909584086,
      "grad_norm": 1.0352061986923218,
      "learning_rate": 2.2192441704636826e-05,
      "loss": 0.2498,
      "step": 2490
    },
    {
      "epoch": 1.8083182640144666,
      "grad_norm": 0.9290292263031006,
      "learning_rate": 2.2058429375502548e-05,
      "loss": 0.257,
      "step": 2500
    },
    {
      "epoch": 1.8155515370705244,
      "grad_norm": 0.9421617388725281,
      "learning_rate": 2.1924417046368267e-05,
      "loss": 0.2278,
      "step": 2510
    },
    {
      "epoch": 1.8227848101265822,
      "grad_norm": 0.9962188601493835,
      "learning_rate": 2.1790404717233986e-05,
      "loss": 0.2493,
      "step": 2520
    },
    {
      "epoch": 1.8300180831826403,
      "grad_norm": 0.7415176630020142,
      "learning_rate": 2.1656392388099705e-05,
      "loss": 0.2458,
      "step": 2530
    },
    {
      "epoch": 1.837251356238698,
      "grad_norm": 0.9931446313858032,
      "learning_rate": 2.1522380058965424e-05,
      "loss": 0.2739,
      "step": 2540
    },
    {
      "epoch": 1.8444846292947559,
      "grad_norm": 0.7371763586997986,
      "learning_rate": 2.1388367729831146e-05,
      "loss": 0.2631,
      "step": 2550
    },
    {
      "epoch": 1.851717902350814,
      "grad_norm": 0.6499118804931641,
      "learning_rate": 2.1254355400696865e-05,
      "loss": 0.2289,
      "step": 2560
    },
    {
      "epoch": 1.8589511754068715,
      "grad_norm": 0.7419933676719666,
      "learning_rate": 2.1120343071562584e-05,
      "loss": 0.2312,
      "step": 2570
    },
    {
      "epoch": 1.8661844484629295,
      "grad_norm": 0.91588294506073,
      "learning_rate": 2.0986330742428303e-05,
      "loss": 0.2469,
      "step": 2580
    },
    {
      "epoch": 1.8734177215189873,
      "grad_norm": 0.7944947481155396,
      "learning_rate": 2.0852318413294025e-05,
      "loss": 0.2408,
      "step": 2590
    },
    {
      "epoch": 1.8806509945750451,
      "grad_norm": 0.7480332255363464,
      "learning_rate": 2.0718306084159744e-05,
      "loss": 0.2621,
      "step": 2600
    },
    {
      "epoch": 1.8878842676311032,
      "grad_norm": 0.7239651679992676,
      "learning_rate": 2.0584293755025463e-05,
      "loss": 0.2217,
      "step": 2610
    },
    {
      "epoch": 1.895117540687161,
      "grad_norm": 0.8091750741004944,
      "learning_rate": 2.0450281425891182e-05,
      "loss": 0.2149,
      "step": 2620
    },
    {
      "epoch": 1.9023508137432188,
      "grad_norm": 0.9756098389625549,
      "learning_rate": 2.03162690967569e-05,
      "loss": 0.2558,
      "step": 2630
    },
    {
      "epoch": 1.9095840867992768,
      "grad_norm": 1.4490482807159424,
      "learning_rate": 2.0182256767622624e-05,
      "loss": 0.2561,
      "step": 2640
    },
    {
      "epoch": 1.9168173598553344,
      "grad_norm": 0.7804121971130371,
      "learning_rate": 2.0048244438488343e-05,
      "loss": 0.2398,
      "step": 2650
    },
    {
      "epoch": 1.9240506329113924,
      "grad_norm": 0.6378359198570251,
      "learning_rate": 1.991423210935406e-05,
      "loss": 0.2498,
      "step": 2660
    },
    {
      "epoch": 1.9312839059674503,
      "grad_norm": 1.0600472688674927,
      "learning_rate": 1.978021978021978e-05,
      "loss": 0.2477,
      "step": 2670
    },
    {
      "epoch": 1.938517179023508,
      "grad_norm": 0.6639711856842041,
      "learning_rate": 1.9646207451085503e-05,
      "loss": 0.2629,
      "step": 2680
    },
    {
      "epoch": 1.945750452079566,
      "grad_norm": 0.7966877818107605,
      "learning_rate": 1.9512195121951222e-05,
      "loss": 0.2395,
      "step": 2690
    },
    {
      "epoch": 1.952983725135624,
      "grad_norm": 1.1348742246627808,
      "learning_rate": 1.937818279281694e-05,
      "loss": 0.2602,
      "step": 2700
    },
    {
      "epoch": 1.9602169981916817,
      "grad_norm": 0.9117560386657715,
      "learning_rate": 1.924417046368266e-05,
      "loss": 0.232,
      "step": 2710
    },
    {
      "epoch": 1.9674502712477397,
      "grad_norm": 0.6842429041862488,
      "learning_rate": 1.911015813454838e-05,
      "loss": 0.2409,
      "step": 2720
    },
    {
      "epoch": 1.9746835443037973,
      "grad_norm": 0.618970513343811,
      "learning_rate": 1.89761458054141e-05,
      "loss": 0.2407,
      "step": 2730
    },
    {
      "epoch": 1.9819168173598554,
      "grad_norm": 0.7713649272918701,
      "learning_rate": 1.884213347627982e-05,
      "loss": 0.2495,
      "step": 2740
    },
    {
      "epoch": 1.9891500904159132,
      "grad_norm": 0.7112859487533569,
      "learning_rate": 1.870812114714554e-05,
      "loss": 0.2654,
      "step": 2750
    },
    {
      "epoch": 1.996383363471971,
      "grad_norm": 0.8368362188339233,
      "learning_rate": 1.8574108818011258e-05,
      "loss": 0.2482,
      "step": 2760
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.30803531408309937,
      "eval_runtime": 59.9587,
      "eval_samples_per_second": 11.541,
      "eval_steps_per_second": 11.541,
      "step": 2765
    },
    {
      "epoch": 2.003616636528029,
      "grad_norm": 0.56220543384552,
      "learning_rate": 1.844009648887698e-05,
      "loss": 0.2666,
      "step": 2770
    },
    {
      "epoch": 2.0108499095840866,
      "grad_norm": 0.5676460862159729,
      "learning_rate": 1.83060841597427e-05,
      "loss": 0.2088,
      "step": 2780
    },
    {
      "epoch": 2.0180831826401446,
      "grad_norm": 0.9686766862869263,
      "learning_rate": 1.817207183060842e-05,
      "loss": 0.2688,
      "step": 2790
    },
    {
      "epoch": 2.0253164556962027,
      "grad_norm": 0.6389455199241638,
      "learning_rate": 1.8038059501474137e-05,
      "loss": 0.2579,
      "step": 2800
    },
    {
      "epoch": 2.0325497287522603,
      "grad_norm": 0.9885610342025757,
      "learning_rate": 1.7904047172339856e-05,
      "loss": 0.2453,
      "step": 2810
    },
    {
      "epoch": 2.0397830018083183,
      "grad_norm": 0.9323759078979492,
      "learning_rate": 1.7770034843205575e-05,
      "loss": 0.2546,
      "step": 2820
    },
    {
      "epoch": 2.0470162748643763,
      "grad_norm": 0.6844428181648254,
      "learning_rate": 1.7636022514071294e-05,
      "loss": 0.2197,
      "step": 2830
    },
    {
      "epoch": 2.054249547920434,
      "grad_norm": 0.882843554019928,
      "learning_rate": 1.7502010184937017e-05,
      "loss": 0.2894,
      "step": 2840
    },
    {
      "epoch": 2.061482820976492,
      "grad_norm": 0.8367316722869873,
      "learning_rate": 1.7367997855802736e-05,
      "loss": 0.2316,
      "step": 2850
    },
    {
      "epoch": 2.0687160940325495,
      "grad_norm": 0.6903860569000244,
      "learning_rate": 1.7233985526668455e-05,
      "loss": 0.2266,
      "step": 2860
    },
    {
      "epoch": 2.0759493670886076,
      "grad_norm": 0.5962510108947754,
      "learning_rate": 1.7099973197534174e-05,
      "loss": 0.28,
      "step": 2870
    },
    {
      "epoch": 2.0831826401446656,
      "grad_norm": 1.495290756225586,
      "learning_rate": 1.6965960868399893e-05,
      "loss": 0.2103,
      "step": 2880
    },
    {
      "epoch": 2.090415913200723,
      "grad_norm": 1.7275909185409546,
      "learning_rate": 1.683194853926561e-05,
      "loss": 0.2737,
      "step": 2890
    },
    {
      "epoch": 2.097649186256781,
      "grad_norm": 0.8669446706771851,
      "learning_rate": 1.669793621013133e-05,
      "loss": 0.2134,
      "step": 2900
    },
    {
      "epoch": 2.1048824593128392,
      "grad_norm": 0.7273367643356323,
      "learning_rate": 1.6563923880997053e-05,
      "loss": 0.229,
      "step": 2910
    },
    {
      "epoch": 2.112115732368897,
      "grad_norm": 0.9603479504585266,
      "learning_rate": 1.6429911551862772e-05,
      "loss": 0.2424,
      "step": 2920
    },
    {
      "epoch": 2.119349005424955,
      "grad_norm": 1.0963714122772217,
      "learning_rate": 1.629589922272849e-05,
      "loss": 0.2249,
      "step": 2930
    },
    {
      "epoch": 2.1265822784810124,
      "grad_norm": 0.8380763530731201,
      "learning_rate": 1.616188689359421e-05,
      "loss": 0.2638,
      "step": 2940
    },
    {
      "epoch": 2.1338155515370705,
      "grad_norm": 0.9831618070602417,
      "learning_rate": 1.602787456445993e-05,
      "loss": 0.2261,
      "step": 2950
    },
    {
      "epoch": 2.1410488245931285,
      "grad_norm": 0.7039121389389038,
      "learning_rate": 1.589386223532565e-05,
      "loss": 0.2341,
      "step": 2960
    },
    {
      "epoch": 2.148282097649186,
      "grad_norm": 0.7483216524124146,
      "learning_rate": 1.575984990619137e-05,
      "loss": 0.2383,
      "step": 2970
    },
    {
      "epoch": 2.155515370705244,
      "grad_norm": 0.8593596816062927,
      "learning_rate": 1.562583757705709e-05,
      "loss": 0.2602,
      "step": 2980
    },
    {
      "epoch": 2.162748643761302,
      "grad_norm": 0.8311262130737305,
      "learning_rate": 1.5491825247922808e-05,
      "loss": 0.2804,
      "step": 2990
    },
    {
      "epoch": 2.1699819168173597,
      "grad_norm": 0.7268744707107544,
      "learning_rate": 1.535781291878853e-05,
      "loss": 0.2004,
      "step": 3000
    },
    {
      "epoch": 2.1772151898734178,
      "grad_norm": 0.58906489610672,
      "learning_rate": 1.522380058965425e-05,
      "loss": 0.2344,
      "step": 3010
    },
    {
      "epoch": 2.184448462929476,
      "grad_norm": 0.6885944604873657,
      "learning_rate": 1.5089788260519968e-05,
      "loss": 0.2242,
      "step": 3020
    },
    {
      "epoch": 2.1916817359855334,
      "grad_norm": 0.8659848570823669,
      "learning_rate": 1.4955775931385687e-05,
      "loss": 0.248,
      "step": 3030
    },
    {
      "epoch": 2.1989150090415914,
      "grad_norm": 0.8674936294555664,
      "learning_rate": 1.4821763602251406e-05,
      "loss": 0.2772,
      "step": 3040
    },
    {
      "epoch": 2.206148282097649,
      "grad_norm": 0.8169660568237305,
      "learning_rate": 1.4687751273117129e-05,
      "loss": 0.2404,
      "step": 3050
    },
    {
      "epoch": 2.213381555153707,
      "grad_norm": 0.7711973190307617,
      "learning_rate": 1.4553738943982847e-05,
      "loss": 0.2447,
      "step": 3060
    },
    {
      "epoch": 2.220614828209765,
      "grad_norm": 0.6516894698143005,
      "learning_rate": 1.4419726614848566e-05,
      "loss": 0.225,
      "step": 3070
    },
    {
      "epoch": 2.2278481012658227,
      "grad_norm": 0.7216740250587463,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.2607,
      "step": 3080
    },
    {
      "epoch": 2.2350813743218807,
      "grad_norm": 1.1890182495117188,
      "learning_rate": 1.4151701956580008e-05,
      "loss": 0.2125,
      "step": 3090
    },
    {
      "epoch": 2.2423146473779383,
      "grad_norm": 0.6206274032592773,
      "learning_rate": 1.4017689627445727e-05,
      "loss": 0.227,
      "step": 3100
    },
    {
      "epoch": 2.2495479204339963,
      "grad_norm": 0.7956590056419373,
      "learning_rate": 1.3883677298311446e-05,
      "loss": 0.2605,
      "step": 3110
    },
    {
      "epoch": 2.2567811934900543,
      "grad_norm": 0.8426486849784851,
      "learning_rate": 1.3749664969177165e-05,
      "loss": 0.2359,
      "step": 3120
    },
    {
      "epoch": 2.264014466546112,
      "grad_norm": 0.7997283935546875,
      "learning_rate": 1.3615652640042884e-05,
      "loss": 0.2373,
      "step": 3130
    },
    {
      "epoch": 2.27124773960217,
      "grad_norm": 1.5081329345703125,
      "learning_rate": 1.3481640310908606e-05,
      "loss": 0.231,
      "step": 3140
    },
    {
      "epoch": 2.278481012658228,
      "grad_norm": 1.0746349096298218,
      "learning_rate": 1.3347627981774325e-05,
      "loss": 0.2379,
      "step": 3150
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.7982090711593628,
      "learning_rate": 1.3213615652640044e-05,
      "loss": 0.2545,
      "step": 3160
    },
    {
      "epoch": 2.2929475587703436,
      "grad_norm": 0.6600468754768372,
      "learning_rate": 1.3079603323505763e-05,
      "loss": 0.2467,
      "step": 3170
    },
    {
      "epoch": 2.3001808318264017,
      "grad_norm": 0.8811435699462891,
      "learning_rate": 1.2945590994371482e-05,
      "loss": 0.2651,
      "step": 3180
    },
    {
      "epoch": 2.3074141048824592,
      "grad_norm": 0.7238408327102661,
      "learning_rate": 1.2811578665237203e-05,
      "loss": 0.2366,
      "step": 3190
    },
    {
      "epoch": 2.3146473779385173,
      "grad_norm": 0.8474276065826416,
      "learning_rate": 1.2677566336102922e-05,
      "loss": 0.2316,
      "step": 3200
    },
    {
      "epoch": 2.321880650994575,
      "grad_norm": 0.7644539475440979,
      "learning_rate": 1.2543554006968642e-05,
      "loss": 0.2408,
      "step": 3210
    },
    {
      "epoch": 2.329113924050633,
      "grad_norm": 0.6684224009513855,
      "learning_rate": 1.2409541677834361e-05,
      "loss": 0.2991,
      "step": 3220
    },
    {
      "epoch": 2.336347197106691,
      "grad_norm": 0.9958723187446594,
      "learning_rate": 1.227552934870008e-05,
      "loss": 0.243,
      "step": 3230
    },
    {
      "epoch": 2.3435804701627485,
      "grad_norm": 0.5366302132606506,
      "learning_rate": 1.21415170195658e-05,
      "loss": 0.2184,
      "step": 3240
    },
    {
      "epoch": 2.3508137432188065,
      "grad_norm": 0.9260081648826599,
      "learning_rate": 1.200750469043152e-05,
      "loss": 0.252,
      "step": 3250
    },
    {
      "epoch": 2.358047016274864,
      "grad_norm": 1.1788673400878906,
      "learning_rate": 1.1873492361297239e-05,
      "loss": 0.2369,
      "step": 3260
    },
    {
      "epoch": 2.365280289330922,
      "grad_norm": 0.7679851651191711,
      "learning_rate": 1.173948003216296e-05,
      "loss": 0.2518,
      "step": 3270
    },
    {
      "epoch": 2.37251356238698,
      "grad_norm": 0.6747058629989624,
      "learning_rate": 1.1605467703028678e-05,
      "loss": 0.2293,
      "step": 3280
    },
    {
      "epoch": 2.379746835443038,
      "grad_norm": 1.186470866203308,
      "learning_rate": 1.1471455373894399e-05,
      "loss": 0.2462,
      "step": 3290
    },
    {
      "epoch": 2.386980108499096,
      "grad_norm": 0.6559849381446838,
      "learning_rate": 1.1337443044760118e-05,
      "loss": 0.2332,
      "step": 3300
    },
    {
      "epoch": 2.394213381555154,
      "grad_norm": 0.6278023719787598,
      "learning_rate": 1.1203430715625839e-05,
      "loss": 0.2662,
      "step": 3310
    },
    {
      "epoch": 2.4014466546112114,
      "grad_norm": 0.8479017615318298,
      "learning_rate": 1.1069418386491558e-05,
      "loss": 0.2489,
      "step": 3320
    },
    {
      "epoch": 2.4086799276672695,
      "grad_norm": 0.7756142616271973,
      "learning_rate": 1.0935406057357278e-05,
      "loss": 0.2419,
      "step": 3330
    },
    {
      "epoch": 2.4159132007233275,
      "grad_norm": 0.7696451544761658,
      "learning_rate": 1.0801393728222997e-05,
      "loss": 0.2588,
      "step": 3340
    },
    {
      "epoch": 2.423146473779385,
      "grad_norm": 0.7688946723937988,
      "learning_rate": 1.0667381399088716e-05,
      "loss": 0.2444,
      "step": 3350
    },
    {
      "epoch": 2.430379746835443,
      "grad_norm": 0.9113950729370117,
      "learning_rate": 1.0533369069954437e-05,
      "loss": 0.2556,
      "step": 3360
    },
    {
      "epoch": 2.4376130198915007,
      "grad_norm": 0.8997178077697754,
      "learning_rate": 1.0399356740820156e-05,
      "loss": 0.2532,
      "step": 3370
    },
    {
      "epoch": 2.4448462929475587,
      "grad_norm": 0.9923109412193298,
      "learning_rate": 1.0265344411685877e-05,
      "loss": 0.2434,
      "step": 3380
    },
    {
      "epoch": 2.4520795660036168,
      "grad_norm": 0.8647897839546204,
      "learning_rate": 1.0131332082551595e-05,
      "loss": 0.245,
      "step": 3390
    },
    {
      "epoch": 2.4593128390596743,
      "grad_norm": 1.1143585443496704,
      "learning_rate": 9.997319753417316e-06,
      "loss": 0.2247,
      "step": 3400
    },
    {
      "epoch": 2.4665461121157324,
      "grad_norm": 1.3023574352264404,
      "learning_rate": 9.863307424283035e-06,
      "loss": 0.2252,
      "step": 3410
    },
    {
      "epoch": 2.4737793851717904,
      "grad_norm": 0.7223711609840393,
      "learning_rate": 9.729295095148754e-06,
      "loss": 0.2596,
      "step": 3420
    },
    {
      "epoch": 2.481012658227848,
      "grad_norm": 1.257817029953003,
      "learning_rate": 9.595282766014475e-06,
      "loss": 0.2543,
      "step": 3430
    },
    {
      "epoch": 2.488245931283906,
      "grad_norm": 0.8493991494178772,
      "learning_rate": 9.461270436880194e-06,
      "loss": 0.2514,
      "step": 3440
    },
    {
      "epoch": 2.495479204339964,
      "grad_norm": 0.7627488374710083,
      "learning_rate": 9.327258107745913e-06,
      "loss": 0.2487,
      "step": 3450
    },
    {
      "epoch": 2.5027124773960217,
      "grad_norm": 0.5220277905464172,
      "learning_rate": 9.193245778611632e-06,
      "loss": 0.2381,
      "step": 3460
    },
    {
      "epoch": 2.5099457504520797,
      "grad_norm": 0.8431286811828613,
      "learning_rate": 9.059233449477352e-06,
      "loss": 0.2471,
      "step": 3470
    },
    {
      "epoch": 2.5171790235081373,
      "grad_norm": 0.8509764671325684,
      "learning_rate": 8.925221120343071e-06,
      "loss": 0.2346,
      "step": 3480
    },
    {
      "epoch": 2.5244122965641953,
      "grad_norm": 0.984022319316864,
      "learning_rate": 8.791208791208792e-06,
      "loss": 0.2638,
      "step": 3490
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 1.1644424200057983,
      "learning_rate": 8.657196462074511e-06,
      "loss": 0.2206,
      "step": 3500
    },
    {
      "epoch": 2.538878842676311,
      "grad_norm": 0.9131946563720703,
      "learning_rate": 8.52318413294023e-06,
      "loss": 0.232,
      "step": 3510
    },
    {
      "epoch": 2.546112115732369,
      "grad_norm": 0.9978691339492798,
      "learning_rate": 8.38917180380595e-06,
      "loss": 0.2569,
      "step": 3520
    },
    {
      "epoch": 2.5533453887884265,
      "grad_norm": 0.9311498999595642,
      "learning_rate": 8.25515947467167e-06,
      "loss": 0.2468,
      "step": 3530
    },
    {
      "epoch": 2.5605786618444846,
      "grad_norm": 0.742301881313324,
      "learning_rate": 8.12114714553739e-06,
      "loss": 0.2153,
      "step": 3540
    },
    {
      "epoch": 2.5678119349005426,
      "grad_norm": 0.873257577419281,
      "learning_rate": 7.987134816403109e-06,
      "loss": 0.214,
      "step": 3550
    },
    {
      "epoch": 2.5750452079566006,
      "grad_norm": 0.9766570329666138,
      "learning_rate": 7.85312248726883e-06,
      "loss": 0.2032,
      "step": 3560
    },
    {
      "epoch": 2.5822784810126582,
      "grad_norm": 0.805841326713562,
      "learning_rate": 7.719110158134549e-06,
      "loss": 0.255,
      "step": 3570
    },
    {
      "epoch": 2.5895117540687163,
      "grad_norm": 0.7457530498504639,
      "learning_rate": 7.585097829000268e-06,
      "loss": 0.2787,
      "step": 3580
    },
    {
      "epoch": 2.596745027124774,
      "grad_norm": 1.0405185222625732,
      "learning_rate": 7.451085499865988e-06,
      "loss": 0.2493,
      "step": 3590
    },
    {
      "epoch": 2.603978300180832,
      "grad_norm": 0.8706818222999573,
      "learning_rate": 7.317073170731707e-06,
      "loss": 0.2491,
      "step": 3600
    },
    {
      "epoch": 2.61121157323689,
      "grad_norm": 0.8414295315742493,
      "learning_rate": 7.183060841597428e-06,
      "loss": 0.2168,
      "step": 3610
    },
    {
      "epoch": 2.6184448462929475,
      "grad_norm": 1.0401015281677246,
      "learning_rate": 7.049048512463147e-06,
      "loss": 0.2156,
      "step": 3620
    },
    {
      "epoch": 2.6256781193490055,
      "grad_norm": 0.6709201335906982,
      "learning_rate": 6.915036183328867e-06,
      "loss": 0.2556,
      "step": 3630
    },
    {
      "epoch": 2.632911392405063,
      "grad_norm": 0.8011340498924255,
      "learning_rate": 6.781023854194586e-06,
      "loss": 0.2192,
      "step": 3640
    },
    {
      "epoch": 2.640144665461121,
      "grad_norm": 0.7679179310798645,
      "learning_rate": 6.6470115250603065e-06,
      "loss": 0.2034,
      "step": 3650
    },
    {
      "epoch": 2.647377938517179,
      "grad_norm": 1.2640208005905151,
      "learning_rate": 6.5129991959260254e-06,
      "loss": 0.2274,
      "step": 3660
    },
    {
      "epoch": 2.6546112115732368,
      "grad_norm": 0.7462677955627441,
      "learning_rate": 6.378986866791744e-06,
      "loss": 0.2185,
      "step": 3670
    },
    {
      "epoch": 2.661844484629295,
      "grad_norm": 0.6792279481887817,
      "learning_rate": 6.244974537657465e-06,
      "loss": 0.2392,
      "step": 3680
    },
    {
      "epoch": 2.6690777576853524,
      "grad_norm": 1.0264416933059692,
      "learning_rate": 6.110962208523185e-06,
      "loss": 0.2539,
      "step": 3690
    },
    {
      "epoch": 2.6763110307414104,
      "grad_norm": 0.9351864457130432,
      "learning_rate": 5.976949879388904e-06,
      "loss": 0.282,
      "step": 3700
    },
    {
      "epoch": 2.6835443037974684,
      "grad_norm": 0.953508198261261,
      "learning_rate": 5.842937550254624e-06,
      "loss": 0.2385,
      "step": 3710
    },
    {
      "epoch": 2.6907775768535265,
      "grad_norm": 0.5227461457252502,
      "learning_rate": 5.7089252211203435e-06,
      "loss": 0.2087,
      "step": 3720
    },
    {
      "epoch": 2.698010849909584,
      "grad_norm": 0.7136702537536621,
      "learning_rate": 5.574912891986063e-06,
      "loss": 0.2318,
      "step": 3730
    },
    {
      "epoch": 2.705244122965642,
      "grad_norm": 1.161880373954773,
      "learning_rate": 5.440900562851783e-06,
      "loss": 0.2336,
      "step": 3740
    },
    {
      "epoch": 2.7124773960216997,
      "grad_norm": 0.6848407983779907,
      "learning_rate": 5.306888233717502e-06,
      "loss": 0.2686,
      "step": 3750
    },
    {
      "epoch": 2.7197106690777577,
      "grad_norm": 0.8650665283203125,
      "learning_rate": 5.172875904583222e-06,
      "loss": 0.2346,
      "step": 3760
    },
    {
      "epoch": 2.7269439421338157,
      "grad_norm": 0.6478945016860962,
      "learning_rate": 5.038863575448942e-06,
      "loss": 0.2408,
      "step": 3770
    },
    {
      "epoch": 2.7341772151898733,
      "grad_norm": 0.840629518032074,
      "learning_rate": 4.904851246314661e-06,
      "loss": 0.2626,
      "step": 3780
    },
    {
      "epoch": 2.7414104882459314,
      "grad_norm": 1.0858646631240845,
      "learning_rate": 4.7708389171803805e-06,
      "loss": 0.2338,
      "step": 3790
    },
    {
      "epoch": 2.748643761301989,
      "grad_norm": 0.6518255472183228,
      "learning_rate": 4.6368265880461e-06,
      "loss": 0.2195,
      "step": 3800
    },
    {
      "epoch": 2.755877034358047,
      "grad_norm": 0.6238564848899841,
      "learning_rate": 4.50281425891182e-06,
      "loss": 0.2392,
      "step": 3810
    },
    {
      "epoch": 2.763110307414105,
      "grad_norm": 1.1932741403579712,
      "learning_rate": 4.36880192977754e-06,
      "loss": 0.2499,
      "step": 3820
    },
    {
      "epoch": 2.7703435804701626,
      "grad_norm": 0.7978706955909729,
      "learning_rate": 4.23478960064326e-06,
      "loss": 0.2097,
      "step": 3830
    },
    {
      "epoch": 2.7775768535262206,
      "grad_norm": 1.1045621633529663,
      "learning_rate": 4.1007772715089796e-06,
      "loss": 0.2069,
      "step": 3840
    },
    {
      "epoch": 2.7848101265822782,
      "grad_norm": 1.229242205619812,
      "learning_rate": 3.966764942374699e-06,
      "loss": 0.2213,
      "step": 3850
    },
    {
      "epoch": 2.7920433996383363,
      "grad_norm": 0.9433271884918213,
      "learning_rate": 3.832752613240418e-06,
      "loss": 0.2526,
      "step": 3860
    },
    {
      "epoch": 2.7992766726943943,
      "grad_norm": 0.6953520178794861,
      "learning_rate": 3.6987402841061377e-06,
      "loss": 0.2501,
      "step": 3870
    },
    {
      "epoch": 2.8065099457504523,
      "grad_norm": 0.8981924653053284,
      "learning_rate": 3.5647279549718576e-06,
      "loss": 0.2564,
      "step": 3880
    },
    {
      "epoch": 2.81374321880651,
      "grad_norm": 0.6292991638183594,
      "learning_rate": 3.4307156258375774e-06,
      "loss": 0.2162,
      "step": 3890
    },
    {
      "epoch": 2.820976491862568,
      "grad_norm": 0.7746564745903015,
      "learning_rate": 3.2967032967032968e-06,
      "loss": 0.232,
      "step": 3900
    },
    {
      "epoch": 2.8282097649186255,
      "grad_norm": 0.7641200423240662,
      "learning_rate": 3.1626909675690166e-06,
      "loss": 0.2361,
      "step": 3910
    },
    {
      "epoch": 2.8354430379746836,
      "grad_norm": 1.1670855283737183,
      "learning_rate": 3.028678638434736e-06,
      "loss": 0.2664,
      "step": 3920
    },
    {
      "epoch": 2.8426763110307416,
      "grad_norm": 1.580491065979004,
      "learning_rate": 2.894666309300456e-06,
      "loss": 0.2294,
      "step": 3930
    },
    {
      "epoch": 2.849909584086799,
      "grad_norm": 0.852680504322052,
      "learning_rate": 2.7606539801661756e-06,
      "loss": 0.257,
      "step": 3940
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.6953287720680237,
      "learning_rate": 2.6266416510318954e-06,
      "loss": 0.259,
      "step": 3950
    },
    {
      "epoch": 2.864376130198915,
      "grad_norm": 1.1618120670318604,
      "learning_rate": 2.492629321897615e-06,
      "loss": 0.2206,
      "step": 3960
    },
    {
      "epoch": 2.871609403254973,
      "grad_norm": 0.7778320908546448,
      "learning_rate": 2.358616992763334e-06,
      "loss": 0.2036,
      "step": 3970
    },
    {
      "epoch": 2.878842676311031,
      "grad_norm": 0.47472915053367615,
      "learning_rate": 2.224604663629054e-06,
      "loss": 0.2579,
      "step": 3980
    },
    {
      "epoch": 2.8860759493670884,
      "grad_norm": 1.3277100324630737,
      "learning_rate": 2.090592334494774e-06,
      "loss": 0.205,
      "step": 3990
    },
    {
      "epoch": 2.8933092224231465,
      "grad_norm": 0.8346686959266663,
      "learning_rate": 1.9565800053604932e-06,
      "loss": 0.2311,
      "step": 4000
    },
    {
      "epoch": 2.900542495479204,
      "grad_norm": 0.6297268271446228,
      "learning_rate": 1.8225676762262128e-06,
      "loss": 0.2612,
      "step": 4010
    },
    {
      "epoch": 2.907775768535262,
      "grad_norm": 0.7551562786102295,
      "learning_rate": 1.6885553470919327e-06,
      "loss": 0.2257,
      "step": 4020
    },
    {
      "epoch": 2.91500904159132,
      "grad_norm": 0.8577800393104553,
      "learning_rate": 1.5545430179576523e-06,
      "loss": 0.2518,
      "step": 4030
    },
    {
      "epoch": 2.922242314647378,
      "grad_norm": 1.0306066274642944,
      "learning_rate": 1.4205306888233719e-06,
      "loss": 0.2218,
      "step": 4040
    },
    {
      "epoch": 2.9294755877034357,
      "grad_norm": 0.8993064165115356,
      "learning_rate": 1.2865183596890915e-06,
      "loss": 0.242,
      "step": 4050
    },
    {
      "epoch": 2.9367088607594938,
      "grad_norm": 0.8770492076873779,
      "learning_rate": 1.1525060305548113e-06,
      "loss": 0.242,
      "step": 4060
    },
    {
      "epoch": 2.9439421338155514,
      "grad_norm": 1.199742317199707,
      "learning_rate": 1.0184937014205307e-06,
      "loss": 0.2359,
      "step": 4070
    },
    {
      "epoch": 2.9511754068716094,
      "grad_norm": 1.030846118927002,
      "learning_rate": 8.844813722862505e-07,
      "loss": 0.2383,
      "step": 4080
    },
    {
      "epoch": 2.9584086799276674,
      "grad_norm": 0.7587871551513672,
      "learning_rate": 7.5046904315197e-07,
      "loss": 0.2349,
      "step": 4090
    },
    {
      "epoch": 2.965641952983725,
      "grad_norm": 1.1347887516021729,
      "learning_rate": 6.164567140176897e-07,
      "loss": 0.2603,
      "step": 4100
    },
    {
      "epoch": 2.972875226039783,
      "grad_norm": 0.8656131625175476,
      "learning_rate": 4.824443848834093e-07,
      "loss": 0.2361,
      "step": 4110
    },
    {
      "epoch": 2.9801084990958406,
      "grad_norm": 1.0158934593200684,
      "learning_rate": 3.4843205574912896e-07,
      "loss": 0.2591,
      "step": 4120
    },
    {
      "epoch": 2.9873417721518987,
      "grad_norm": 0.8768919706344604,
      "learning_rate": 2.1441972661484859e-07,
      "loss": 0.2263,
      "step": 4130
    },
    {
      "epoch": 2.9945750452079567,
      "grad_norm": 1.0823668241500854,
      "learning_rate": 8.040739748056822e-08,
      "loss": 0.2648,
      "step": 4140
    },
    {
      "epoch": 2.9989150090415913,
      "eval_loss": 0.2997841238975525,
      "eval_runtime": 59.0484,
      "eval_samples_per_second": 11.719,
      "eval_steps_per_second": 11.719,
      "step": 4146
    }
  ],
  "logging_steps": 10,
  "max_steps": 4146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9130519747362816.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
