{
  "best_metric": 0.2821888029575348,
  "best_model_checkpoint": "Qwen2.5-Coder-1.5B-Instruct-LoRA/checkpoint-4146",
  "epoch": 2.9989150090415913,
  "eval_steps": 500,
  "global_step": 4146,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007233273056057866,
      "grad_norm": 0.2235219031572342,
      "learning_rate": 1.2048192771084338e-06,
      "loss": 2.0715,
      "step": 10
    },
    {
      "epoch": 0.014466546112115732,
      "grad_norm": 0.22252021729946136,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 2.1373,
      "step": 20
    },
    {
      "epoch": 0.0216998191681736,
      "grad_norm": 0.1973022073507309,
      "learning_rate": 3.614457831325301e-06,
      "loss": 2.0368,
      "step": 30
    },
    {
      "epoch": 0.028933092224231464,
      "grad_norm": 0.24260582029819489,
      "learning_rate": 4.819277108433735e-06,
      "loss": 1.9658,
      "step": 40
    },
    {
      "epoch": 0.03616636528028933,
      "grad_norm": 0.22661735117435455,
      "learning_rate": 6.024096385542169e-06,
      "loss": 2.0958,
      "step": 50
    },
    {
      "epoch": 0.0433996383363472,
      "grad_norm": 0.23279574513435364,
      "learning_rate": 7.228915662650602e-06,
      "loss": 2.0017,
      "step": 60
    },
    {
      "epoch": 0.05063291139240506,
      "grad_norm": 0.3357563018798828,
      "learning_rate": 8.433734939759036e-06,
      "loss": 2.1195,
      "step": 70
    },
    {
      "epoch": 0.05786618444846293,
      "grad_norm": 0.2501360774040222,
      "learning_rate": 9.63855421686747e-06,
      "loss": 1.9281,
      "step": 80
    },
    {
      "epoch": 0.0650994575045208,
      "grad_norm": 0.32015717029571533,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 2.0112,
      "step": 90
    },
    {
      "epoch": 0.07233273056057866,
      "grad_norm": 0.28841662406921387,
      "learning_rate": 1.2048192771084338e-05,
      "loss": 1.932,
      "step": 100
    },
    {
      "epoch": 0.07956600361663653,
      "grad_norm": 0.40098002552986145,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 1.9444,
      "step": 110
    },
    {
      "epoch": 0.0867992766726944,
      "grad_norm": 0.3433424234390259,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 1.9729,
      "step": 120
    },
    {
      "epoch": 0.09403254972875226,
      "grad_norm": 0.4617822766304016,
      "learning_rate": 1.566265060240964e-05,
      "loss": 2.0552,
      "step": 130
    },
    {
      "epoch": 0.10126582278481013,
      "grad_norm": 0.47761526703834534,
      "learning_rate": 1.6867469879518073e-05,
      "loss": 1.9043,
      "step": 140
    },
    {
      "epoch": 0.10849909584086799,
      "grad_norm": 0.40047159790992737,
      "learning_rate": 1.8072289156626505e-05,
      "loss": 1.8003,
      "step": 150
    },
    {
      "epoch": 0.11573236889692586,
      "grad_norm": 0.3583082854747772,
      "learning_rate": 1.927710843373494e-05,
      "loss": 1.7492,
      "step": 160
    },
    {
      "epoch": 0.12296564195298372,
      "grad_norm": 0.4389243721961975,
      "learning_rate": 2.0481927710843373e-05,
      "loss": 1.8608,
      "step": 170
    },
    {
      "epoch": 0.1301989150090416,
      "grad_norm": 0.4781053066253662,
      "learning_rate": 2.168674698795181e-05,
      "loss": 1.758,
      "step": 180
    },
    {
      "epoch": 0.13743218806509946,
      "grad_norm": 0.5707418322563171,
      "learning_rate": 2.289156626506024e-05,
      "loss": 1.6533,
      "step": 190
    },
    {
      "epoch": 0.14466546112115733,
      "grad_norm": 0.6380345225334167,
      "learning_rate": 2.4096385542168677e-05,
      "loss": 1.5861,
      "step": 200
    },
    {
      "epoch": 0.1518987341772152,
      "grad_norm": 0.6642054915428162,
      "learning_rate": 2.530120481927711e-05,
      "loss": 1.4512,
      "step": 210
    },
    {
      "epoch": 0.15913200723327306,
      "grad_norm": 0.7920821309089661,
      "learning_rate": 2.6506024096385545e-05,
      "loss": 1.3854,
      "step": 220
    },
    {
      "epoch": 0.16636528028933092,
      "grad_norm": 0.8014837503433228,
      "learning_rate": 2.7710843373493977e-05,
      "loss": 1.224,
      "step": 230
    },
    {
      "epoch": 0.1735985533453888,
      "grad_norm": 1.066171646118164,
      "learning_rate": 2.891566265060241e-05,
      "loss": 1.1666,
      "step": 240
    },
    {
      "epoch": 0.18083182640144665,
      "grad_norm": 0.9107170701026917,
      "learning_rate": 3.012048192771085e-05,
      "loss": 0.9471,
      "step": 250
    },
    {
      "epoch": 0.18806509945750452,
      "grad_norm": 1.0190649032592773,
      "learning_rate": 3.132530120481928e-05,
      "loss": 0.8194,
      "step": 260
    },
    {
      "epoch": 0.19529837251356238,
      "grad_norm": 1.169699788093567,
      "learning_rate": 3.253012048192771e-05,
      "loss": 0.7378,
      "step": 270
    },
    {
      "epoch": 0.20253164556962025,
      "grad_norm": 1.4749161005020142,
      "learning_rate": 3.3734939759036146e-05,
      "loss": 0.6284,
      "step": 280
    },
    {
      "epoch": 0.20976491862567812,
      "grad_norm": 0.6658755540847778,
      "learning_rate": 3.4939759036144585e-05,
      "loss": 0.5452,
      "step": 290
    },
    {
      "epoch": 0.21699819168173598,
      "grad_norm": 0.7612382769584656,
      "learning_rate": 3.614457831325301e-05,
      "loss": 0.5129,
      "step": 300
    },
    {
      "epoch": 0.22423146473779385,
      "grad_norm": 0.6780254244804382,
      "learning_rate": 3.734939759036144e-05,
      "loss": 0.4574,
      "step": 310
    },
    {
      "epoch": 0.2314647377938517,
      "grad_norm": 0.7347803711891174,
      "learning_rate": 3.855421686746988e-05,
      "loss": 0.4395,
      "step": 320
    },
    {
      "epoch": 0.23869801084990958,
      "grad_norm": 1.0338057279586792,
      "learning_rate": 3.9759036144578314e-05,
      "loss": 0.3966,
      "step": 330
    },
    {
      "epoch": 0.24593128390596744,
      "grad_norm": 0.6612870693206787,
      "learning_rate": 4.0963855421686746e-05,
      "loss": 0.4128,
      "step": 340
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.8019009232521057,
      "learning_rate": 4.2168674698795186e-05,
      "loss": 0.4132,
      "step": 350
    },
    {
      "epoch": 0.2603978300180832,
      "grad_norm": 0.7299871444702148,
      "learning_rate": 4.337349397590362e-05,
      "loss": 0.3512,
      "step": 360
    },
    {
      "epoch": 0.26763110307414106,
      "grad_norm": 0.753024697303772,
      "learning_rate": 4.457831325301205e-05,
      "loss": 0.3863,
      "step": 370
    },
    {
      "epoch": 0.27486437613019893,
      "grad_norm": 0.9461882710456848,
      "learning_rate": 4.578313253012048e-05,
      "loss": 0.3575,
      "step": 380
    },
    {
      "epoch": 0.2820976491862568,
      "grad_norm": 0.9971913695335388,
      "learning_rate": 4.698795180722892e-05,
      "loss": 0.3994,
      "step": 390
    },
    {
      "epoch": 0.28933092224231466,
      "grad_norm": 0.5197072625160217,
      "learning_rate": 4.8192771084337354e-05,
      "loss": 0.3582,
      "step": 400
    },
    {
      "epoch": 0.2965641952983725,
      "grad_norm": 1.0796215534210205,
      "learning_rate": 4.9397590361445786e-05,
      "loss": 0.3257,
      "step": 410
    },
    {
      "epoch": 0.3037974683544304,
      "grad_norm": 1.338003396987915,
      "learning_rate": 4.9932993835432864e-05,
      "loss": 0.3168,
      "step": 420
    },
    {
      "epoch": 0.31103074141048825,
      "grad_norm": 0.7899011969566345,
      "learning_rate": 4.979898150629858e-05,
      "loss": 0.3918,
      "step": 430
    },
    {
      "epoch": 0.3182640144665461,
      "grad_norm": 1.0217535495758057,
      "learning_rate": 4.96649691771643e-05,
      "loss": 0.3513,
      "step": 440
    },
    {
      "epoch": 0.325497287522604,
      "grad_norm": 0.3745138943195343,
      "learning_rate": 4.953095684803002e-05,
      "loss": 0.3011,
      "step": 450
    },
    {
      "epoch": 0.33273056057866185,
      "grad_norm": 0.4071778655052185,
      "learning_rate": 4.939694451889574e-05,
      "loss": 0.3227,
      "step": 460
    },
    {
      "epoch": 0.3399638336347197,
      "grad_norm": 1.1186960935592651,
      "learning_rate": 4.926293218976146e-05,
      "loss": 0.3221,
      "step": 470
    },
    {
      "epoch": 0.3471971066907776,
      "grad_norm": 1.6667548418045044,
      "learning_rate": 4.9128919860627184e-05,
      "loss": 0.3344,
      "step": 480
    },
    {
      "epoch": 0.35443037974683544,
      "grad_norm": 0.8135351538658142,
      "learning_rate": 4.89949075314929e-05,
      "loss": 0.3118,
      "step": 490
    },
    {
      "epoch": 0.3616636528028933,
      "grad_norm": 0.8548212051391602,
      "learning_rate": 4.886089520235862e-05,
      "loss": 0.2927,
      "step": 500
    },
    {
      "epoch": 0.3688969258589512,
      "grad_norm": 0.6323423385620117,
      "learning_rate": 4.872688287322434e-05,
      "loss": 0.2828,
      "step": 510
    },
    {
      "epoch": 0.37613019891500904,
      "grad_norm": 1.3829048871994019,
      "learning_rate": 4.859287054409006e-05,
      "loss": 0.2964,
      "step": 520
    },
    {
      "epoch": 0.3833634719710669,
      "grad_norm": 0.6435466408729553,
      "learning_rate": 4.8458858214955776e-05,
      "loss": 0.2908,
      "step": 530
    },
    {
      "epoch": 0.39059674502712477,
      "grad_norm": 0.8213828802108765,
      "learning_rate": 4.83248458858215e-05,
      "loss": 0.2724,
      "step": 540
    },
    {
      "epoch": 0.39783001808318263,
      "grad_norm": 0.4184046685695648,
      "learning_rate": 4.8190833556687214e-05,
      "loss": 0.3156,
      "step": 550
    },
    {
      "epoch": 0.4050632911392405,
      "grad_norm": 1.403093934059143,
      "learning_rate": 4.805682122755294e-05,
      "loss": 0.3078,
      "step": 560
    },
    {
      "epoch": 0.41229656419529837,
      "grad_norm": 0.4661906957626343,
      "learning_rate": 4.792280889841866e-05,
      "loss": 0.3201,
      "step": 570
    },
    {
      "epoch": 0.41952983725135623,
      "grad_norm": 0.8681190013885498,
      "learning_rate": 4.778879656928438e-05,
      "loss": 0.2822,
      "step": 580
    },
    {
      "epoch": 0.4267631103074141,
      "grad_norm": 0.5824540853500366,
      "learning_rate": 4.7654784240150096e-05,
      "loss": 0.3284,
      "step": 590
    },
    {
      "epoch": 0.43399638336347196,
      "grad_norm": 0.4532422721385956,
      "learning_rate": 4.752077191101582e-05,
      "loss": 0.3087,
      "step": 600
    },
    {
      "epoch": 0.4412296564195298,
      "grad_norm": 0.5527794361114502,
      "learning_rate": 4.7386759581881534e-05,
      "loss": 0.2733,
      "step": 610
    },
    {
      "epoch": 0.4484629294755877,
      "grad_norm": 0.6270887851715088,
      "learning_rate": 4.7252747252747257e-05,
      "loss": 0.3054,
      "step": 620
    },
    {
      "epoch": 0.45569620253164556,
      "grad_norm": 1.0777771472930908,
      "learning_rate": 4.711873492361297e-05,
      "loss": 0.3049,
      "step": 630
    },
    {
      "epoch": 0.4629294755877034,
      "grad_norm": 0.9255538582801819,
      "learning_rate": 4.699812382739212e-05,
      "loss": 0.2915,
      "step": 640
    },
    {
      "epoch": 0.4701627486437613,
      "grad_norm": 0.7370269894599915,
      "learning_rate": 4.686411149825784e-05,
      "loss": 0.2559,
      "step": 650
    },
    {
      "epoch": 0.47739602169981915,
      "grad_norm": 0.690119206905365,
      "learning_rate": 4.673009916912356e-05,
      "loss": 0.2718,
      "step": 660
    },
    {
      "epoch": 0.484629294755877,
      "grad_norm": 0.7215714454650879,
      "learning_rate": 4.6596086839989287e-05,
      "loss": 0.3109,
      "step": 670
    },
    {
      "epoch": 0.4918625678119349,
      "grad_norm": 1.1671674251556396,
      "learning_rate": 4.6462074510855e-05,
      "loss": 0.2482,
      "step": 680
    },
    {
      "epoch": 0.49909584086799275,
      "grad_norm": 0.8461971282958984,
      "learning_rate": 4.6328062181720725e-05,
      "loss": 0.2327,
      "step": 690
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.750868558883667,
      "learning_rate": 4.619404985258644e-05,
      "loss": 0.2887,
      "step": 700
    },
    {
      "epoch": 0.5135623869801085,
      "grad_norm": 0.5873847603797913,
      "learning_rate": 4.606003752345216e-05,
      "loss": 0.241,
      "step": 710
    },
    {
      "epoch": 0.5207956600361664,
      "grad_norm": 1.8332403898239136,
      "learning_rate": 4.592602519431788e-05,
      "loss": 0.2397,
      "step": 720
    },
    {
      "epoch": 0.5280289330922242,
      "grad_norm": 0.9238295555114746,
      "learning_rate": 4.57920128651836e-05,
      "loss": 0.2997,
      "step": 730
    },
    {
      "epoch": 0.5352622061482821,
      "grad_norm": 0.6420412659645081,
      "learning_rate": 4.5658000536049316e-05,
      "loss": 0.2474,
      "step": 740
    },
    {
      "epoch": 0.5424954792043399,
      "grad_norm": 0.661214292049408,
      "learning_rate": 4.552398820691504e-05,
      "loss": 0.2849,
      "step": 750
    },
    {
      "epoch": 0.5497287522603979,
      "grad_norm": 1.7755920886993408,
      "learning_rate": 4.538997587778076e-05,
      "loss": 0.2707,
      "step": 760
    },
    {
      "epoch": 0.5569620253164557,
      "grad_norm": 0.7504300475120544,
      "learning_rate": 4.5255963548646476e-05,
      "loss": 0.2714,
      "step": 770
    },
    {
      "epoch": 0.5641952983725136,
      "grad_norm": 1.6952273845672607,
      "learning_rate": 4.51219512195122e-05,
      "loss": 0.2395,
      "step": 780
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 1.1162561178207397,
      "learning_rate": 4.4987938890377914e-05,
      "loss": 0.2722,
      "step": 790
    },
    {
      "epoch": 0.5786618444846293,
      "grad_norm": 0.8023176789283752,
      "learning_rate": 4.4853926561243637e-05,
      "loss": 0.2584,
      "step": 800
    },
    {
      "epoch": 0.5858951175406871,
      "grad_norm": 1.3645131587982178,
      "learning_rate": 4.471991423210936e-05,
      "loss": 0.2395,
      "step": 810
    },
    {
      "epoch": 0.593128390596745,
      "grad_norm": 1.841072678565979,
      "learning_rate": 4.4585901902975074e-05,
      "loss": 0.2286,
      "step": 820
    },
    {
      "epoch": 0.6003616636528029,
      "grad_norm": 1.248021125793457,
      "learning_rate": 4.44518895738408e-05,
      "loss": 0.2625,
      "step": 830
    },
    {
      "epoch": 0.6075949367088608,
      "grad_norm": 1.2779591083526611,
      "learning_rate": 4.431787724470651e-05,
      "loss": 0.2718,
      "step": 840
    },
    {
      "epoch": 0.6148282097649186,
      "grad_norm": 0.572695255279541,
      "learning_rate": 4.4183864915572235e-05,
      "loss": 0.2588,
      "step": 850
    },
    {
      "epoch": 0.6220614828209765,
      "grad_norm": 0.9359967112541199,
      "learning_rate": 4.404985258643796e-05,
      "loss": 0.2415,
      "step": 860
    },
    {
      "epoch": 0.6292947558770343,
      "grad_norm": 0.9464649558067322,
      "learning_rate": 4.391584025730367e-05,
      "loss": 0.2373,
      "step": 870
    },
    {
      "epoch": 0.6365280289330922,
      "grad_norm": 0.5109188556671143,
      "learning_rate": 4.3781827928169395e-05,
      "loss": 0.2411,
      "step": 880
    },
    {
      "epoch": 0.64376130198915,
      "grad_norm": 0.716219425201416,
      "learning_rate": 4.364781559903511e-05,
      "loss": 0.2282,
      "step": 890
    },
    {
      "epoch": 0.650994575045208,
      "grad_norm": 0.6313747763633728,
      "learning_rate": 4.351380326990083e-05,
      "loss": 0.2455,
      "step": 900
    },
    {
      "epoch": 0.6582278481012658,
      "grad_norm": 0.7226805686950684,
      "learning_rate": 4.337979094076655e-05,
      "loss": 0.2794,
      "step": 910
    },
    {
      "epoch": 0.6654611211573237,
      "grad_norm": 0.44433343410491943,
      "learning_rate": 4.324577861163227e-05,
      "loss": 0.2584,
      "step": 920
    },
    {
      "epoch": 0.6726943942133815,
      "grad_norm": 1.3308775424957275,
      "learning_rate": 4.3111766282497987e-05,
      "loss": 0.2369,
      "step": 930
    },
    {
      "epoch": 0.6799276672694394,
      "grad_norm": 0.8205574750900269,
      "learning_rate": 4.2977753953363716e-05,
      "loss": 0.2335,
      "step": 940
    },
    {
      "epoch": 0.6871609403254972,
      "grad_norm": 0.7144971489906311,
      "learning_rate": 4.284374162422943e-05,
      "loss": 0.2403,
      "step": 950
    },
    {
      "epoch": 0.6943942133815552,
      "grad_norm": 0.9699015021324158,
      "learning_rate": 4.2709729295095154e-05,
      "loss": 0.2408,
      "step": 960
    },
    {
      "epoch": 0.701627486437613,
      "grad_norm": 0.5334663987159729,
      "learning_rate": 4.257571696596087e-05,
      "loss": 0.2385,
      "step": 970
    },
    {
      "epoch": 0.7088607594936709,
      "grad_norm": 1.198240041732788,
      "learning_rate": 4.244170463682659e-05,
      "loss": 0.248,
      "step": 980
    },
    {
      "epoch": 0.7160940325497287,
      "grad_norm": 0.6772853136062622,
      "learning_rate": 4.230769230769231e-05,
      "loss": 0.2498,
      "step": 990
    },
    {
      "epoch": 0.7233273056057866,
      "grad_norm": 0.4530617594718933,
      "learning_rate": 4.217367997855803e-05,
      "loss": 0.2606,
      "step": 1000
    },
    {
      "epoch": 0.7305605786618445,
      "grad_norm": 0.7752683758735657,
      "learning_rate": 4.2039667649423745e-05,
      "loss": 0.211,
      "step": 1010
    },
    {
      "epoch": 0.7377938517179023,
      "grad_norm": 1.2194914817810059,
      "learning_rate": 4.190565532028947e-05,
      "loss": 0.2668,
      "step": 1020
    },
    {
      "epoch": 0.7450271247739603,
      "grad_norm": 0.6626141667366028,
      "learning_rate": 4.177164299115519e-05,
      "loss": 0.2417,
      "step": 1030
    },
    {
      "epoch": 0.7522603978300181,
      "grad_norm": 0.8727081418037415,
      "learning_rate": 4.163763066202091e-05,
      "loss": 0.2489,
      "step": 1040
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.8564244508743286,
      "learning_rate": 4.150361833288663e-05,
      "loss": 0.2039,
      "step": 1050
    },
    {
      "epoch": 0.7667269439421338,
      "grad_norm": 0.6343992352485657,
      "learning_rate": 4.136960600375235e-05,
      "loss": 0.2242,
      "step": 1060
    },
    {
      "epoch": 0.7739602169981917,
      "grad_norm": 0.7396233081817627,
      "learning_rate": 4.1235593674618066e-05,
      "loss": 0.2565,
      "step": 1070
    },
    {
      "epoch": 0.7811934900542495,
      "grad_norm": 0.7027408480644226,
      "learning_rate": 4.110158134548379e-05,
      "loss": 0.2579,
      "step": 1080
    },
    {
      "epoch": 0.7884267631103075,
      "grad_norm": 0.332126259803772,
      "learning_rate": 4.0967569016349504e-05,
      "loss": 0.1958,
      "step": 1090
    },
    {
      "epoch": 0.7956600361663653,
      "grad_norm": 0.8357457518577576,
      "learning_rate": 4.0833556687215226e-05,
      "loss": 0.2785,
      "step": 1100
    },
    {
      "epoch": 0.8028933092224232,
      "grad_norm": 0.5178957581520081,
      "learning_rate": 4.069954435808094e-05,
      "loss": 0.2112,
      "step": 1110
    },
    {
      "epoch": 0.810126582278481,
      "grad_norm": 0.6464913487434387,
      "learning_rate": 4.0565532028946664e-05,
      "loss": 0.2182,
      "step": 1120
    },
    {
      "epoch": 0.8173598553345389,
      "grad_norm": 1.429192304611206,
      "learning_rate": 4.0431519699812386e-05,
      "loss": 0.249,
      "step": 1130
    },
    {
      "epoch": 0.8245931283905967,
      "grad_norm": 0.7543821334838867,
      "learning_rate": 4.029750737067811e-05,
      "loss": 0.2401,
      "step": 1140
    },
    {
      "epoch": 0.8318264014466547,
      "grad_norm": 0.6156616806983948,
      "learning_rate": 4.0163495041543824e-05,
      "loss": 0.265,
      "step": 1150
    },
    {
      "epoch": 0.8390596745027125,
      "grad_norm": 0.6240174174308777,
      "learning_rate": 4.0029482712409547e-05,
      "loss": 0.2338,
      "step": 1160
    },
    {
      "epoch": 0.8462929475587704,
      "grad_norm": 0.7756465077400208,
      "learning_rate": 3.989547038327526e-05,
      "loss": 0.2387,
      "step": 1170
    },
    {
      "epoch": 0.8535262206148282,
      "grad_norm": 0.5571498274803162,
      "learning_rate": 3.9761458054140984e-05,
      "loss": 0.2495,
      "step": 1180
    },
    {
      "epoch": 0.8607594936708861,
      "grad_norm": 0.6158565878868103,
      "learning_rate": 3.96274457250067e-05,
      "loss": 0.2379,
      "step": 1190
    },
    {
      "epoch": 0.8679927667269439,
      "grad_norm": 0.651819109916687,
      "learning_rate": 3.949343339587242e-05,
      "loss": 0.2165,
      "step": 1200
    },
    {
      "epoch": 0.8752260397830018,
      "grad_norm": 0.6675863862037659,
      "learning_rate": 3.935942106673814e-05,
      "loss": 0.2538,
      "step": 1210
    },
    {
      "epoch": 0.8824593128390597,
      "grad_norm": 0.46399471163749695,
      "learning_rate": 3.922540873760386e-05,
      "loss": 0.2499,
      "step": 1220
    },
    {
      "epoch": 0.8896925858951176,
      "grad_norm": 0.5485907793045044,
      "learning_rate": 3.909139640846958e-05,
      "loss": 0.246,
      "step": 1230
    },
    {
      "epoch": 0.8969258589511754,
      "grad_norm": 0.5153966546058655,
      "learning_rate": 3.8957384079335305e-05,
      "loss": 0.2322,
      "step": 1240
    },
    {
      "epoch": 0.9041591320072333,
      "grad_norm": 0.7550102472305298,
      "learning_rate": 3.882337175020102e-05,
      "loss": 0.2458,
      "step": 1250
    },
    {
      "epoch": 0.9113924050632911,
      "grad_norm": 0.9885342121124268,
      "learning_rate": 3.868935942106674e-05,
      "loss": 0.2541,
      "step": 1260
    },
    {
      "epoch": 0.918625678119349,
      "grad_norm": 0.6611931920051575,
      "learning_rate": 3.855534709193246e-05,
      "loss": 0.2364,
      "step": 1270
    },
    {
      "epoch": 0.9258589511754068,
      "grad_norm": 0.70868980884552,
      "learning_rate": 3.842133476279818e-05,
      "loss": 0.2038,
      "step": 1280
    },
    {
      "epoch": 0.9330922242314648,
      "grad_norm": 0.8556094765663147,
      "learning_rate": 3.8287322433663897e-05,
      "loss": 0.2379,
      "step": 1290
    },
    {
      "epoch": 0.9403254972875226,
      "grad_norm": 0.9353923201560974,
      "learning_rate": 3.815331010452962e-05,
      "loss": 0.2189,
      "step": 1300
    },
    {
      "epoch": 0.9475587703435805,
      "grad_norm": 0.9211310744285583,
      "learning_rate": 3.801929777539534e-05,
      "loss": 0.2407,
      "step": 1310
    },
    {
      "epoch": 0.9547920433996383,
      "grad_norm": 0.7036399245262146,
      "learning_rate": 3.788528544626106e-05,
      "loss": 0.2448,
      "step": 1320
    },
    {
      "epoch": 0.9620253164556962,
      "grad_norm": 0.6152032017707825,
      "learning_rate": 3.775127311712678e-05,
      "loss": 0.2231,
      "step": 1330
    },
    {
      "epoch": 0.969258589511754,
      "grad_norm": 0.9774277210235596,
      "learning_rate": 3.7617260787992495e-05,
      "loss": 0.242,
      "step": 1340
    },
    {
      "epoch": 0.976491862567812,
      "grad_norm": 1.08003830909729,
      "learning_rate": 3.748324845885822e-05,
      "loss": 0.2115,
      "step": 1350
    },
    {
      "epoch": 0.9837251356238698,
      "grad_norm": 0.8634737133979797,
      "learning_rate": 3.734923612972393e-05,
      "loss": 0.235,
      "step": 1360
    },
    {
      "epoch": 0.9909584086799277,
      "grad_norm": 0.6049680709838867,
      "learning_rate": 3.7215223800589655e-05,
      "loss": 0.2053,
      "step": 1370
    },
    {
      "epoch": 0.9981916817359855,
      "grad_norm": 0.8331637978553772,
      "learning_rate": 3.708121147145537e-05,
      "loss": 0.2315,
      "step": 1380
    },
    {
      "epoch": 0.9996383363471971,
      "eval_loss": 0.31595277786254883,
      "eval_runtime": 103.508,
      "eval_samples_per_second": 6.685,
      "eval_steps_per_second": 6.685,
      "step": 1382
    },
    {
      "epoch": 1.0054249547920433,
      "grad_norm": 0.7423516511917114,
      "learning_rate": 3.694719914232109e-05,
      "loss": 0.2415,
      "step": 1390
    },
    {
      "epoch": 1.0126582278481013,
      "grad_norm": 0.5242429375648499,
      "learning_rate": 3.6813186813186815e-05,
      "loss": 0.2109,
      "step": 1400
    },
    {
      "epoch": 1.0198915009041591,
      "grad_norm": 1.128756046295166,
      "learning_rate": 3.667917448405254e-05,
      "loss": 0.2338,
      "step": 1410
    },
    {
      "epoch": 1.027124773960217,
      "grad_norm": 0.9976669549942017,
      "learning_rate": 3.654516215491825e-05,
      "loss": 0.2451,
      "step": 1420
    },
    {
      "epoch": 1.0343580470162748,
      "grad_norm": 0.9782804250717163,
      "learning_rate": 3.6411149825783976e-05,
      "loss": 0.276,
      "step": 1430
    },
    {
      "epoch": 1.0415913200723328,
      "grad_norm": 0.5857256054878235,
      "learning_rate": 3.627713749664969e-05,
      "loss": 0.2111,
      "step": 1440
    },
    {
      "epoch": 1.0488245931283906,
      "grad_norm": 0.631039023399353,
      "learning_rate": 3.6143125167515414e-05,
      "loss": 0.2168,
      "step": 1450
    },
    {
      "epoch": 1.0560578661844484,
      "grad_norm": 0.844210147857666,
      "learning_rate": 3.600911283838113e-05,
      "loss": 0.223,
      "step": 1460
    },
    {
      "epoch": 1.0632911392405062,
      "grad_norm": 1.5963249206542969,
      "learning_rate": 3.587510050924685e-05,
      "loss": 0.2207,
      "step": 1470
    },
    {
      "epoch": 1.0705244122965643,
      "grad_norm": 1.090116262435913,
      "learning_rate": 3.574108818011257e-05,
      "loss": 0.218,
      "step": 1480
    },
    {
      "epoch": 1.077757685352622,
      "grad_norm": 1.3846204280853271,
      "learning_rate": 3.5607075850978296e-05,
      "loss": 0.2178,
      "step": 1490
    },
    {
      "epoch": 1.0849909584086799,
      "grad_norm": 1.381330966949463,
      "learning_rate": 3.547306352184401e-05,
      "loss": 0.2454,
      "step": 1500
    },
    {
      "epoch": 1.092224231464738,
      "grad_norm": 0.614983081817627,
      "learning_rate": 3.5339051192709734e-05,
      "loss": 0.2518,
      "step": 1510
    },
    {
      "epoch": 1.0994575045207957,
      "grad_norm": 0.8899112939834595,
      "learning_rate": 3.520503886357545e-05,
      "loss": 0.2556,
      "step": 1520
    },
    {
      "epoch": 1.1066907775768535,
      "grad_norm": 0.673393189907074,
      "learning_rate": 3.507102653444117e-05,
      "loss": 0.2286,
      "step": 1530
    },
    {
      "epoch": 1.1139240506329113,
      "grad_norm": 0.7186110615730286,
      "learning_rate": 3.493701420530689e-05,
      "loss": 0.2537,
      "step": 1540
    },
    {
      "epoch": 1.1211573236889691,
      "grad_norm": 0.8486864566802979,
      "learning_rate": 3.480300187617261e-05,
      "loss": 0.2684,
      "step": 1550
    },
    {
      "epoch": 1.1283905967450272,
      "grad_norm": 0.5947039127349854,
      "learning_rate": 3.4668989547038326e-05,
      "loss": 0.2012,
      "step": 1560
    },
    {
      "epoch": 1.135623869801085,
      "grad_norm": 0.9465447664260864,
      "learning_rate": 3.453497721790405e-05,
      "loss": 0.2412,
      "step": 1570
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.7196813225746155,
      "learning_rate": 3.440096488876977e-05,
      "loss": 0.2236,
      "step": 1580
    },
    {
      "epoch": 1.1500904159132008,
      "grad_norm": 0.9107735753059387,
      "learning_rate": 3.426695255963549e-05,
      "loss": 0.2453,
      "step": 1590
    },
    {
      "epoch": 1.1573236889692586,
      "grad_norm": 0.797856867313385,
      "learning_rate": 3.413294023050121e-05,
      "loss": 0.2335,
      "step": 1600
    },
    {
      "epoch": 1.1645569620253164,
      "grad_norm": 0.7004480957984924,
      "learning_rate": 3.399892790136693e-05,
      "loss": 0.2643,
      "step": 1610
    },
    {
      "epoch": 1.1717902350813743,
      "grad_norm": 0.8255200982093811,
      "learning_rate": 3.3864915572232646e-05,
      "loss": 0.2329,
      "step": 1620
    },
    {
      "epoch": 1.179023508137432,
      "grad_norm": 0.8851673603057861,
      "learning_rate": 3.373090324309837e-05,
      "loss": 0.2274,
      "step": 1630
    },
    {
      "epoch": 1.18625678119349,
      "grad_norm": 0.6658806800842285,
      "learning_rate": 3.3596890913964084e-05,
      "loss": 0.218,
      "step": 1640
    },
    {
      "epoch": 1.193490054249548,
      "grad_norm": 0.7561066746711731,
      "learning_rate": 3.3462878584829806e-05,
      "loss": 0.2167,
      "step": 1650
    },
    {
      "epoch": 1.2007233273056057,
      "grad_norm": 0.6029132604598999,
      "learning_rate": 3.332886625569552e-05,
      "loss": 0.2527,
      "step": 1660
    },
    {
      "epoch": 1.2079566003616637,
      "grad_norm": 0.7453030943870544,
      "learning_rate": 3.319485392656125e-05,
      "loss": 0.2157,
      "step": 1670
    },
    {
      "epoch": 1.2151898734177216,
      "grad_norm": 0.5607209205627441,
      "learning_rate": 3.306084159742697e-05,
      "loss": 0.2148,
      "step": 1680
    },
    {
      "epoch": 1.2224231464737794,
      "grad_norm": 1.45113205909729,
      "learning_rate": 3.292682926829269e-05,
      "loss": 0.2339,
      "step": 1690
    },
    {
      "epoch": 1.2296564195298372,
      "grad_norm": 0.9348069429397583,
      "learning_rate": 3.2792816939158405e-05,
      "loss": 0.21,
      "step": 1700
    },
    {
      "epoch": 1.2368896925858952,
      "grad_norm": 0.6382311582565308,
      "learning_rate": 3.265880461002413e-05,
      "loss": 0.2041,
      "step": 1710
    },
    {
      "epoch": 1.244122965641953,
      "grad_norm": 0.8601292967796326,
      "learning_rate": 3.252479228088984e-05,
      "loss": 0.2911,
      "step": 1720
    },
    {
      "epoch": 1.2513562386980108,
      "grad_norm": 0.6091639995574951,
      "learning_rate": 3.2390779951755565e-05,
      "loss": 0.2203,
      "step": 1730
    },
    {
      "epoch": 1.2585895117540686,
      "grad_norm": 0.4129345118999481,
      "learning_rate": 3.225676762262128e-05,
      "loss": 0.2106,
      "step": 1740
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.7456302642822266,
      "learning_rate": 3.2122755293487e-05,
      "loss": 0.2351,
      "step": 1750
    },
    {
      "epoch": 1.2730560578661845,
      "grad_norm": 0.522723913192749,
      "learning_rate": 3.198874296435272e-05,
      "loss": 0.2142,
      "step": 1760
    },
    {
      "epoch": 1.2802893309222423,
      "grad_norm": 0.8208797574043274,
      "learning_rate": 3.185473063521844e-05,
      "loss": 0.2212,
      "step": 1770
    },
    {
      "epoch": 1.2875226039783003,
      "grad_norm": 0.6599830985069275,
      "learning_rate": 3.172071830608416e-05,
      "loss": 0.2659,
      "step": 1780
    },
    {
      "epoch": 1.2947558770343581,
      "grad_norm": 0.540233314037323,
      "learning_rate": 3.158670597694988e-05,
      "loss": 0.197,
      "step": 1790
    },
    {
      "epoch": 1.301989150090416,
      "grad_norm": 0.6325926184654236,
      "learning_rate": 3.14526936478156e-05,
      "loss": 0.2154,
      "step": 1800
    },
    {
      "epoch": 1.3092224231464737,
      "grad_norm": 0.9964933395385742,
      "learning_rate": 3.131868131868132e-05,
      "loss": 0.2034,
      "step": 1810
    },
    {
      "epoch": 1.3164556962025316,
      "grad_norm": 0.6653202176094055,
      "learning_rate": 3.118466898954704e-05,
      "loss": 0.2055,
      "step": 1820
    },
    {
      "epoch": 1.3236889692585896,
      "grad_norm": 0.5943734645843506,
      "learning_rate": 3.1050656660412755e-05,
      "loss": 0.2284,
      "step": 1830
    },
    {
      "epoch": 1.3309222423146474,
      "grad_norm": 0.6944224834442139,
      "learning_rate": 3.091664433127848e-05,
      "loss": 0.2576,
      "step": 1840
    },
    {
      "epoch": 1.3381555153707052,
      "grad_norm": 0.7140095233917236,
      "learning_rate": 3.07826320021442e-05,
      "loss": 0.2194,
      "step": 1850
    },
    {
      "epoch": 1.3453887884267632,
      "grad_norm": 0.7190632224082947,
      "learning_rate": 3.064861967300992e-05,
      "loss": 0.1924,
      "step": 1860
    },
    {
      "epoch": 1.352622061482821,
      "grad_norm": 0.5755197405815125,
      "learning_rate": 3.051460734387564e-05,
      "loss": 0.1952,
      "step": 1870
    },
    {
      "epoch": 1.3598553345388789,
      "grad_norm": 0.8243202567100525,
      "learning_rate": 3.038059501474136e-05,
      "loss": 0.1975,
      "step": 1880
    },
    {
      "epoch": 1.3670886075949367,
      "grad_norm": 0.7410286068916321,
      "learning_rate": 3.024658268560708e-05,
      "loss": 0.1983,
      "step": 1890
    },
    {
      "epoch": 1.3743218806509945,
      "grad_norm": 0.8127866983413696,
      "learning_rate": 3.0112570356472798e-05,
      "loss": 0.2125,
      "step": 1900
    },
    {
      "epoch": 1.3815551537070525,
      "grad_norm": 1.041479468345642,
      "learning_rate": 2.9978558027338517e-05,
      "loss": 0.23,
      "step": 1910
    },
    {
      "epoch": 1.3887884267631103,
      "grad_norm": 0.7344696521759033,
      "learning_rate": 2.9844545698204236e-05,
      "loss": 0.2226,
      "step": 1920
    },
    {
      "epoch": 1.3960216998191681,
      "grad_norm": 0.6235588788986206,
      "learning_rate": 2.9710533369069955e-05,
      "loss": 0.2092,
      "step": 1930
    },
    {
      "epoch": 1.4032549728752262,
      "grad_norm": 0.6103919744491577,
      "learning_rate": 2.9576521039935674e-05,
      "loss": 0.2472,
      "step": 1940
    },
    {
      "epoch": 1.410488245931284,
      "grad_norm": 1.2428560256958008,
      "learning_rate": 2.9442508710801396e-05,
      "loss": 0.2201,
      "step": 1950
    },
    {
      "epoch": 1.4177215189873418,
      "grad_norm": 0.9202677011489868,
      "learning_rate": 2.9308496381667115e-05,
      "loss": 0.1632,
      "step": 1960
    },
    {
      "epoch": 1.4249547920433996,
      "grad_norm": 0.5823897123336792,
      "learning_rate": 2.9174484052532837e-05,
      "loss": 0.2141,
      "step": 1970
    },
    {
      "epoch": 1.4321880650994574,
      "grad_norm": 1.0190767049789429,
      "learning_rate": 2.9040471723398556e-05,
      "loss": 0.2225,
      "step": 1980
    },
    {
      "epoch": 1.4394213381555154,
      "grad_norm": 0.5008891224861145,
      "learning_rate": 2.8906459394264275e-05,
      "loss": 0.2012,
      "step": 1990
    },
    {
      "epoch": 1.4466546112115732,
      "grad_norm": 0.4789373576641083,
      "learning_rate": 2.8772447065129994e-05,
      "loss": 0.2247,
      "step": 2000
    },
    {
      "epoch": 1.453887884267631,
      "grad_norm": 0.7547730207443237,
      "learning_rate": 2.8638434735995713e-05,
      "loss": 0.2388,
      "step": 2010
    },
    {
      "epoch": 1.461121157323689,
      "grad_norm": 0.848646342754364,
      "learning_rate": 2.8504422406861432e-05,
      "loss": 0.2415,
      "step": 2020
    },
    {
      "epoch": 1.4683544303797469,
      "grad_norm": 0.7258052825927734,
      "learning_rate": 2.837041007772715e-05,
      "loss": 0.2232,
      "step": 2030
    },
    {
      "epoch": 1.4755877034358047,
      "grad_norm": 0.6580058336257935,
      "learning_rate": 2.8236397748592873e-05,
      "loss": 0.2162,
      "step": 2040
    },
    {
      "epoch": 1.4828209764918625,
      "grad_norm": 0.4311078190803528,
      "learning_rate": 2.8102385419458592e-05,
      "loss": 0.198,
      "step": 2050
    },
    {
      "epoch": 1.4900542495479203,
      "grad_norm": 0.9177742600440979,
      "learning_rate": 2.796837309032431e-05,
      "loss": 0.2064,
      "step": 2060
    },
    {
      "epoch": 1.4972875226039783,
      "grad_norm": 0.9020694494247437,
      "learning_rate": 2.783436076119003e-05,
      "loss": 0.1889,
      "step": 2070
    },
    {
      "epoch": 1.5045207956600362,
      "grad_norm": 0.9699457287788391,
      "learning_rate": 2.770034843205575e-05,
      "loss": 0.1911,
      "step": 2080
    },
    {
      "epoch": 1.511754068716094,
      "grad_norm": 0.8272379040718079,
      "learning_rate": 2.7566336102921468e-05,
      "loss": 0.1897,
      "step": 2090
    },
    {
      "epoch": 1.518987341772152,
      "grad_norm": 1.028607964515686,
      "learning_rate": 2.7432323773787187e-05,
      "loss": 0.2409,
      "step": 2100
    },
    {
      "epoch": 1.5262206148282098,
      "grad_norm": 1.1026793718338013,
      "learning_rate": 2.7298311444652906e-05,
      "loss": 0.2316,
      "step": 2110
    },
    {
      "epoch": 1.5334538878842676,
      "grad_norm": 0.840574324131012,
      "learning_rate": 2.7164299115518625e-05,
      "loss": 0.2142,
      "step": 2120
    },
    {
      "epoch": 1.5406871609403257,
      "grad_norm": 0.6170225739479065,
      "learning_rate": 2.703028678638435e-05,
      "loss": 0.2249,
      "step": 2130
    },
    {
      "epoch": 1.5479204339963832,
      "grad_norm": 0.5697236061096191,
      "learning_rate": 2.689627445725007e-05,
      "loss": 0.2084,
      "step": 2140
    },
    {
      "epoch": 1.5551537070524413,
      "grad_norm": 1.2660460472106934,
      "learning_rate": 2.676226212811579e-05,
      "loss": 0.184,
      "step": 2150
    },
    {
      "epoch": 1.562386980108499,
      "grad_norm": 0.5405701398849487,
      "learning_rate": 2.6628249798981508e-05,
      "loss": 0.2189,
      "step": 2160
    },
    {
      "epoch": 1.5696202531645569,
      "grad_norm": 0.8050090074539185,
      "learning_rate": 2.6494237469847227e-05,
      "loss": 0.2023,
      "step": 2170
    },
    {
      "epoch": 1.576853526220615,
      "grad_norm": 0.5178146958351135,
      "learning_rate": 2.6360225140712946e-05,
      "loss": 0.2252,
      "step": 2180
    },
    {
      "epoch": 1.5840867992766727,
      "grad_norm": 0.5162696242332458,
      "learning_rate": 2.6226212811578665e-05,
      "loss": 0.2165,
      "step": 2190
    },
    {
      "epoch": 1.5913200723327305,
      "grad_norm": 0.7668120861053467,
      "learning_rate": 2.6092200482444384e-05,
      "loss": 0.2058,
      "step": 2200
    },
    {
      "epoch": 1.5985533453887886,
      "grad_norm": 1.066850185394287,
      "learning_rate": 2.5958188153310103e-05,
      "loss": 0.208,
      "step": 2210
    },
    {
      "epoch": 1.6057866184448462,
      "grad_norm": 0.65165114402771,
      "learning_rate": 2.582417582417583e-05,
      "loss": 0.2401,
      "step": 2220
    },
    {
      "epoch": 1.6130198915009042,
      "grad_norm": 0.6778727173805237,
      "learning_rate": 2.5690163495041547e-05,
      "loss": 0.1834,
      "step": 2230
    },
    {
      "epoch": 1.620253164556962,
      "grad_norm": 0.8638041615486145,
      "learning_rate": 2.5556151165907266e-05,
      "loss": 0.2169,
      "step": 2240
    },
    {
      "epoch": 1.6274864376130198,
      "grad_norm": 0.8150834441184998,
      "learning_rate": 2.5422138836772985e-05,
      "loss": 0.2473,
      "step": 2250
    },
    {
      "epoch": 1.6347197106690778,
      "grad_norm": 0.6023833751678467,
      "learning_rate": 2.5288126507638704e-05,
      "loss": 0.2214,
      "step": 2260
    },
    {
      "epoch": 1.6419529837251357,
      "grad_norm": 0.7273944616317749,
      "learning_rate": 2.5154114178504423e-05,
      "loss": 0.2417,
      "step": 2270
    },
    {
      "epoch": 1.6491862567811935,
      "grad_norm": 0.9604803323745728,
      "learning_rate": 2.5020101849370142e-05,
      "loss": 0.2439,
      "step": 2280
    },
    {
      "epoch": 1.6564195298372515,
      "grad_norm": 0.5186142325401306,
      "learning_rate": 2.4886089520235865e-05,
      "loss": 0.1592,
      "step": 2290
    },
    {
      "epoch": 1.663652802893309,
      "grad_norm": 0.7787802219390869,
      "learning_rate": 2.4752077191101583e-05,
      "loss": 0.2171,
      "step": 2300
    },
    {
      "epoch": 1.6708860759493671,
      "grad_norm": 0.570502519607544,
      "learning_rate": 2.4618064861967302e-05,
      "loss": 0.1712,
      "step": 2310
    },
    {
      "epoch": 1.678119349005425,
      "grad_norm": 0.818587064743042,
      "learning_rate": 2.448405253283302e-05,
      "loss": 0.2188,
      "step": 2320
    },
    {
      "epoch": 1.6853526220614827,
      "grad_norm": 0.5725545883178711,
      "learning_rate": 2.435004020369874e-05,
      "loss": 0.2198,
      "step": 2330
    },
    {
      "epoch": 1.6925858951175408,
      "grad_norm": 0.7337807416915894,
      "learning_rate": 2.4216027874564463e-05,
      "loss": 0.2143,
      "step": 2340
    },
    {
      "epoch": 1.6998191681735986,
      "grad_norm": 0.7277799844741821,
      "learning_rate": 2.4082015545430182e-05,
      "loss": 0.2283,
      "step": 2350
    },
    {
      "epoch": 1.7070524412296564,
      "grad_norm": 0.5790568590164185,
      "learning_rate": 2.39480032162959e-05,
      "loss": 0.2,
      "step": 2360
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.8233261108398438,
      "learning_rate": 2.381399088716162e-05,
      "loss": 0.2029,
      "step": 2370
    },
    {
      "epoch": 1.721518987341772,
      "grad_norm": 0.8131745457649231,
      "learning_rate": 2.3679978558027342e-05,
      "loss": 0.2301,
      "step": 2380
    },
    {
      "epoch": 1.72875226039783,
      "grad_norm": 0.6009740233421326,
      "learning_rate": 2.354596622889306e-05,
      "loss": 0.2055,
      "step": 2390
    },
    {
      "epoch": 1.7359855334538878,
      "grad_norm": 0.7717772722244263,
      "learning_rate": 2.341195389975878e-05,
      "loss": 0.2205,
      "step": 2400
    },
    {
      "epoch": 1.7432188065099457,
      "grad_norm": 0.7359285354614258,
      "learning_rate": 2.32779415706245e-05,
      "loss": 0.2419,
      "step": 2410
    },
    {
      "epoch": 1.7504520795660037,
      "grad_norm": 0.6911803483963013,
      "learning_rate": 2.3143929241490218e-05,
      "loss": 0.1932,
      "step": 2420
    },
    {
      "epoch": 1.7576853526220615,
      "grad_norm": 0.8148995041847229,
      "learning_rate": 2.300991691235594e-05,
      "loss": 0.2098,
      "step": 2430
    },
    {
      "epoch": 1.7649186256781193,
      "grad_norm": 0.5745434165000916,
      "learning_rate": 2.287590458322166e-05,
      "loss": 0.2029,
      "step": 2440
    },
    {
      "epoch": 1.7721518987341773,
      "grad_norm": 0.5674307346343994,
      "learning_rate": 2.2741892254087378e-05,
      "loss": 0.2123,
      "step": 2450
    },
    {
      "epoch": 1.779385171790235,
      "grad_norm": 0.8648498058319092,
      "learning_rate": 2.2607879924953097e-05,
      "loss": 0.201,
      "step": 2460
    },
    {
      "epoch": 1.786618444846293,
      "grad_norm": 0.7385300993919373,
      "learning_rate": 2.2473867595818816e-05,
      "loss": 0.2025,
      "step": 2470
    },
    {
      "epoch": 1.7938517179023508,
      "grad_norm": 0.5955479145050049,
      "learning_rate": 2.2339855266684535e-05,
      "loss": 0.2062,
      "step": 2480
    },
    {
      "epoch": 1.8010849909584086,
      "grad_norm": 1.3097481727600098,
      "learning_rate": 2.2205842937550257e-05,
      "loss": 0.2063,
      "step": 2490
    },
    {
      "epoch": 1.8083182640144666,
      "grad_norm": 0.8225658535957336,
      "learning_rate": 2.2071830608415976e-05,
      "loss": 0.2112,
      "step": 2500
    },
    {
      "epoch": 1.8155515370705244,
      "grad_norm": 0.6771882176399231,
      "learning_rate": 2.1937818279281695e-05,
      "loss": 0.1862,
      "step": 2510
    },
    {
      "epoch": 1.8227848101265822,
      "grad_norm": 0.9902222156524658,
      "learning_rate": 2.1803805950147414e-05,
      "loss": 0.2212,
      "step": 2520
    },
    {
      "epoch": 1.8300180831826403,
      "grad_norm": 0.6164343357086182,
      "learning_rate": 2.1669793621013133e-05,
      "loss": 0.2041,
      "step": 2530
    },
    {
      "epoch": 1.837251356238698,
      "grad_norm": 0.9797788858413696,
      "learning_rate": 2.1535781291878852e-05,
      "loss": 0.2391,
      "step": 2540
    },
    {
      "epoch": 1.8444846292947559,
      "grad_norm": 0.5576661825180054,
      "learning_rate": 2.140176896274457e-05,
      "loss": 0.2268,
      "step": 2550
    },
    {
      "epoch": 1.851717902350814,
      "grad_norm": 0.745193600654602,
      "learning_rate": 2.126775663361029e-05,
      "loss": 0.1921,
      "step": 2560
    },
    {
      "epoch": 1.8589511754068715,
      "grad_norm": 0.6847861409187317,
      "learning_rate": 2.1133744304476013e-05,
      "loss": 0.2029,
      "step": 2570
    },
    {
      "epoch": 1.8661844484629295,
      "grad_norm": 0.7096017599105835,
      "learning_rate": 2.099973197534173e-05,
      "loss": 0.2205,
      "step": 2580
    },
    {
      "epoch": 1.8734177215189873,
      "grad_norm": 0.7748004198074341,
      "learning_rate": 2.086571964620745e-05,
      "loss": 0.204,
      "step": 2590
    },
    {
      "epoch": 1.8806509945750451,
      "grad_norm": 0.8049401640892029,
      "learning_rate": 2.073170731707317e-05,
      "loss": 0.2203,
      "step": 2600
    },
    {
      "epoch": 1.8878842676311032,
      "grad_norm": 0.4968940019607544,
      "learning_rate": 2.0597694987938892e-05,
      "loss": 0.1872,
      "step": 2610
    },
    {
      "epoch": 1.895117540687161,
      "grad_norm": 0.6435350775718689,
      "learning_rate": 2.046368265880461e-05,
      "loss": 0.1882,
      "step": 2620
    },
    {
      "epoch": 1.9023508137432188,
      "grad_norm": 0.7073442935943604,
      "learning_rate": 2.032967032967033e-05,
      "loss": 0.2176,
      "step": 2630
    },
    {
      "epoch": 1.9095840867992768,
      "grad_norm": 0.9573593139648438,
      "learning_rate": 2.019565800053605e-05,
      "loss": 0.2095,
      "step": 2640
    },
    {
      "epoch": 1.9168173598553344,
      "grad_norm": 0.6015340089797974,
      "learning_rate": 2.0061645671401768e-05,
      "loss": 0.2043,
      "step": 2650
    },
    {
      "epoch": 1.9240506329113924,
      "grad_norm": 0.5147665739059448,
      "learning_rate": 1.992763334226749e-05,
      "loss": 0.2216,
      "step": 2660
    },
    {
      "epoch": 1.9312839059674503,
      "grad_norm": 0.7970046997070312,
      "learning_rate": 1.979362101313321e-05,
      "loss": 0.2133,
      "step": 2670
    },
    {
      "epoch": 1.938517179023508,
      "grad_norm": 0.7718749642372131,
      "learning_rate": 1.9659608683998928e-05,
      "loss": 0.2186,
      "step": 2680
    },
    {
      "epoch": 1.945750452079566,
      "grad_norm": 0.7624858617782593,
      "learning_rate": 1.9525596354864647e-05,
      "loss": 0.2081,
      "step": 2690
    },
    {
      "epoch": 1.952983725135624,
      "grad_norm": 1.2039698362350464,
      "learning_rate": 1.939158402573037e-05,
      "loss": 0.2187,
      "step": 2700
    },
    {
      "epoch": 1.9602169981916817,
      "grad_norm": 0.8306654095649719,
      "learning_rate": 1.925757169659609e-05,
      "loss": 0.206,
      "step": 2710
    },
    {
      "epoch": 1.9674502712477397,
      "grad_norm": 0.7454043626785278,
      "learning_rate": 1.9123559367461807e-05,
      "loss": 0.1963,
      "step": 2720
    },
    {
      "epoch": 1.9746835443037973,
      "grad_norm": 0.6422552466392517,
      "learning_rate": 1.8989547038327526e-05,
      "loss": 0.2093,
      "step": 2730
    },
    {
      "epoch": 1.9819168173598554,
      "grad_norm": 0.6857679486274719,
      "learning_rate": 1.8855534709193245e-05,
      "loss": 0.2116,
      "step": 2740
    },
    {
      "epoch": 1.9891500904159132,
      "grad_norm": 0.7447910904884338,
      "learning_rate": 1.8721522380058968e-05,
      "loss": 0.2246,
      "step": 2750
    },
    {
      "epoch": 1.996383363471971,
      "grad_norm": 0.6056234836578369,
      "learning_rate": 1.8587510050924687e-05,
      "loss": 0.214,
      "step": 2760
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.28702783584594727,
      "eval_runtime": 103.4439,
      "eval_samples_per_second": 6.69,
      "eval_steps_per_second": 6.69,
      "step": 2765
    },
    {
      "epoch": 2.003616636528029,
      "grad_norm": 0.5200974941253662,
      "learning_rate": 1.8453497721790406e-05,
      "loss": 0.2315,
      "step": 2770
    },
    {
      "epoch": 2.0108499095840866,
      "grad_norm": 0.6485161781311035,
      "learning_rate": 1.8319485392656124e-05,
      "loss": 0.176,
      "step": 2780
    },
    {
      "epoch": 2.0180831826401446,
      "grad_norm": 0.6827544569969177,
      "learning_rate": 1.8185473063521847e-05,
      "loss": 0.2349,
      "step": 2790
    },
    {
      "epoch": 2.0253164556962027,
      "grad_norm": 0.6611039042472839,
      "learning_rate": 1.8051460734387566e-05,
      "loss": 0.2214,
      "step": 2800
    },
    {
      "epoch": 2.0325497287522603,
      "grad_norm": 1.0377867221832275,
      "learning_rate": 1.7917448405253285e-05,
      "loss": 0.2108,
      "step": 2810
    },
    {
      "epoch": 2.0397830018083183,
      "grad_norm": 0.8206525444984436,
      "learning_rate": 1.7783436076119004e-05,
      "loss": 0.2088,
      "step": 2820
    },
    {
      "epoch": 2.0470162748643763,
      "grad_norm": 0.7542048692703247,
      "learning_rate": 1.7649423746984723e-05,
      "loss": 0.1896,
      "step": 2830
    },
    {
      "epoch": 2.054249547920434,
      "grad_norm": 0.9255654811859131,
      "learning_rate": 1.7515411417850445e-05,
      "loss": 0.2484,
      "step": 2840
    },
    {
      "epoch": 2.061482820976492,
      "grad_norm": 0.7357693314552307,
      "learning_rate": 1.7381399088716164e-05,
      "loss": 0.2001,
      "step": 2850
    },
    {
      "epoch": 2.0687160940325495,
      "grad_norm": 0.5439627766609192,
      "learning_rate": 1.7247386759581883e-05,
      "loss": 0.1941,
      "step": 2860
    },
    {
      "epoch": 2.0759493670886076,
      "grad_norm": 0.6545450687408447,
      "learning_rate": 1.7113374430447602e-05,
      "loss": 0.2454,
      "step": 2870
    },
    {
      "epoch": 2.0831826401446656,
      "grad_norm": 1.0102989673614502,
      "learning_rate": 1.697936210131332e-05,
      "loss": 0.1743,
      "step": 2880
    },
    {
      "epoch": 2.090415913200723,
      "grad_norm": 1.140540599822998,
      "learning_rate": 1.6845349772179043e-05,
      "loss": 0.2251,
      "step": 2890
    },
    {
      "epoch": 2.097649186256781,
      "grad_norm": 0.7660875916481018,
      "learning_rate": 1.6711337443044762e-05,
      "loss": 0.1825,
      "step": 2900
    },
    {
      "epoch": 2.1048824593128392,
      "grad_norm": 0.8472743630409241,
      "learning_rate": 1.657732511391048e-05,
      "loss": 0.1991,
      "step": 2910
    },
    {
      "epoch": 2.112115732368897,
      "grad_norm": 0.8453066945075989,
      "learning_rate": 1.64433127847762e-05,
      "loss": 0.2043,
      "step": 2920
    },
    {
      "epoch": 2.119349005424955,
      "grad_norm": 0.9697322249412537,
      "learning_rate": 1.6309300455641923e-05,
      "loss": 0.1917,
      "step": 2930
    },
    {
      "epoch": 2.1265822784810124,
      "grad_norm": 0.7036099433898926,
      "learning_rate": 1.617528812650764e-05,
      "loss": 0.2311,
      "step": 2940
    },
    {
      "epoch": 2.1338155515370705,
      "grad_norm": 0.6158934831619263,
      "learning_rate": 1.604127579737336e-05,
      "loss": 0.1942,
      "step": 2950
    },
    {
      "epoch": 2.1410488245931285,
      "grad_norm": 0.9134772419929504,
      "learning_rate": 1.590726346823908e-05,
      "loss": 0.204,
      "step": 2960
    },
    {
      "epoch": 2.148282097649186,
      "grad_norm": 0.7039419412612915,
      "learning_rate": 1.57732511391048e-05,
      "loss": 0.2052,
      "step": 2970
    },
    {
      "epoch": 2.155515370705244,
      "grad_norm": 0.8268828988075256,
      "learning_rate": 1.5639238809970517e-05,
      "loss": 0.2172,
      "step": 2980
    },
    {
      "epoch": 2.162748643761302,
      "grad_norm": 0.6557756066322327,
      "learning_rate": 1.5505226480836236e-05,
      "loss": 0.2449,
      "step": 2990
    },
    {
      "epoch": 2.1699819168173597,
      "grad_norm": 0.7118065357208252,
      "learning_rate": 1.5371214151701955e-05,
      "loss": 0.1722,
      "step": 3000
    },
    {
      "epoch": 2.1772151898734178,
      "grad_norm": 0.575067400932312,
      "learning_rate": 1.5237201822567676e-05,
      "loss": 0.1999,
      "step": 3010
    },
    {
      "epoch": 2.184448462929476,
      "grad_norm": 0.583156943321228,
      "learning_rate": 1.5103189493433398e-05,
      "loss": 0.1803,
      "step": 3020
    },
    {
      "epoch": 2.1916817359855334,
      "grad_norm": 0.8401907086372375,
      "learning_rate": 1.4969177164299117e-05,
      "loss": 0.2172,
      "step": 3030
    },
    {
      "epoch": 2.1989150090415914,
      "grad_norm": 0.6445108652114868,
      "learning_rate": 1.4835164835164836e-05,
      "loss": 0.2321,
      "step": 3040
    },
    {
      "epoch": 2.206148282097649,
      "grad_norm": 1.080910563468933,
      "learning_rate": 1.4701152506030555e-05,
      "loss": 0.2037,
      "step": 3050
    },
    {
      "epoch": 2.213381555153707,
      "grad_norm": 0.787616491317749,
      "learning_rate": 1.4567140176896274e-05,
      "loss": 0.2095,
      "step": 3060
    },
    {
      "epoch": 2.220614828209765,
      "grad_norm": 0.47032639384269714,
      "learning_rate": 1.4433127847761997e-05,
      "loss": 0.1966,
      "step": 3070
    },
    {
      "epoch": 2.2278481012658227,
      "grad_norm": 0.6891705989837646,
      "learning_rate": 1.4299115518627716e-05,
      "loss": 0.2256,
      "step": 3080
    },
    {
      "epoch": 2.2350813743218807,
      "grad_norm": 1.183719515800476,
      "learning_rate": 1.4165103189493435e-05,
      "loss": 0.1866,
      "step": 3090
    },
    {
      "epoch": 2.2423146473779383,
      "grad_norm": 0.7512016892433167,
      "learning_rate": 1.4031090860359154e-05,
      "loss": 0.1934,
      "step": 3100
    },
    {
      "epoch": 2.2495479204339963,
      "grad_norm": 0.749311625957489,
      "learning_rate": 1.3897078531224874e-05,
      "loss": 0.2088,
      "step": 3110
    },
    {
      "epoch": 2.2567811934900543,
      "grad_norm": 0.8321534991264343,
      "learning_rate": 1.3763066202090593e-05,
      "loss": 0.1923,
      "step": 3120
    },
    {
      "epoch": 2.264014466546112,
      "grad_norm": 0.8591716885566711,
      "learning_rate": 1.3629053872956312e-05,
      "loss": 0.1973,
      "step": 3130
    },
    {
      "epoch": 2.27124773960217,
      "grad_norm": 1.2724485397338867,
      "learning_rate": 1.3495041543822031e-05,
      "loss": 0.197,
      "step": 3140
    },
    {
      "epoch": 2.278481012658228,
      "grad_norm": 0.8790555596351624,
      "learning_rate": 1.336102921468775e-05,
      "loss": 0.201,
      "step": 3150
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.9125410318374634,
      "learning_rate": 1.3227016885553472e-05,
      "loss": 0.2186,
      "step": 3160
    },
    {
      "epoch": 2.2929475587703436,
      "grad_norm": 0.574574887752533,
      "learning_rate": 1.3093004556419191e-05,
      "loss": 0.2062,
      "step": 3170
    },
    {
      "epoch": 2.3001808318264017,
      "grad_norm": 0.5792120695114136,
      "learning_rate": 1.295899222728491e-05,
      "loss": 0.2201,
      "step": 3180
    },
    {
      "epoch": 2.3074141048824592,
      "grad_norm": 0.8359670042991638,
      "learning_rate": 1.282497989815063e-05,
      "loss": 0.2068,
      "step": 3190
    },
    {
      "epoch": 2.3146473779385173,
      "grad_norm": 0.7617717385292053,
      "learning_rate": 1.2690967569016348e-05,
      "loss": 0.2008,
      "step": 3200
    },
    {
      "epoch": 2.321880650994575,
      "grad_norm": 0.5860282182693481,
      "learning_rate": 1.255695523988207e-05,
      "loss": 0.2036,
      "step": 3210
    },
    {
      "epoch": 2.329113924050633,
      "grad_norm": 0.48248541355133057,
      "learning_rate": 1.242294291074779e-05,
      "loss": 0.2542,
      "step": 3220
    },
    {
      "epoch": 2.336347197106691,
      "grad_norm": 0.9033003449440002,
      "learning_rate": 1.2288930581613509e-05,
      "loss": 0.2048,
      "step": 3230
    },
    {
      "epoch": 2.3435804701627485,
      "grad_norm": 0.6013076305389404,
      "learning_rate": 1.215491825247923e-05,
      "loss": 0.1815,
      "step": 3240
    },
    {
      "epoch": 2.3508137432188065,
      "grad_norm": 0.8120284676551819,
      "learning_rate": 1.2020905923344948e-05,
      "loss": 0.2193,
      "step": 3250
    },
    {
      "epoch": 2.358047016274864,
      "grad_norm": 1.0421531200408936,
      "learning_rate": 1.1886893594210669e-05,
      "loss": 0.2062,
      "step": 3260
    },
    {
      "epoch": 2.365280289330922,
      "grad_norm": 0.7044607400894165,
      "learning_rate": 1.1752881265076388e-05,
      "loss": 0.215,
      "step": 3270
    },
    {
      "epoch": 2.37251356238698,
      "grad_norm": 0.7002025246620178,
      "learning_rate": 1.1618868935942107e-05,
      "loss": 0.2043,
      "step": 3280
    },
    {
      "epoch": 2.379746835443038,
      "grad_norm": 1.0052249431610107,
      "learning_rate": 1.1484856606807827e-05,
      "loss": 0.2053,
      "step": 3290
    },
    {
      "epoch": 2.386980108499096,
      "grad_norm": 0.7694260478019714,
      "learning_rate": 1.1350844277673546e-05,
      "loss": 0.2011,
      "step": 3300
    },
    {
      "epoch": 2.394213381555154,
      "grad_norm": 1.0144497156143188,
      "learning_rate": 1.1216831948539267e-05,
      "loss": 0.2247,
      "step": 3310
    },
    {
      "epoch": 2.4014466546112114,
      "grad_norm": 0.8140307664871216,
      "learning_rate": 1.1082819619404986e-05,
      "loss": 0.2079,
      "step": 3320
    },
    {
      "epoch": 2.4086799276672695,
      "grad_norm": 0.6205984950065613,
      "learning_rate": 1.0948807290270707e-05,
      "loss": 0.2003,
      "step": 3330
    },
    {
      "epoch": 2.4159132007233275,
      "grad_norm": 0.9165537357330322,
      "learning_rate": 1.0814794961136426e-05,
      "loss": 0.2178,
      "step": 3340
    },
    {
      "epoch": 2.423146473779385,
      "grad_norm": 0.8162001967430115,
      "learning_rate": 1.0680782632002145e-05,
      "loss": 0.2178,
      "step": 3350
    },
    {
      "epoch": 2.430379746835443,
      "grad_norm": 0.763603687286377,
      "learning_rate": 1.0546770302867864e-05,
      "loss": 0.2147,
      "step": 3360
    },
    {
      "epoch": 2.4376130198915007,
      "grad_norm": 0.8275467157363892,
      "learning_rate": 1.0412757973733583e-05,
      "loss": 0.2144,
      "step": 3370
    },
    {
      "epoch": 2.4448462929475587,
      "grad_norm": 0.989124059677124,
      "learning_rate": 1.0278745644599303e-05,
      "loss": 0.204,
      "step": 3380
    },
    {
      "epoch": 2.4520795660036168,
      "grad_norm": 0.7503916025161743,
      "learning_rate": 1.0144733315465022e-05,
      "loss": 0.206,
      "step": 3390
    },
    {
      "epoch": 2.4593128390596743,
      "grad_norm": 0.7827902436256409,
      "learning_rate": 1.0010720986330743e-05,
      "loss": 0.1861,
      "step": 3400
    },
    {
      "epoch": 2.4665461121157324,
      "grad_norm": 1.0820847749710083,
      "learning_rate": 9.876708657196462e-06,
      "loss": 0.187,
      "step": 3410
    },
    {
      "epoch": 2.4737793851717904,
      "grad_norm": 0.6227882504463196,
      "learning_rate": 9.742696328062183e-06,
      "loss": 0.2183,
      "step": 3420
    },
    {
      "epoch": 2.481012658227848,
      "grad_norm": 1.2480827569961548,
      "learning_rate": 9.608683998927901e-06,
      "loss": 0.2155,
      "step": 3430
    },
    {
      "epoch": 2.488245931283906,
      "grad_norm": 0.8714257478713989,
      "learning_rate": 9.47467166979362e-06,
      "loss": 0.2201,
      "step": 3440
    },
    {
      "epoch": 2.495479204339964,
      "grad_norm": 0.6411910653114319,
      "learning_rate": 9.340659340659341e-06,
      "loss": 0.208,
      "step": 3450
    },
    {
      "epoch": 2.5027124773960217,
      "grad_norm": 0.5751127600669861,
      "learning_rate": 9.20664701152506e-06,
      "loss": 0.2049,
      "step": 3460
    },
    {
      "epoch": 2.5099457504520797,
      "grad_norm": 0.7989574074745178,
      "learning_rate": 9.07263468239078e-06,
      "loss": 0.2005,
      "step": 3470
    },
    {
      "epoch": 2.5171790235081373,
      "grad_norm": 0.6929466724395752,
      "learning_rate": 8.9386223532565e-06,
      "loss": 0.1967,
      "step": 3480
    },
    {
      "epoch": 2.5244122965641953,
      "grad_norm": 1.0492256879806519,
      "learning_rate": 8.80461002412222e-06,
      "loss": 0.2304,
      "step": 3490
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.9327694773674011,
      "learning_rate": 8.67059769498794e-06,
      "loss": 0.1862,
      "step": 3500
    },
    {
      "epoch": 2.538878842676311,
      "grad_norm": 0.8197846412658691,
      "learning_rate": 8.53658536585366e-06,
      "loss": 0.199,
      "step": 3510
    },
    {
      "epoch": 2.546112115732369,
      "grad_norm": 0.5815983414649963,
      "learning_rate": 8.402573036719379e-06,
      "loss": 0.2185,
      "step": 3520
    },
    {
      "epoch": 2.5533453887884265,
      "grad_norm": 0.9056026339530945,
      "learning_rate": 8.268560707585098e-06,
      "loss": 0.202,
      "step": 3530
    },
    {
      "epoch": 2.5605786618444846,
      "grad_norm": 0.7654427886009216,
      "learning_rate": 8.134548378450819e-06,
      "loss": 0.1885,
      "step": 3540
    },
    {
      "epoch": 2.5678119349005426,
      "grad_norm": 0.7735346555709839,
      "learning_rate": 8.000536049316538e-06,
      "loss": 0.1865,
      "step": 3550
    },
    {
      "epoch": 2.5750452079566006,
      "grad_norm": 0.9061149954795837,
      "learning_rate": 7.866523720182258e-06,
      "loss": 0.1689,
      "step": 3560
    },
    {
      "epoch": 2.5822784810126582,
      "grad_norm": 0.7591092586517334,
      "learning_rate": 7.732511391047977e-06,
      "loss": 0.2161,
      "step": 3570
    },
    {
      "epoch": 2.5895117540687163,
      "grad_norm": 0.6674731969833374,
      "learning_rate": 7.598499061913697e-06,
      "loss": 0.2329,
      "step": 3580
    },
    {
      "epoch": 2.596745027124774,
      "grad_norm": 0.9454059600830078,
      "learning_rate": 7.464486732779416e-06,
      "loss": 0.2236,
      "step": 3590
    },
    {
      "epoch": 2.603978300180832,
      "grad_norm": 0.8141350746154785,
      "learning_rate": 7.330474403645135e-06,
      "loss": 0.2226,
      "step": 3600
    },
    {
      "epoch": 2.61121157323689,
      "grad_norm": 0.8249787092208862,
      "learning_rate": 7.196462074510856e-06,
      "loss": 0.1883,
      "step": 3610
    },
    {
      "epoch": 2.6184448462929475,
      "grad_norm": 1.3344546556472778,
      "learning_rate": 7.062449745376575e-06,
      "loss": 0.1841,
      "step": 3620
    },
    {
      "epoch": 2.6256781193490055,
      "grad_norm": 0.7157905697822571,
      "learning_rate": 6.928437416242295e-06,
      "loss": 0.2189,
      "step": 3630
    },
    {
      "epoch": 2.632911392405063,
      "grad_norm": 0.8852991461753845,
      "learning_rate": 6.794425087108014e-06,
      "loss": 0.1843,
      "step": 3640
    },
    {
      "epoch": 2.640144665461121,
      "grad_norm": 0.6644105315208435,
      "learning_rate": 6.660412757973734e-06,
      "loss": 0.1759,
      "step": 3650
    },
    {
      "epoch": 2.647377938517179,
      "grad_norm": 1.5077297687530518,
      "learning_rate": 6.526400428839453e-06,
      "loss": 0.196,
      "step": 3660
    },
    {
      "epoch": 2.6546112115732368,
      "grad_norm": 0.5866384506225586,
      "learning_rate": 6.392388099705174e-06,
      "loss": 0.1862,
      "step": 3670
    },
    {
      "epoch": 2.661844484629295,
      "grad_norm": 0.5954955816268921,
      "learning_rate": 6.258375770570893e-06,
      "loss": 0.2006,
      "step": 3680
    },
    {
      "epoch": 2.6690777576853524,
      "grad_norm": 0.715699315071106,
      "learning_rate": 6.1243634414366125e-06,
      "loss": 0.2144,
      "step": 3690
    },
    {
      "epoch": 2.6763110307414104,
      "grad_norm": 0.8369816541671753,
      "learning_rate": 5.990351112302332e-06,
      "loss": 0.239,
      "step": 3700
    },
    {
      "epoch": 2.6835443037974684,
      "grad_norm": 1.3412039279937744,
      "learning_rate": 5.856338783168052e-06,
      "loss": 0.2082,
      "step": 3710
    },
    {
      "epoch": 2.6907775768535265,
      "grad_norm": 0.603649914264679,
      "learning_rate": 5.722326454033771e-06,
      "loss": 0.1788,
      "step": 3720
    },
    {
      "epoch": 2.698010849909584,
      "grad_norm": 0.7041906714439392,
      "learning_rate": 5.588314124899491e-06,
      "loss": 0.2048,
      "step": 3730
    },
    {
      "epoch": 2.705244122965642,
      "grad_norm": 0.8745158910751343,
      "learning_rate": 5.454301795765211e-06,
      "loss": 0.1921,
      "step": 3740
    },
    {
      "epoch": 2.7124773960216997,
      "grad_norm": 0.7330317497253418,
      "learning_rate": 5.3202894666309305e-06,
      "loss": 0.2279,
      "step": 3750
    },
    {
      "epoch": 2.7197106690777577,
      "grad_norm": 0.7828449606895447,
      "learning_rate": 5.18627713749665e-06,
      "loss": 0.2054,
      "step": 3760
    },
    {
      "epoch": 2.7269439421338157,
      "grad_norm": 0.8740053176879883,
      "learning_rate": 5.052264808362369e-06,
      "loss": 0.2089,
      "step": 3770
    },
    {
      "epoch": 2.7341772151898733,
      "grad_norm": 0.7200781106948853,
      "learning_rate": 4.918252479228089e-06,
      "loss": 0.2258,
      "step": 3780
    },
    {
      "epoch": 2.7414104882459314,
      "grad_norm": 1.0251275300979614,
      "learning_rate": 4.784240150093809e-06,
      "loss": 0.1985,
      "step": 3790
    },
    {
      "epoch": 2.748643761301989,
      "grad_norm": 0.6460700631141663,
      "learning_rate": 4.650227820959528e-06,
      "loss": 0.1897,
      "step": 3800
    },
    {
      "epoch": 2.755877034358047,
      "grad_norm": 0.7142449617385864,
      "learning_rate": 4.516215491825248e-06,
      "loss": 0.2087,
      "step": 3810
    },
    {
      "epoch": 2.763110307414105,
      "grad_norm": 1.8375043869018555,
      "learning_rate": 4.3822031626909675e-06,
      "loss": 0.2107,
      "step": 3820
    },
    {
      "epoch": 2.7703435804701626,
      "grad_norm": 0.7665080428123474,
      "learning_rate": 4.248190833556687e-06,
      "loss": 0.1854,
      "step": 3830
    },
    {
      "epoch": 2.7775768535262206,
      "grad_norm": 0.8424579501152039,
      "learning_rate": 4.114178504422407e-06,
      "loss": 0.1774,
      "step": 3840
    },
    {
      "epoch": 2.7848101265822782,
      "grad_norm": 1.4180067777633667,
      "learning_rate": 3.980166175288127e-06,
      "loss": 0.1907,
      "step": 3850
    },
    {
      "epoch": 2.7920433996383363,
      "grad_norm": 0.8300852179527283,
      "learning_rate": 3.846153846153847e-06,
      "loss": 0.2139,
      "step": 3860
    },
    {
      "epoch": 2.7992766726943943,
      "grad_norm": 0.5261435508728027,
      "learning_rate": 3.712141517019566e-06,
      "loss": 0.2148,
      "step": 3870
    },
    {
      "epoch": 2.8065099457504523,
      "grad_norm": 0.8091126084327698,
      "learning_rate": 3.578129187885285e-06,
      "loss": 0.2211,
      "step": 3880
    },
    {
      "epoch": 2.81374321880651,
      "grad_norm": 0.7712728381156921,
      "learning_rate": 3.444116858751005e-06,
      "loss": 0.1806,
      "step": 3890
    },
    {
      "epoch": 2.820976491862568,
      "grad_norm": 0.974751889705658,
      "learning_rate": 3.3101045296167248e-06,
      "loss": 0.1862,
      "step": 3900
    },
    {
      "epoch": 2.8282097649186255,
      "grad_norm": 0.7738860249519348,
      "learning_rate": 3.1760922004824446e-06,
      "loss": 0.2106,
      "step": 3910
    },
    {
      "epoch": 2.8354430379746836,
      "grad_norm": 1.1643866300582886,
      "learning_rate": 3.0420798713481644e-06,
      "loss": 0.2307,
      "step": 3920
    },
    {
      "epoch": 2.8426763110307416,
      "grad_norm": 0.8947793245315552,
      "learning_rate": 2.908067542213884e-06,
      "loss": 0.1941,
      "step": 3930
    },
    {
      "epoch": 2.849909584086799,
      "grad_norm": 0.9650359749794006,
      "learning_rate": 2.774055213079603e-06,
      "loss": 0.2161,
      "step": 3940
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.6613971590995789,
      "learning_rate": 2.640042883945323e-06,
      "loss": 0.217,
      "step": 3950
    },
    {
      "epoch": 2.864376130198915,
      "grad_norm": 1.1727126836776733,
      "learning_rate": 2.506030554811043e-06,
      "loss": 0.184,
      "step": 3960
    },
    {
      "epoch": 2.871609403254973,
      "grad_norm": 0.6739354133605957,
      "learning_rate": 2.3720182256767626e-06,
      "loss": 0.1724,
      "step": 3970
    },
    {
      "epoch": 2.878842676311031,
      "grad_norm": 0.537499725818634,
      "learning_rate": 2.238005896542482e-06,
      "loss": 0.2198,
      "step": 3980
    },
    {
      "epoch": 2.8860759493670884,
      "grad_norm": 1.1071364879608154,
      "learning_rate": 2.1039935674082014e-06,
      "loss": 0.1817,
      "step": 3990
    },
    {
      "epoch": 2.8933092224231465,
      "grad_norm": 0.9829232692718506,
      "learning_rate": 1.9699812382739212e-06,
      "loss": 0.2035,
      "step": 4000
    },
    {
      "epoch": 2.900542495479204,
      "grad_norm": 0.6616301536560059,
      "learning_rate": 1.835968909139641e-06,
      "loss": 0.2284,
      "step": 4010
    },
    {
      "epoch": 2.907775768535262,
      "grad_norm": 0.6335816383361816,
      "learning_rate": 1.7019565800053605e-06,
      "loss": 0.1916,
      "step": 4020
    },
    {
      "epoch": 2.91500904159132,
      "grad_norm": 0.7803839445114136,
      "learning_rate": 1.5679442508710803e-06,
      "loss": 0.2224,
      "step": 4030
    },
    {
      "epoch": 2.922242314647378,
      "grad_norm": 1.4920824766159058,
      "learning_rate": 1.4339319217367999e-06,
      "loss": 0.2012,
      "step": 4040
    },
    {
      "epoch": 2.9294755877034357,
      "grad_norm": 0.8803523182868958,
      "learning_rate": 1.2999195926025195e-06,
      "loss": 0.2057,
      "step": 4050
    },
    {
      "epoch": 2.9367088607594938,
      "grad_norm": 0.8219721913337708,
      "learning_rate": 1.165907263468239e-06,
      "loss": 0.2058,
      "step": 4060
    },
    {
      "epoch": 2.9439421338155514,
      "grad_norm": 0.7152129411697388,
      "learning_rate": 1.0318949343339587e-06,
      "loss": 0.1966,
      "step": 4070
    },
    {
      "epoch": 2.9511754068716094,
      "grad_norm": 0.962043046951294,
      "learning_rate": 8.978826051996785e-07,
      "loss": 0.2009,
      "step": 4080
    },
    {
      "epoch": 2.9584086799276674,
      "grad_norm": 0.5933757424354553,
      "learning_rate": 7.638702760653981e-07,
      "loss": 0.1994,
      "step": 4090
    },
    {
      "epoch": 2.965641952983725,
      "grad_norm": 1.156834602355957,
      "learning_rate": 6.298579469311177e-07,
      "loss": 0.2183,
      "step": 4100
    },
    {
      "epoch": 2.972875226039783,
      "grad_norm": 0.694236695766449,
      "learning_rate": 4.958456177968374e-07,
      "loss": 0.195,
      "step": 4110
    },
    {
      "epoch": 2.9801084990958406,
      "grad_norm": 0.9134301543235779,
      "learning_rate": 3.61833288662557e-07,
      "loss": 0.2216,
      "step": 4120
    },
    {
      "epoch": 2.9873417721518987,
      "grad_norm": 1.0014928579330444,
      "learning_rate": 2.278209595282766e-07,
      "loss": 0.1861,
      "step": 4130
    },
    {
      "epoch": 2.9945750452079567,
      "grad_norm": 0.8338040709495544,
      "learning_rate": 9.380863039399625e-08,
      "loss": 0.2241,
      "step": 4140
    },
    {
      "epoch": 2.9989150090415913,
      "eval_loss": 0.2821888029575348,
      "eval_runtime": 103.5468,
      "eval_samples_per_second": 6.683,
      "eval_steps_per_second": 6.683,
      "step": 4146
    }
  ],
  "logging_steps": 10,
  "max_steps": 4146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.3406091532435456e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
