{
  "best_metric": 0.28545141220092773,
  "best_model_checkpoint": "Qwen2.5-Coder-3B-Instruct-LoRA/checkpoint-4146",
  "epoch": 2.9989150090415913,
  "eval_steps": 500,
  "global_step": 4146,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007233273056057866,
      "grad_norm": 0.15618053078651428,
      "learning_rate": 7.228915662650603e-07,
      "loss": 2.0027,
      "step": 10
    },
    {
      "epoch": 0.014466546112115732,
      "grad_norm": 0.1442939192056656,
      "learning_rate": 1.4457831325301207e-06,
      "loss": 2.0589,
      "step": 20
    },
    {
      "epoch": 0.0216998191681736,
      "grad_norm": 0.12320918589830399,
      "learning_rate": 2.1686746987951806e-06,
      "loss": 1.9676,
      "step": 30
    },
    {
      "epoch": 0.028933092224231464,
      "grad_norm": 0.16613298654556274,
      "learning_rate": 2.8915662650602413e-06,
      "loss": 1.9024,
      "step": 40
    },
    {
      "epoch": 0.03616636528028933,
      "grad_norm": 0.14498141407966614,
      "learning_rate": 3.614457831325301e-06,
      "loss": 2.0209,
      "step": 50
    },
    {
      "epoch": 0.0433996383363472,
      "grad_norm": 0.15048383176326752,
      "learning_rate": 4.337349397590361e-06,
      "loss": 1.9446,
      "step": 60
    },
    {
      "epoch": 0.05063291139240506,
      "grad_norm": 0.20572972297668457,
      "learning_rate": 5.060240963855422e-06,
      "loss": 2.056,
      "step": 70
    },
    {
      "epoch": 0.05786618444846293,
      "grad_norm": 0.160697802901268,
      "learning_rate": 5.783132530120483e-06,
      "loss": 1.8789,
      "step": 80
    },
    {
      "epoch": 0.0650994575045208,
      "grad_norm": 0.19365091621875763,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 1.958,
      "step": 90
    },
    {
      "epoch": 0.07233273056057866,
      "grad_norm": 0.1678103655576706,
      "learning_rate": 7.228915662650602e-06,
      "loss": 1.882,
      "step": 100
    },
    {
      "epoch": 0.07956600361663653,
      "grad_norm": 0.25053009390830994,
      "learning_rate": 7.951807228915663e-06,
      "loss": 1.9102,
      "step": 110
    },
    {
      "epoch": 0.0867992766726944,
      "grad_norm": 0.20742662250995636,
      "learning_rate": 8.674698795180722e-06,
      "loss": 1.9571,
      "step": 120
    },
    {
      "epoch": 0.09403254972875226,
      "grad_norm": 0.2965954542160034,
      "learning_rate": 9.397590361445783e-06,
      "loss": 2.0491,
      "step": 130
    },
    {
      "epoch": 0.10126582278481013,
      "grad_norm": 0.3257176876068115,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 1.922,
      "step": 140
    },
    {
      "epoch": 0.10849909584086799,
      "grad_norm": 0.2631766200065613,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 1.8279,
      "step": 150
    },
    {
      "epoch": 0.11573236889692586,
      "grad_norm": 0.23071368038654327,
      "learning_rate": 1.1566265060240965e-05,
      "loss": 1.7997,
      "step": 160
    },
    {
      "epoch": 0.12296564195298372,
      "grad_norm": 0.27860939502716064,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 1.9455,
      "step": 170
    },
    {
      "epoch": 0.1301989150090416,
      "grad_norm": 0.32226067781448364,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 1.8737,
      "step": 180
    },
    {
      "epoch": 0.13743218806509946,
      "grad_norm": 0.3802511990070343,
      "learning_rate": 1.3734939759036144e-05,
      "loss": 1.7868,
      "step": 190
    },
    {
      "epoch": 0.14466546112115733,
      "grad_norm": 0.40022003650665283,
      "learning_rate": 1.4457831325301205e-05,
      "loss": 1.7555,
      "step": 200
    },
    {
      "epoch": 0.1518987341772152,
      "grad_norm": 0.37310275435447693,
      "learning_rate": 1.5180722891566264e-05,
      "loss": 1.6645,
      "step": 210
    },
    {
      "epoch": 0.15913200723327306,
      "grad_norm": 0.4076991379261017,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 1.6544,
      "step": 220
    },
    {
      "epoch": 0.16636528028933092,
      "grad_norm": 0.3933812379837036,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 1.5766,
      "step": 230
    },
    {
      "epoch": 0.1735985533453888,
      "grad_norm": 0.46802404522895813,
      "learning_rate": 1.7349397590361444e-05,
      "loss": 1.6383,
      "step": 240
    },
    {
      "epoch": 0.18083182640144665,
      "grad_norm": 0.4649888277053833,
      "learning_rate": 1.807228915662651e-05,
      "loss": 1.5,
      "step": 250
    },
    {
      "epoch": 0.18806509945750452,
      "grad_norm": 0.49526292085647583,
      "learning_rate": 1.8795180722891566e-05,
      "loss": 1.4761,
      "step": 260
    },
    {
      "epoch": 0.19529837251356238,
      "grad_norm": 0.5008724927902222,
      "learning_rate": 1.9518072289156627e-05,
      "loss": 1.3444,
      "step": 270
    },
    {
      "epoch": 0.20253164556962025,
      "grad_norm": 0.7854418754577637,
      "learning_rate": 2.0240963855421687e-05,
      "loss": 1.2791,
      "step": 280
    },
    {
      "epoch": 0.20976491862567812,
      "grad_norm": 0.6134413480758667,
      "learning_rate": 2.0963855421686748e-05,
      "loss": 1.1959,
      "step": 290
    },
    {
      "epoch": 0.21699819168173598,
      "grad_norm": 0.9017700552940369,
      "learning_rate": 2.168674698795181e-05,
      "loss": 1.0146,
      "step": 300
    },
    {
      "epoch": 0.22423146473779385,
      "grad_norm": 0.8071762323379517,
      "learning_rate": 2.2409638554216866e-05,
      "loss": 0.8756,
      "step": 310
    },
    {
      "epoch": 0.2314647377938517,
      "grad_norm": 0.7701794505119324,
      "learning_rate": 2.313253012048193e-05,
      "loss": 0.7741,
      "step": 320
    },
    {
      "epoch": 0.23869801084990958,
      "grad_norm": 0.8747300505638123,
      "learning_rate": 2.3855421686746988e-05,
      "loss": 0.6692,
      "step": 330
    },
    {
      "epoch": 0.24593128390596744,
      "grad_norm": 0.7129759192466736,
      "learning_rate": 2.457831325301205e-05,
      "loss": 0.6161,
      "step": 340
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.542189359664917,
      "learning_rate": 2.530120481927711e-05,
      "loss": 0.5581,
      "step": 350
    },
    {
      "epoch": 0.2603978300180832,
      "grad_norm": 0.6401716470718384,
      "learning_rate": 2.602409638554217e-05,
      "loss": 0.453,
      "step": 360
    },
    {
      "epoch": 0.26763110307414106,
      "grad_norm": 0.5480882525444031,
      "learning_rate": 2.674698795180723e-05,
      "loss": 0.4659,
      "step": 370
    },
    {
      "epoch": 0.27486437613019893,
      "grad_norm": 0.9591647386550903,
      "learning_rate": 2.7469879518072288e-05,
      "loss": 0.4088,
      "step": 380
    },
    {
      "epoch": 0.2820976491862568,
      "grad_norm": 0.595331609249115,
      "learning_rate": 2.8192771084337352e-05,
      "loss": 0.4529,
      "step": 390
    },
    {
      "epoch": 0.28933092224231466,
      "grad_norm": 0.5219366550445557,
      "learning_rate": 2.891566265060241e-05,
      "loss": 0.3922,
      "step": 400
    },
    {
      "epoch": 0.2965641952983725,
      "grad_norm": 0.5046800374984741,
      "learning_rate": 2.963855421686747e-05,
      "loss": 0.3404,
      "step": 410
    },
    {
      "epoch": 0.3037974683544304,
      "grad_norm": 0.8206260204315186,
      "learning_rate": 2.9959796301259715e-05,
      "loss": 0.3249,
      "step": 420
    },
    {
      "epoch": 0.31103074141048825,
      "grad_norm": 0.4926619231700897,
      "learning_rate": 2.9879388903779148e-05,
      "loss": 0.3906,
      "step": 430
    },
    {
      "epoch": 0.3182640144665461,
      "grad_norm": 1.0518302917480469,
      "learning_rate": 2.979898150629858e-05,
      "loss": 0.3463,
      "step": 440
    },
    {
      "epoch": 0.325497287522604,
      "grad_norm": 0.48004254698753357,
      "learning_rate": 2.971857410881801e-05,
      "loss": 0.2928,
      "step": 450
    },
    {
      "epoch": 0.33273056057866185,
      "grad_norm": 0.3788369297981262,
      "learning_rate": 2.9638166711337443e-05,
      "loss": 0.3037,
      "step": 460
    },
    {
      "epoch": 0.3399638336347197,
      "grad_norm": 0.657770037651062,
      "learning_rate": 2.9557759313856876e-05,
      "loss": 0.304,
      "step": 470
    },
    {
      "epoch": 0.3471971066907776,
      "grad_norm": 0.6131691932678223,
      "learning_rate": 2.947735191637631e-05,
      "loss": 0.3213,
      "step": 480
    },
    {
      "epoch": 0.35443037974683544,
      "grad_norm": 0.5147794485092163,
      "learning_rate": 2.939694451889574e-05,
      "loss": 0.2952,
      "step": 490
    },
    {
      "epoch": 0.3616636528028933,
      "grad_norm": 0.8368288278579712,
      "learning_rate": 2.931653712141517e-05,
      "loss": 0.2725,
      "step": 500
    },
    {
      "epoch": 0.3688969258589512,
      "grad_norm": 0.7207967638969421,
      "learning_rate": 2.9236129723934603e-05,
      "loss": 0.2719,
      "step": 510
    },
    {
      "epoch": 0.37613019891500904,
      "grad_norm": 1.0519453287124634,
      "learning_rate": 2.9155722326454033e-05,
      "loss": 0.2765,
      "step": 520
    },
    {
      "epoch": 0.3833634719710669,
      "grad_norm": 0.7047211527824402,
      "learning_rate": 2.9075314928973465e-05,
      "loss": 0.2794,
      "step": 530
    },
    {
      "epoch": 0.39059674502712477,
      "grad_norm": 0.6409996151924133,
      "learning_rate": 2.8994907531492898e-05,
      "loss": 0.2469,
      "step": 540
    },
    {
      "epoch": 0.39783001808318263,
      "grad_norm": 0.40598055720329285,
      "learning_rate": 2.8914500134012327e-05,
      "loss": 0.2956,
      "step": 550
    },
    {
      "epoch": 0.4050632911392405,
      "grad_norm": 0.7315600514411926,
      "learning_rate": 2.8834092736531764e-05,
      "loss": 0.2917,
      "step": 560
    },
    {
      "epoch": 0.41229656419529837,
      "grad_norm": 0.6504259705543518,
      "learning_rate": 2.8753685339051193e-05,
      "loss": 0.2935,
      "step": 570
    },
    {
      "epoch": 0.41952983725135623,
      "grad_norm": 0.5114114284515381,
      "learning_rate": 2.8673277941570626e-05,
      "loss": 0.2523,
      "step": 580
    },
    {
      "epoch": 0.4267631103074141,
      "grad_norm": 0.4736548662185669,
      "learning_rate": 2.859287054409006e-05,
      "loss": 0.308,
      "step": 590
    },
    {
      "epoch": 0.43399638336347196,
      "grad_norm": 0.40963277220726013,
      "learning_rate": 2.8512463146609488e-05,
      "loss": 0.2773,
      "step": 600
    },
    {
      "epoch": 0.4412296564195298,
      "grad_norm": 0.36474332213401794,
      "learning_rate": 2.843205574912892e-05,
      "loss": 0.2493,
      "step": 610
    },
    {
      "epoch": 0.4484629294755877,
      "grad_norm": 0.4833776652812958,
      "learning_rate": 2.8351648351648353e-05,
      "loss": 0.2891,
      "step": 620
    },
    {
      "epoch": 0.45569620253164556,
      "grad_norm": 0.7858027815818787,
      "learning_rate": 2.8271240954167783e-05,
      "loss": 0.2853,
      "step": 630
    },
    {
      "epoch": 0.4629294755877034,
      "grad_norm": 0.29485514760017395,
      "learning_rate": 2.8190833556687215e-05,
      "loss": 0.269,
      "step": 640
    },
    {
      "epoch": 0.4701627486437613,
      "grad_norm": 0.5448315739631653,
      "learning_rate": 2.8110426159206648e-05,
      "loss": 0.2397,
      "step": 650
    },
    {
      "epoch": 0.47739602169981915,
      "grad_norm": 0.4541039764881134,
      "learning_rate": 2.803001876172608e-05,
      "loss": 0.2623,
      "step": 660
    },
    {
      "epoch": 0.484629294755877,
      "grad_norm": 1.1881471872329712,
      "learning_rate": 2.7949611364245514e-05,
      "loss": 0.2961,
      "step": 670
    },
    {
      "epoch": 0.4918625678119349,
      "grad_norm": 2.0665671825408936,
      "learning_rate": 2.7869203966764943e-05,
      "loss": 0.2422,
      "step": 680
    },
    {
      "epoch": 0.49909584086799275,
      "grad_norm": 0.39036044478416443,
      "learning_rate": 2.7788796569284376e-05,
      "loss": 0.2269,
      "step": 690
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.7403146624565125,
      "learning_rate": 2.7708389171803805e-05,
      "loss": 0.2707,
      "step": 700
    },
    {
      "epoch": 0.5135623869801085,
      "grad_norm": 0.3697325885295868,
      "learning_rate": 2.7627981774323238e-05,
      "loss": 0.2345,
      "step": 710
    },
    {
      "epoch": 0.5207956600361664,
      "grad_norm": 0.6182664036750793,
      "learning_rate": 2.754757437684267e-05,
      "loss": 0.244,
      "step": 720
    },
    {
      "epoch": 0.5280289330922242,
      "grad_norm": 0.606322705745697,
      "learning_rate": 2.74671669793621e-05,
      "loss": 0.2892,
      "step": 730
    },
    {
      "epoch": 0.5352622061482821,
      "grad_norm": 0.37891414761543274,
      "learning_rate": 2.7386759581881536e-05,
      "loss": 0.2419,
      "step": 740
    },
    {
      "epoch": 0.5424954792043399,
      "grad_norm": 0.4809238910675049,
      "learning_rate": 2.7306352184400965e-05,
      "loss": 0.2766,
      "step": 750
    },
    {
      "epoch": 0.5497287522603979,
      "grad_norm": 0.469230592250824,
      "learning_rate": 2.7225944786920398e-05,
      "loss": 0.2672,
      "step": 760
    },
    {
      "epoch": 0.5569620253164557,
      "grad_norm": 0.451860249042511,
      "learning_rate": 2.714553738943983e-05,
      "loss": 0.2703,
      "step": 770
    },
    {
      "epoch": 0.5641952983725136,
      "grad_norm": 0.45340457558631897,
      "learning_rate": 2.706512999195926e-05,
      "loss": 0.239,
      "step": 780
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.5708378553390503,
      "learning_rate": 2.6984722594478693e-05,
      "loss": 0.2633,
      "step": 790
    },
    {
      "epoch": 0.5786618444846293,
      "grad_norm": 0.5395111441612244,
      "learning_rate": 2.6904315196998122e-05,
      "loss": 0.2532,
      "step": 800
    },
    {
      "epoch": 0.5858951175406871,
      "grad_norm": 0.6076334714889526,
      "learning_rate": 2.6823907799517555e-05,
      "loss": 0.231,
      "step": 810
    },
    {
      "epoch": 0.593128390596745,
      "grad_norm": 0.7434477806091309,
      "learning_rate": 2.6743500402036988e-05,
      "loss": 0.2252,
      "step": 820
    },
    {
      "epoch": 0.6003616636528029,
      "grad_norm": 0.567787766456604,
      "learning_rate": 2.666309300455642e-05,
      "loss": 0.2506,
      "step": 830
    },
    {
      "epoch": 0.6075949367088608,
      "grad_norm": 0.604269802570343,
      "learning_rate": 2.6582685607075853e-05,
      "loss": 0.262,
      "step": 840
    },
    {
      "epoch": 0.6148282097649186,
      "grad_norm": 0.519220232963562,
      "learning_rate": 2.6502278209595286e-05,
      "loss": 0.2518,
      "step": 850
    },
    {
      "epoch": 0.6220614828209765,
      "grad_norm": 0.5189812779426575,
      "learning_rate": 2.6421870812114715e-05,
      "loss": 0.2402,
      "step": 860
    },
    {
      "epoch": 0.6292947558770343,
      "grad_norm": 0.6660866737365723,
      "learning_rate": 2.6341463414634148e-05,
      "loss": 0.2319,
      "step": 870
    },
    {
      "epoch": 0.6365280289330922,
      "grad_norm": 0.4204140603542328,
      "learning_rate": 2.6261056017153577e-05,
      "loss": 0.244,
      "step": 880
    },
    {
      "epoch": 0.64376130198915,
      "grad_norm": 0.718045175075531,
      "learning_rate": 2.618064861967301e-05,
      "loss": 0.2271,
      "step": 890
    },
    {
      "epoch": 0.650994575045208,
      "grad_norm": 0.5941691994667053,
      "learning_rate": 2.6100241222192443e-05,
      "loss": 0.2443,
      "step": 900
    },
    {
      "epoch": 0.6582278481012658,
      "grad_norm": 0.7149595022201538,
      "learning_rate": 2.6019833824711872e-05,
      "loss": 0.2757,
      "step": 910
    },
    {
      "epoch": 0.6654611211573237,
      "grad_norm": 0.523337721824646,
      "learning_rate": 2.5939426427231308e-05,
      "loss": 0.2542,
      "step": 920
    },
    {
      "epoch": 0.6726943942133815,
      "grad_norm": 0.5020321607589722,
      "learning_rate": 2.5859019029750738e-05,
      "loss": 0.2359,
      "step": 930
    },
    {
      "epoch": 0.6799276672694394,
      "grad_norm": 0.8180668950080872,
      "learning_rate": 2.577861163227017e-05,
      "loss": 0.2319,
      "step": 940
    },
    {
      "epoch": 0.6871609403254972,
      "grad_norm": 0.6462804079055786,
      "learning_rate": 2.5698204234789603e-05,
      "loss": 0.2301,
      "step": 950
    },
    {
      "epoch": 0.6943942133815552,
      "grad_norm": 0.738968551158905,
      "learning_rate": 2.5617796837309032e-05,
      "loss": 0.2269,
      "step": 960
    },
    {
      "epoch": 0.701627486437613,
      "grad_norm": 0.4856787323951721,
      "learning_rate": 2.5537389439828465e-05,
      "loss": 0.2316,
      "step": 970
    },
    {
      "epoch": 0.7088607594936709,
      "grad_norm": 0.810259222984314,
      "learning_rate": 2.5456982042347894e-05,
      "loss": 0.2418,
      "step": 980
    },
    {
      "epoch": 0.7160940325497287,
      "grad_norm": 0.5868244767189026,
      "learning_rate": 2.5376574644867327e-05,
      "loss": 0.2445,
      "step": 990
    },
    {
      "epoch": 0.7233273056057866,
      "grad_norm": 0.44775402545928955,
      "learning_rate": 2.529616724738676e-05,
      "loss": 0.2521,
      "step": 1000
    },
    {
      "epoch": 0.7305605786618445,
      "grad_norm": 0.5288752317428589,
      "learning_rate": 2.5215759849906193e-05,
      "loss": 0.2155,
      "step": 1010
    },
    {
      "epoch": 0.7377938517179023,
      "grad_norm": 0.9837886095046997,
      "learning_rate": 2.5135352452425625e-05,
      "loss": 0.2667,
      "step": 1020
    },
    {
      "epoch": 0.7450271247739603,
      "grad_norm": 0.6658116579055786,
      "learning_rate": 2.5054945054945058e-05,
      "loss": 0.2402,
      "step": 1030
    },
    {
      "epoch": 0.7522603978300181,
      "grad_norm": 0.6214501261711121,
      "learning_rate": 2.4974537657464487e-05,
      "loss": 0.2409,
      "step": 1040
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.47662055492401123,
      "learning_rate": 2.489413025998392e-05,
      "loss": 0.1984,
      "step": 1050
    },
    {
      "epoch": 0.7667269439421338,
      "grad_norm": 0.536322832107544,
      "learning_rate": 2.481372286250335e-05,
      "loss": 0.2258,
      "step": 1060
    },
    {
      "epoch": 0.7739602169981917,
      "grad_norm": 0.5596567988395691,
      "learning_rate": 2.4733315465022782e-05,
      "loss": 0.2541,
      "step": 1070
    },
    {
      "epoch": 0.7811934900542495,
      "grad_norm": 0.5559620261192322,
      "learning_rate": 2.4652908067542215e-05,
      "loss": 0.2439,
      "step": 1080
    },
    {
      "epoch": 0.7884267631103075,
      "grad_norm": 0.4398309588432312,
      "learning_rate": 2.4572500670061644e-05,
      "loss": 0.1966,
      "step": 1090
    },
    {
      "epoch": 0.7956600361663653,
      "grad_norm": 0.6451774835586548,
      "learning_rate": 2.4492093272581077e-05,
      "loss": 0.28,
      "step": 1100
    },
    {
      "epoch": 0.8028933092224232,
      "grad_norm": 0.4542534053325653,
      "learning_rate": 2.441168587510051e-05,
      "loss": 0.207,
      "step": 1110
    },
    {
      "epoch": 0.810126582278481,
      "grad_norm": 0.5003021955490112,
      "learning_rate": 2.4331278477619943e-05,
      "loss": 0.2146,
      "step": 1120
    },
    {
      "epoch": 0.8173598553345389,
      "grad_norm": 0.9856685996055603,
      "learning_rate": 2.4250871080139375e-05,
      "loss": 0.2448,
      "step": 1130
    },
    {
      "epoch": 0.8245931283905967,
      "grad_norm": 0.8139278292655945,
      "learning_rate": 2.4170463682658805e-05,
      "loss": 0.2411,
      "step": 1140
    },
    {
      "epoch": 0.8318264014466547,
      "grad_norm": 0.4760347604751587,
      "learning_rate": 2.4090056285178237e-05,
      "loss": 0.2603,
      "step": 1150
    },
    {
      "epoch": 0.8390596745027125,
      "grad_norm": 0.571262538433075,
      "learning_rate": 2.4009648887697667e-05,
      "loss": 0.2354,
      "step": 1160
    },
    {
      "epoch": 0.8462929475587704,
      "grad_norm": 0.6921206712722778,
      "learning_rate": 2.39292414902171e-05,
      "loss": 0.2332,
      "step": 1170
    },
    {
      "epoch": 0.8535262206148282,
      "grad_norm": 0.5345845222473145,
      "learning_rate": 2.3848834092736532e-05,
      "loss": 0.249,
      "step": 1180
    },
    {
      "epoch": 0.8607594936708861,
      "grad_norm": 0.5005009770393372,
      "learning_rate": 2.376842669525596e-05,
      "loss": 0.2348,
      "step": 1190
    },
    {
      "epoch": 0.8679927667269439,
      "grad_norm": 0.5681484341621399,
      "learning_rate": 2.3688019297775398e-05,
      "loss": 0.2119,
      "step": 1200
    },
    {
      "epoch": 0.8752260397830018,
      "grad_norm": 0.5825056433677673,
      "learning_rate": 2.3607611900294827e-05,
      "loss": 0.248,
      "step": 1210
    },
    {
      "epoch": 0.8824593128390597,
      "grad_norm": 0.48910555243492126,
      "learning_rate": 2.352720450281426e-05,
      "loss": 0.2465,
      "step": 1220
    },
    {
      "epoch": 0.8896925858951176,
      "grad_norm": 0.5700782537460327,
      "learning_rate": 2.3446797105333693e-05,
      "loss": 0.2413,
      "step": 1230
    },
    {
      "epoch": 0.8969258589511754,
      "grad_norm": 0.4866601824760437,
      "learning_rate": 2.3366389707853122e-05,
      "loss": 0.2288,
      "step": 1240
    },
    {
      "epoch": 0.9041591320072333,
      "grad_norm": 0.45553943514823914,
      "learning_rate": 2.3285982310372555e-05,
      "loss": 0.2416,
      "step": 1250
    },
    {
      "epoch": 0.9113924050632911,
      "grad_norm": 0.643968939781189,
      "learning_rate": 2.3205574912891987e-05,
      "loss": 0.2551,
      "step": 1260
    },
    {
      "epoch": 0.918625678119349,
      "grad_norm": 0.46250617504119873,
      "learning_rate": 2.3125167515411417e-05,
      "loss": 0.238,
      "step": 1270
    },
    {
      "epoch": 0.9258589511754068,
      "grad_norm": 0.6031555533409119,
      "learning_rate": 2.304476011793085e-05,
      "loss": 0.1999,
      "step": 1280
    },
    {
      "epoch": 0.9330922242314648,
      "grad_norm": 0.7291587591171265,
      "learning_rate": 2.2964352720450282e-05,
      "loss": 0.2309,
      "step": 1290
    },
    {
      "epoch": 0.9403254972875226,
      "grad_norm": 0.5895913243293762,
      "learning_rate": 2.2883945322969715e-05,
      "loss": 0.2166,
      "step": 1300
    },
    {
      "epoch": 0.9475587703435805,
      "grad_norm": 0.7950814366340637,
      "learning_rate": 2.2803537925489148e-05,
      "loss": 0.2343,
      "step": 1310
    },
    {
      "epoch": 0.9547920433996383,
      "grad_norm": 0.5503612756729126,
      "learning_rate": 2.2723130528008577e-05,
      "loss": 0.2379,
      "step": 1320
    },
    {
      "epoch": 0.9620253164556962,
      "grad_norm": 0.6846901774406433,
      "learning_rate": 2.264272313052801e-05,
      "loss": 0.2162,
      "step": 1330
    },
    {
      "epoch": 0.969258589511754,
      "grad_norm": 0.8067989945411682,
      "learning_rate": 2.256231573304744e-05,
      "loss": 0.2393,
      "step": 1340
    },
    {
      "epoch": 0.976491862567812,
      "grad_norm": 0.5848799347877502,
      "learning_rate": 2.2481908335566872e-05,
      "loss": 0.2098,
      "step": 1350
    },
    {
      "epoch": 0.9837251356238698,
      "grad_norm": 0.6150126457214355,
      "learning_rate": 2.2401500938086305e-05,
      "loss": 0.2259,
      "step": 1360
    },
    {
      "epoch": 0.9909584086799277,
      "grad_norm": 0.5495573282241821,
      "learning_rate": 2.2321093540605734e-05,
      "loss": 0.2002,
      "step": 1370
    },
    {
      "epoch": 0.9981916817359855,
      "grad_norm": 0.6283828616142273,
      "learning_rate": 2.224068614312517e-05,
      "loss": 0.2346,
      "step": 1380
    },
    {
      "epoch": 0.9996383363471971,
      "eval_loss": 0.3119134306907654,
      "eval_runtime": 41.6675,
      "eval_samples_per_second": 16.608,
      "eval_steps_per_second": 16.608,
      "step": 1382
    },
    {
      "epoch": 1.0054249547920433,
      "grad_norm": 0.6360343098640442,
      "learning_rate": 2.21602787456446e-05,
      "loss": 0.2346,
      "step": 1390
    },
    {
      "epoch": 1.0126582278481013,
      "grad_norm": 0.47066089510917664,
      "learning_rate": 2.2079871348164032e-05,
      "loss": 0.2067,
      "step": 1400
    },
    {
      "epoch": 1.0198915009041591,
      "grad_norm": 0.8369451761245728,
      "learning_rate": 2.1999463950683465e-05,
      "loss": 0.2395,
      "step": 1410
    },
    {
      "epoch": 1.027124773960217,
      "grad_norm": 1.3026926517486572,
      "learning_rate": 2.1919056553202894e-05,
      "loss": 0.2434,
      "step": 1420
    },
    {
      "epoch": 1.0343580470162748,
      "grad_norm": 1.2512283325195312,
      "learning_rate": 2.1838649155722327e-05,
      "loss": 0.2779,
      "step": 1430
    },
    {
      "epoch": 1.0415913200723328,
      "grad_norm": 0.5921669006347656,
      "learning_rate": 2.175824175824176e-05,
      "loss": 0.2129,
      "step": 1440
    },
    {
      "epoch": 1.0488245931283906,
      "grad_norm": 0.5082955956459045,
      "learning_rate": 2.167783436076119e-05,
      "loss": 0.222,
      "step": 1450
    },
    {
      "epoch": 1.0560578661844484,
      "grad_norm": 0.8459033370018005,
      "learning_rate": 2.1597426963280622e-05,
      "loss": 0.229,
      "step": 1460
    },
    {
      "epoch": 1.0632911392405062,
      "grad_norm": 0.49186018109321594,
      "learning_rate": 2.1517019565800055e-05,
      "loss": 0.2162,
      "step": 1470
    },
    {
      "epoch": 1.0705244122965643,
      "grad_norm": 0.7132468819618225,
      "learning_rate": 2.1436612168319487e-05,
      "loss": 0.2154,
      "step": 1480
    },
    {
      "epoch": 1.077757685352622,
      "grad_norm": 0.7842065691947937,
      "learning_rate": 2.135620477083892e-05,
      "loss": 0.2172,
      "step": 1490
    },
    {
      "epoch": 1.0849909584086799,
      "grad_norm": 0.981094241142273,
      "learning_rate": 2.127579737335835e-05,
      "loss": 0.2451,
      "step": 1500
    },
    {
      "epoch": 1.092224231464738,
      "grad_norm": 0.5618695616722107,
      "learning_rate": 2.1195389975877782e-05,
      "loss": 0.2522,
      "step": 1510
    },
    {
      "epoch": 1.0994575045207957,
      "grad_norm": 0.7574401497840881,
      "learning_rate": 2.111498257839721e-05,
      "loss": 0.2576,
      "step": 1520
    },
    {
      "epoch": 1.1066907775768535,
      "grad_norm": 0.42323535680770874,
      "learning_rate": 2.1034575180916644e-05,
      "loss": 0.2235,
      "step": 1530
    },
    {
      "epoch": 1.1139240506329113,
      "grad_norm": 0.5868588089942932,
      "learning_rate": 2.0954167783436077e-05,
      "loss": 0.2557,
      "step": 1540
    },
    {
      "epoch": 1.1211573236889691,
      "grad_norm": 0.834413468837738,
      "learning_rate": 2.0873760385955506e-05,
      "loss": 0.2686,
      "step": 1550
    },
    {
      "epoch": 1.1283905967450272,
      "grad_norm": 0.610722005367279,
      "learning_rate": 2.0793352988474942e-05,
      "loss": 0.2005,
      "step": 1560
    },
    {
      "epoch": 1.135623869801085,
      "grad_norm": 0.7716536521911621,
      "learning_rate": 2.0712945590994372e-05,
      "loss": 0.243,
      "step": 1570
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.7064631581306458,
      "learning_rate": 2.0632538193513804e-05,
      "loss": 0.219,
      "step": 1580
    },
    {
      "epoch": 1.1500904159132008,
      "grad_norm": 0.8953648805618286,
      "learning_rate": 2.0552130796033237e-05,
      "loss": 0.245,
      "step": 1590
    },
    {
      "epoch": 1.1573236889692586,
      "grad_norm": 0.7671789526939392,
      "learning_rate": 2.0471723398552667e-05,
      "loss": 0.2347,
      "step": 1600
    },
    {
      "epoch": 1.1645569620253164,
      "grad_norm": 0.6636571884155273,
      "learning_rate": 2.03913160010721e-05,
      "loss": 0.2706,
      "step": 1610
    },
    {
      "epoch": 1.1717902350813743,
      "grad_norm": 0.7182672023773193,
      "learning_rate": 2.0310908603591532e-05,
      "loss": 0.2368,
      "step": 1620
    },
    {
      "epoch": 1.179023508137432,
      "grad_norm": 0.564885139465332,
      "learning_rate": 2.023050120611096e-05,
      "loss": 0.2276,
      "step": 1630
    },
    {
      "epoch": 1.18625678119349,
      "grad_norm": 0.6229522824287415,
      "learning_rate": 2.0150093808630394e-05,
      "loss": 0.2177,
      "step": 1640
    },
    {
      "epoch": 1.193490054249548,
      "grad_norm": 0.7323914170265198,
      "learning_rate": 2.0069686411149827e-05,
      "loss": 0.2199,
      "step": 1650
    },
    {
      "epoch": 1.2007233273056057,
      "grad_norm": 0.5805661082267761,
      "learning_rate": 1.998927901366926e-05,
      "loss": 0.2574,
      "step": 1660
    },
    {
      "epoch": 1.2079566003616637,
      "grad_norm": 0.7986851334571838,
      "learning_rate": 1.9908871616188692e-05,
      "loss": 0.2095,
      "step": 1670
    },
    {
      "epoch": 1.2151898734177216,
      "grad_norm": 0.5440154671669006,
      "learning_rate": 1.982846421870812e-05,
      "loss": 0.2188,
      "step": 1680
    },
    {
      "epoch": 1.2224231464737794,
      "grad_norm": 0.7356598973274231,
      "learning_rate": 1.9748056821227554e-05,
      "loss": 0.2225,
      "step": 1690
    },
    {
      "epoch": 1.2296564195298372,
      "grad_norm": 0.8441382050514221,
      "learning_rate": 1.9667649423746984e-05,
      "loss": 0.2159,
      "step": 1700
    },
    {
      "epoch": 1.2368896925858952,
      "grad_norm": 0.49536246061325073,
      "learning_rate": 1.9587242026266416e-05,
      "loss": 0.2087,
      "step": 1710
    },
    {
      "epoch": 1.244122965641953,
      "grad_norm": 0.7679255604743958,
      "learning_rate": 1.950683462878585e-05,
      "loss": 0.2823,
      "step": 1720
    },
    {
      "epoch": 1.2513562386980108,
      "grad_norm": 0.6383930444717407,
      "learning_rate": 1.942642723130528e-05,
      "loss": 0.2246,
      "step": 1730
    },
    {
      "epoch": 1.2585895117540686,
      "grad_norm": 0.5188856720924377,
      "learning_rate": 1.934601983382471e-05,
      "loss": 0.2196,
      "step": 1740
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.6690871715545654,
      "learning_rate": 1.9265612436344144e-05,
      "loss": 0.238,
      "step": 1750
    },
    {
      "epoch": 1.2730560578661845,
      "grad_norm": 0.6224941611289978,
      "learning_rate": 1.9185205038863577e-05,
      "loss": 0.2197,
      "step": 1760
    },
    {
      "epoch": 1.2802893309222423,
      "grad_norm": 0.8081833720207214,
      "learning_rate": 1.910479764138301e-05,
      "loss": 0.2198,
      "step": 1770
    },
    {
      "epoch": 1.2875226039783003,
      "grad_norm": 0.4957663118839264,
      "learning_rate": 1.902439024390244e-05,
      "loss": 0.267,
      "step": 1780
    },
    {
      "epoch": 1.2947558770343581,
      "grad_norm": 0.5565000772476196,
      "learning_rate": 1.894398284642187e-05,
      "loss": 0.2001,
      "step": 1790
    },
    {
      "epoch": 1.301989150090416,
      "grad_norm": 0.669214129447937,
      "learning_rate": 1.88635754489413e-05,
      "loss": 0.2197,
      "step": 1800
    },
    {
      "epoch": 1.3092224231464737,
      "grad_norm": 0.601508617401123,
      "learning_rate": 1.8783168051460734e-05,
      "loss": 0.2045,
      "step": 1810
    },
    {
      "epoch": 1.3164556962025316,
      "grad_norm": 0.527339518070221,
      "learning_rate": 1.8702760653980166e-05,
      "loss": 0.2095,
      "step": 1820
    },
    {
      "epoch": 1.3236889692585896,
      "grad_norm": 0.4818804860115051,
      "learning_rate": 1.8622353256499596e-05,
      "loss": 0.2298,
      "step": 1830
    },
    {
      "epoch": 1.3309222423146474,
      "grad_norm": 0.6752506494522095,
      "learning_rate": 1.8541945859019032e-05,
      "loss": 0.2605,
      "step": 1840
    },
    {
      "epoch": 1.3381555153707052,
      "grad_norm": 0.5788516998291016,
      "learning_rate": 1.8461538461538465e-05,
      "loss": 0.2186,
      "step": 1850
    },
    {
      "epoch": 1.3453887884267632,
      "grad_norm": 0.5404784083366394,
      "learning_rate": 1.8381131064057894e-05,
      "loss": 0.1978,
      "step": 1860
    },
    {
      "epoch": 1.352622061482821,
      "grad_norm": 0.7611216902732849,
      "learning_rate": 1.8300723666577327e-05,
      "loss": 0.1913,
      "step": 1870
    },
    {
      "epoch": 1.3598553345388789,
      "grad_norm": 0.668215274810791,
      "learning_rate": 1.8220316269096756e-05,
      "loss": 0.1973,
      "step": 1880
    },
    {
      "epoch": 1.3670886075949367,
      "grad_norm": 0.579346776008606,
      "learning_rate": 1.813990887161619e-05,
      "loss": 0.195,
      "step": 1890
    },
    {
      "epoch": 1.3743218806509945,
      "grad_norm": 0.5563446879386902,
      "learning_rate": 1.805950147413562e-05,
      "loss": 0.2201,
      "step": 1900
    },
    {
      "epoch": 1.3815551537070525,
      "grad_norm": 1.1993803977966309,
      "learning_rate": 1.797909407665505e-05,
      "loss": 0.2307,
      "step": 1910
    },
    {
      "epoch": 1.3887884267631103,
      "grad_norm": 0.6429650783538818,
      "learning_rate": 1.7898686679174484e-05,
      "loss": 0.2287,
      "step": 1920
    },
    {
      "epoch": 1.3960216998191681,
      "grad_norm": 0.5798598527908325,
      "learning_rate": 1.7818279281693916e-05,
      "loss": 0.2164,
      "step": 1930
    },
    {
      "epoch": 1.4032549728752262,
      "grad_norm": 0.6695327162742615,
      "learning_rate": 1.773787188421335e-05,
      "loss": 0.2531,
      "step": 1940
    },
    {
      "epoch": 1.410488245931284,
      "grad_norm": 1.1263257265090942,
      "learning_rate": 1.7657464486732782e-05,
      "loss": 0.2263,
      "step": 1950
    },
    {
      "epoch": 1.4177215189873418,
      "grad_norm": 0.8011753559112549,
      "learning_rate": 1.757705708925221e-05,
      "loss": 0.1609,
      "step": 1960
    },
    {
      "epoch": 1.4249547920433996,
      "grad_norm": 0.6040870547294617,
      "learning_rate": 1.7496649691771644e-05,
      "loss": 0.2173,
      "step": 1970
    },
    {
      "epoch": 1.4321880650994574,
      "grad_norm": 0.8536904454231262,
      "learning_rate": 1.7416242294291073e-05,
      "loss": 0.2272,
      "step": 1980
    },
    {
      "epoch": 1.4394213381555154,
      "grad_norm": 0.4851541221141815,
      "learning_rate": 1.7335834896810506e-05,
      "loss": 0.2009,
      "step": 1990
    },
    {
      "epoch": 1.4466546112115732,
      "grad_norm": 0.5377666354179382,
      "learning_rate": 1.725542749932994e-05,
      "loss": 0.227,
      "step": 2000
    },
    {
      "epoch": 1.453887884267631,
      "grad_norm": 0.6299400329589844,
      "learning_rate": 1.7175020101849368e-05,
      "loss": 0.2341,
      "step": 2010
    },
    {
      "epoch": 1.461121157323689,
      "grad_norm": 0.6594777703285217,
      "learning_rate": 1.7094612704368804e-05,
      "loss": 0.2408,
      "step": 2020
    },
    {
      "epoch": 1.4683544303797469,
      "grad_norm": 0.5933617949485779,
      "learning_rate": 1.7014205306888237e-05,
      "loss": 0.2275,
      "step": 2030
    },
    {
      "epoch": 1.4755877034358047,
      "grad_norm": 0.6947556734085083,
      "learning_rate": 1.6933797909407666e-05,
      "loss": 0.2155,
      "step": 2040
    },
    {
      "epoch": 1.4828209764918625,
      "grad_norm": 0.3781082034111023,
      "learning_rate": 1.68533905119271e-05,
      "loss": 0.209,
      "step": 2050
    },
    {
      "epoch": 1.4900542495479203,
      "grad_norm": 1.0734310150146484,
      "learning_rate": 1.677298311444653e-05,
      "loss": 0.2045,
      "step": 2060
    },
    {
      "epoch": 1.4972875226039783,
      "grad_norm": 0.7904857993125916,
      "learning_rate": 1.669257571696596e-05,
      "loss": 0.1952,
      "step": 2070
    },
    {
      "epoch": 1.5045207956600362,
      "grad_norm": 0.8129745125770569,
      "learning_rate": 1.6612168319485394e-05,
      "loss": 0.193,
      "step": 2080
    },
    {
      "epoch": 1.511754068716094,
      "grad_norm": 0.7823628783226013,
      "learning_rate": 1.6531760922004823e-05,
      "loss": 0.1918,
      "step": 2090
    },
    {
      "epoch": 1.518987341772152,
      "grad_norm": 0.692043125629425,
      "learning_rate": 1.6451353524524256e-05,
      "loss": 0.2439,
      "step": 2100
    },
    {
      "epoch": 1.5262206148282098,
      "grad_norm": 1.102134346961975,
      "learning_rate": 1.637094612704369e-05,
      "loss": 0.2311,
      "step": 2110
    },
    {
      "epoch": 1.5334538878842676,
      "grad_norm": 0.6619083881378174,
      "learning_rate": 1.629053872956312e-05,
      "loss": 0.2164,
      "step": 2120
    },
    {
      "epoch": 1.5406871609403257,
      "grad_norm": 0.8260590434074402,
      "learning_rate": 1.6210131332082554e-05,
      "loss": 0.2262,
      "step": 2130
    },
    {
      "epoch": 1.5479204339963832,
      "grad_norm": 0.42963355779647827,
      "learning_rate": 1.6129723934601983e-05,
      "loss": 0.2055,
      "step": 2140
    },
    {
      "epoch": 1.5551537070524413,
      "grad_norm": 0.6583328247070312,
      "learning_rate": 1.6049316537121416e-05,
      "loss": 0.1814,
      "step": 2150
    },
    {
      "epoch": 1.562386980108499,
      "grad_norm": 0.5746925473213196,
      "learning_rate": 1.5968909139640846e-05,
      "loss": 0.2233,
      "step": 2160
    },
    {
      "epoch": 1.5696202531645569,
      "grad_norm": 0.6776683330535889,
      "learning_rate": 1.5888501742160278e-05,
      "loss": 0.2001,
      "step": 2170
    },
    {
      "epoch": 1.576853526220615,
      "grad_norm": 0.5913844704627991,
      "learning_rate": 1.580809434467971e-05,
      "loss": 0.2254,
      "step": 2180
    },
    {
      "epoch": 1.5840867992766727,
      "grad_norm": 0.49204695224761963,
      "learning_rate": 1.572768694719914e-05,
      "loss": 0.218,
      "step": 2190
    },
    {
      "epoch": 1.5913200723327305,
      "grad_norm": 0.650877833366394,
      "learning_rate": 1.5647279549718577e-05,
      "loss": 0.206,
      "step": 2200
    },
    {
      "epoch": 1.5985533453887886,
      "grad_norm": 1.1676772832870483,
      "learning_rate": 1.5566872152238006e-05,
      "loss": 0.2047,
      "step": 2210
    },
    {
      "epoch": 1.6057866184448462,
      "grad_norm": 0.7656121253967285,
      "learning_rate": 1.548646475475744e-05,
      "loss": 0.2316,
      "step": 2220
    },
    {
      "epoch": 1.6130198915009042,
      "grad_norm": 0.7066184878349304,
      "learning_rate": 1.540605735727687e-05,
      "loss": 0.1812,
      "step": 2230
    },
    {
      "epoch": 1.620253164556962,
      "grad_norm": 0.7364271283149719,
      "learning_rate": 1.53256499597963e-05,
      "loss": 0.2165,
      "step": 2240
    },
    {
      "epoch": 1.6274864376130198,
      "grad_norm": 0.7777700424194336,
      "learning_rate": 1.5245242562315733e-05,
      "loss": 0.2499,
      "step": 2250
    },
    {
      "epoch": 1.6347197106690778,
      "grad_norm": 0.5315558910369873,
      "learning_rate": 1.5164835164835164e-05,
      "loss": 0.2257,
      "step": 2260
    },
    {
      "epoch": 1.6419529837251357,
      "grad_norm": 0.8329808712005615,
      "learning_rate": 1.5084427767354595e-05,
      "loss": 0.2424,
      "step": 2270
    },
    {
      "epoch": 1.6491862567811935,
      "grad_norm": 0.9404198527336121,
      "learning_rate": 1.5004020369874028e-05,
      "loss": 0.2455,
      "step": 2280
    },
    {
      "epoch": 1.6564195298372515,
      "grad_norm": 0.3848974406719208,
      "learning_rate": 1.4923612972393461e-05,
      "loss": 0.1638,
      "step": 2290
    },
    {
      "epoch": 1.663652802893309,
      "grad_norm": 0.671973705291748,
      "learning_rate": 1.4843205574912892e-05,
      "loss": 0.2164,
      "step": 2300
    },
    {
      "epoch": 1.6708860759493671,
      "grad_norm": 0.6131763458251953,
      "learning_rate": 1.4762798177432323e-05,
      "loss": 0.1745,
      "step": 2310
    },
    {
      "epoch": 1.678119349005425,
      "grad_norm": 0.6457998156547546,
      "learning_rate": 1.4682390779951756e-05,
      "loss": 0.2217,
      "step": 2320
    },
    {
      "epoch": 1.6853526220614827,
      "grad_norm": 0.6203235983848572,
      "learning_rate": 1.4601983382471189e-05,
      "loss": 0.2146,
      "step": 2330
    },
    {
      "epoch": 1.6925858951175408,
      "grad_norm": 0.6221689581871033,
      "learning_rate": 1.452157598499062e-05,
      "loss": 0.2186,
      "step": 2340
    },
    {
      "epoch": 1.6998191681735986,
      "grad_norm": 0.5299751162528992,
      "learning_rate": 1.444116858751005e-05,
      "loss": 0.2253,
      "step": 2350
    },
    {
      "epoch": 1.7070524412296564,
      "grad_norm": 0.6189897656440735,
      "learning_rate": 1.4360761190029483e-05,
      "loss": 0.2014,
      "step": 2360
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.5553787350654602,
      "learning_rate": 1.4280353792548916e-05,
      "loss": 0.2067,
      "step": 2370
    },
    {
      "epoch": 1.721518987341772,
      "grad_norm": 1.0125716924667358,
      "learning_rate": 1.4199946395068347e-05,
      "loss": 0.2275,
      "step": 2380
    },
    {
      "epoch": 1.72875226039783,
      "grad_norm": 0.47155097126960754,
      "learning_rate": 1.4119538997587778e-05,
      "loss": 0.2073,
      "step": 2390
    },
    {
      "epoch": 1.7359855334538878,
      "grad_norm": 0.7093312740325928,
      "learning_rate": 1.403913160010721e-05,
      "loss": 0.2142,
      "step": 2400
    },
    {
      "epoch": 1.7432188065099457,
      "grad_norm": 0.6406539678573608,
      "learning_rate": 1.3958724202626642e-05,
      "loss": 0.2445,
      "step": 2410
    },
    {
      "epoch": 1.7504520795660037,
      "grad_norm": 0.5810263752937317,
      "learning_rate": 1.3878316805146075e-05,
      "loss": 0.1895,
      "step": 2420
    },
    {
      "epoch": 1.7576853526220615,
      "grad_norm": 1.1126891374588013,
      "learning_rate": 1.3805950147413563e-05,
      "loss": 0.2152,
      "step": 2430
    },
    {
      "epoch": 1.7649186256781193,
      "grad_norm": 0.5188766121864319,
      "learning_rate": 1.3725542749932994e-05,
      "loss": 0.2042,
      "step": 2440
    },
    {
      "epoch": 1.7721518987341773,
      "grad_norm": 0.46668991446495056,
      "learning_rate": 1.3645135352452425e-05,
      "loss": 0.2069,
      "step": 2450
    },
    {
      "epoch": 1.779385171790235,
      "grad_norm": 0.5274156332015991,
      "learning_rate": 1.3564727954971858e-05,
      "loss": 0.2024,
      "step": 2460
    },
    {
      "epoch": 1.786618444846293,
      "grad_norm": 0.7169845700263977,
      "learning_rate": 1.348432055749129e-05,
      "loss": 0.2022,
      "step": 2470
    },
    {
      "epoch": 1.7938517179023508,
      "grad_norm": 0.5900048017501831,
      "learning_rate": 1.3403913160010722e-05,
      "loss": 0.2089,
      "step": 2480
    },
    {
      "epoch": 1.8010849909584086,
      "grad_norm": 1.1840208768844604,
      "learning_rate": 1.3323505762530153e-05,
      "loss": 0.2127,
      "step": 2490
    },
    {
      "epoch": 1.8083182640144666,
      "grad_norm": 0.868445634841919,
      "learning_rate": 1.3243098365049584e-05,
      "loss": 0.2177,
      "step": 2500
    },
    {
      "epoch": 1.8155515370705244,
      "grad_norm": 0.7440908551216125,
      "learning_rate": 1.3162690967569017e-05,
      "loss": 0.1969,
      "step": 2510
    },
    {
      "epoch": 1.8227848101265822,
      "grad_norm": 1.1993513107299805,
      "learning_rate": 1.308228357008845e-05,
      "loss": 0.2238,
      "step": 2520
    },
    {
      "epoch": 1.8300180831826403,
      "grad_norm": 0.6473672389984131,
      "learning_rate": 1.300187617260788e-05,
      "loss": 0.2099,
      "step": 2530
    },
    {
      "epoch": 1.837251356238698,
      "grad_norm": 0.8804253339767456,
      "learning_rate": 1.2921468775127311e-05,
      "loss": 0.2427,
      "step": 2540
    },
    {
      "epoch": 1.8444846292947559,
      "grad_norm": 0.5022869110107422,
      "learning_rate": 1.2841061377646744e-05,
      "loss": 0.2341,
      "step": 2550
    },
    {
      "epoch": 1.851717902350814,
      "grad_norm": 0.8125908374786377,
      "learning_rate": 1.2760653980166175e-05,
      "loss": 0.1982,
      "step": 2560
    },
    {
      "epoch": 1.8589511754068715,
      "grad_norm": 0.8206477761268616,
      "learning_rate": 1.2680246582685608e-05,
      "loss": 0.2092,
      "step": 2570
    },
    {
      "epoch": 1.8661844484629295,
      "grad_norm": 0.6544977426528931,
      "learning_rate": 1.2599839185205039e-05,
      "loss": 0.2238,
      "step": 2580
    },
    {
      "epoch": 1.8734177215189873,
      "grad_norm": 0.7087900042533875,
      "learning_rate": 1.251943178772447e-05,
      "loss": 0.1989,
      "step": 2590
    },
    {
      "epoch": 1.8806509945750451,
      "grad_norm": 0.5868884921073914,
      "learning_rate": 1.2439024390243903e-05,
      "loss": 0.2141,
      "step": 2600
    },
    {
      "epoch": 1.8878842676311032,
      "grad_norm": 0.5343722105026245,
      "learning_rate": 1.2358616992763335e-05,
      "loss": 0.1863,
      "step": 2610
    },
    {
      "epoch": 1.895117540687161,
      "grad_norm": 0.9700596928596497,
      "learning_rate": 1.2278209595282766e-05,
      "loss": 0.1875,
      "step": 2620
    },
    {
      "epoch": 1.9023508137432188,
      "grad_norm": 0.6876782774925232,
      "learning_rate": 1.2197802197802198e-05,
      "loss": 0.2173,
      "step": 2630
    },
    {
      "epoch": 1.9095840867992768,
      "grad_norm": 1.0082557201385498,
      "learning_rate": 1.211739480032163e-05,
      "loss": 0.2165,
      "step": 2640
    },
    {
      "epoch": 1.9168173598553344,
      "grad_norm": 0.5531176924705505,
      "learning_rate": 1.2036987402841061e-05,
      "loss": 0.2067,
      "step": 2650
    },
    {
      "epoch": 1.9240506329113924,
      "grad_norm": 0.42831552028656006,
      "learning_rate": 1.1956580005360494e-05,
      "loss": 0.2265,
      "step": 2660
    },
    {
      "epoch": 1.9312839059674503,
      "grad_norm": 0.6895039081573486,
      "learning_rate": 1.1876172607879925e-05,
      "loss": 0.2136,
      "step": 2670
    },
    {
      "epoch": 1.938517179023508,
      "grad_norm": 0.5749683976173401,
      "learning_rate": 1.1795765210399356e-05,
      "loss": 0.2255,
      "step": 2680
    },
    {
      "epoch": 1.945750452079566,
      "grad_norm": 0.658318281173706,
      "learning_rate": 1.1715357812918789e-05,
      "loss": 0.2102,
      "step": 2690
    },
    {
      "epoch": 1.952983725135624,
      "grad_norm": 1.0062503814697266,
      "learning_rate": 1.1634950415438222e-05,
      "loss": 0.2197,
      "step": 2700
    },
    {
      "epoch": 1.9602169981916817,
      "grad_norm": 0.6703113913536072,
      "learning_rate": 1.1554543017957653e-05,
      "loss": 0.2059,
      "step": 2710
    },
    {
      "epoch": 1.9674502712477397,
      "grad_norm": 0.7121468782424927,
      "learning_rate": 1.1474135620477084e-05,
      "loss": 0.2008,
      "step": 2720
    },
    {
      "epoch": 1.9746835443037973,
      "grad_norm": 0.4102732241153717,
      "learning_rate": 1.1393728222996516e-05,
      "loss": 0.2087,
      "step": 2730
    },
    {
      "epoch": 1.9819168173598554,
      "grad_norm": 0.6847118735313416,
      "learning_rate": 1.1313320825515947e-05,
      "loss": 0.2057,
      "step": 2740
    },
    {
      "epoch": 1.9891500904159132,
      "grad_norm": 0.7879467606544495,
      "learning_rate": 1.123291342803538e-05,
      "loss": 0.2275,
      "step": 2750
    },
    {
      "epoch": 1.996383363471971,
      "grad_norm": 0.5446122288703918,
      "learning_rate": 1.1152506030554811e-05,
      "loss": 0.2132,
      "step": 2760
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.2875588834285736,
      "eval_runtime": 43.1937,
      "eval_samples_per_second": 16.021,
      "eval_steps_per_second": 16.021,
      "step": 2765
    },
    {
      "epoch": 2.003616636528029,
      "grad_norm": 0.41456156969070435,
      "learning_rate": 1.1072098633074242e-05,
      "loss": 0.2313,
      "step": 2770
    },
    {
      "epoch": 2.0108499095840866,
      "grad_norm": 0.8533740639686584,
      "learning_rate": 1.0991691235593675e-05,
      "loss": 0.1781,
      "step": 2780
    },
    {
      "epoch": 2.0180831826401446,
      "grad_norm": 0.6096323132514954,
      "learning_rate": 1.0911283838113108e-05,
      "loss": 0.2434,
      "step": 2790
    },
    {
      "epoch": 2.0253164556962027,
      "grad_norm": 0.6006674766540527,
      "learning_rate": 1.0830876440632539e-05,
      "loss": 0.2209,
      "step": 2800
    },
    {
      "epoch": 2.0325497287522603,
      "grad_norm": 1.143643856048584,
      "learning_rate": 1.075046904315197e-05,
      "loss": 0.2181,
      "step": 2810
    },
    {
      "epoch": 2.0397830018083183,
      "grad_norm": 0.9158675074577332,
      "learning_rate": 1.0670061645671403e-05,
      "loss": 0.2177,
      "step": 2820
    },
    {
      "epoch": 2.0470162748643763,
      "grad_norm": 1.1325397491455078,
      "learning_rate": 1.0589654248190834e-05,
      "loss": 0.1907,
      "step": 2830
    },
    {
      "epoch": 2.054249547920434,
      "grad_norm": 0.9414148926734924,
      "learning_rate": 1.0509246850710266e-05,
      "loss": 0.2439,
      "step": 2840
    },
    {
      "epoch": 2.061482820976492,
      "grad_norm": 0.6453453302383423,
      "learning_rate": 1.0428839453229697e-05,
      "loss": 0.2,
      "step": 2850
    },
    {
      "epoch": 2.0687160940325495,
      "grad_norm": 0.5261044502258301,
      "learning_rate": 1.0348432055749128e-05,
      "loss": 0.1925,
      "step": 2860
    },
    {
      "epoch": 2.0759493670886076,
      "grad_norm": 0.5422815680503845,
      "learning_rate": 1.0268024658268561e-05,
      "loss": 0.2439,
      "step": 2870
    },
    {
      "epoch": 2.0831826401446656,
      "grad_norm": 0.8196687698364258,
      "learning_rate": 1.0187617260787992e-05,
      "loss": 0.1791,
      "step": 2880
    },
    {
      "epoch": 2.090415913200723,
      "grad_norm": 0.9637407660484314,
      "learning_rate": 1.0107209863307425e-05,
      "loss": 0.234,
      "step": 2890
    },
    {
      "epoch": 2.097649186256781,
      "grad_norm": 0.694344162940979,
      "learning_rate": 1.0026802465826856e-05,
      "loss": 0.1803,
      "step": 2900
    },
    {
      "epoch": 2.1048824593128392,
      "grad_norm": 0.6226950287818909,
      "learning_rate": 9.946395068346287e-06,
      "loss": 0.2044,
      "step": 2910
    },
    {
      "epoch": 2.112115732368897,
      "grad_norm": 1.2635469436645508,
      "learning_rate": 9.86598767086572e-06,
      "loss": 0.2095,
      "step": 2920
    },
    {
      "epoch": 2.119349005424955,
      "grad_norm": 1.2702770233154297,
      "learning_rate": 9.785580273385153e-06,
      "loss": 0.1946,
      "step": 2930
    },
    {
      "epoch": 2.1265822784810124,
      "grad_norm": 0.5204837918281555,
      "learning_rate": 9.705172875904584e-06,
      "loss": 0.2344,
      "step": 2940
    },
    {
      "epoch": 2.1338155515370705,
      "grad_norm": 0.655433177947998,
      "learning_rate": 9.624765478424015e-06,
      "loss": 0.194,
      "step": 2950
    },
    {
      "epoch": 2.1410488245931285,
      "grad_norm": 1.136339783668518,
      "learning_rate": 9.544358080943447e-06,
      "loss": 0.2058,
      "step": 2960
    },
    {
      "epoch": 2.148282097649186,
      "grad_norm": 0.6939035058021545,
      "learning_rate": 9.463950683462878e-06,
      "loss": 0.2112,
      "step": 2970
    },
    {
      "epoch": 2.155515370705244,
      "grad_norm": 0.6508753895759583,
      "learning_rate": 9.383543285982311e-06,
      "loss": 0.2221,
      "step": 2980
    },
    {
      "epoch": 2.162748643761302,
      "grad_norm": 0.6312040686607361,
      "learning_rate": 9.303135888501742e-06,
      "loss": 0.2519,
      "step": 2990
    },
    {
      "epoch": 2.1699819168173597,
      "grad_norm": 0.6897491216659546,
      "learning_rate": 9.222728491021173e-06,
      "loss": 0.1767,
      "step": 3000
    },
    {
      "epoch": 2.1772151898734178,
      "grad_norm": 0.5067952871322632,
      "learning_rate": 9.142321093540606e-06,
      "loss": 0.1993,
      "step": 3010
    },
    {
      "epoch": 2.184448462929476,
      "grad_norm": 0.5260151028633118,
      "learning_rate": 9.061913696060039e-06,
      "loss": 0.1877,
      "step": 3020
    },
    {
      "epoch": 2.1916817359855334,
      "grad_norm": 0.7996760606765747,
      "learning_rate": 8.98150629857947e-06,
      "loss": 0.218,
      "step": 3030
    },
    {
      "epoch": 2.1989150090415914,
      "grad_norm": 0.6920925974845886,
      "learning_rate": 8.9010989010989e-06,
      "loss": 0.2418,
      "step": 3040
    },
    {
      "epoch": 2.206148282097649,
      "grad_norm": 1.086443543434143,
      "learning_rate": 8.820691503618334e-06,
      "loss": 0.206,
      "step": 3050
    },
    {
      "epoch": 2.213381555153707,
      "grad_norm": 0.5297410488128662,
      "learning_rate": 8.740284106137765e-06,
      "loss": 0.2072,
      "step": 3060
    },
    {
      "epoch": 2.220614828209765,
      "grad_norm": 0.601921796798706,
      "learning_rate": 8.659876708657197e-06,
      "loss": 0.201,
      "step": 3070
    },
    {
      "epoch": 2.2278481012658227,
      "grad_norm": 0.5661662817001343,
      "learning_rate": 8.579469311176628e-06,
      "loss": 0.2258,
      "step": 3080
    },
    {
      "epoch": 2.2350813743218807,
      "grad_norm": 1.0656309127807617,
      "learning_rate": 8.49906191369606e-06,
      "loss": 0.1894,
      "step": 3090
    },
    {
      "epoch": 2.2423146473779383,
      "grad_norm": 0.5459045767784119,
      "learning_rate": 8.418654516215492e-06,
      "loss": 0.1878,
      "step": 3100
    },
    {
      "epoch": 2.2495479204339963,
      "grad_norm": 1.8917739391326904,
      "learning_rate": 8.338247118734925e-06,
      "loss": 0.2098,
      "step": 3110
    },
    {
      "epoch": 2.2567811934900543,
      "grad_norm": 0.5604758858680725,
      "learning_rate": 8.257839721254356e-06,
      "loss": 0.1885,
      "step": 3120
    },
    {
      "epoch": 2.264014466546112,
      "grad_norm": 0.712390124797821,
      "learning_rate": 8.177432323773787e-06,
      "loss": 0.2003,
      "step": 3130
    },
    {
      "epoch": 2.27124773960217,
      "grad_norm": 1.886788249015808,
      "learning_rate": 8.09702492629322e-06,
      "loss": 0.1996,
      "step": 3140
    },
    {
      "epoch": 2.278481012658228,
      "grad_norm": 0.769695520401001,
      "learning_rate": 8.01661752881265e-06,
      "loss": 0.2043,
      "step": 3150
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.8387424945831299,
      "learning_rate": 7.936210131332083e-06,
      "loss": 0.2259,
      "step": 3160
    },
    {
      "epoch": 2.2929475587703436,
      "grad_norm": 0.5599609017372131,
      "learning_rate": 7.855802733851514e-06,
      "loss": 0.2072,
      "step": 3170
    },
    {
      "epoch": 2.3001808318264017,
      "grad_norm": 0.5156430006027222,
      "learning_rate": 7.775395336370946e-06,
      "loss": 0.2217,
      "step": 3180
    },
    {
      "epoch": 2.3074141048824592,
      "grad_norm": 0.6124317049980164,
      "learning_rate": 7.694987938890378e-06,
      "loss": 0.2079,
      "step": 3190
    },
    {
      "epoch": 2.3146473779385173,
      "grad_norm": 0.6585136651992798,
      "learning_rate": 7.614580541409809e-06,
      "loss": 0.2014,
      "step": 3200
    },
    {
      "epoch": 2.321880650994575,
      "grad_norm": 0.5951544642448425,
      "learning_rate": 7.534173143929242e-06,
      "loss": 0.207,
      "step": 3210
    },
    {
      "epoch": 2.329113924050633,
      "grad_norm": 0.5547893047332764,
      "learning_rate": 7.453765746448674e-06,
      "loss": 0.2569,
      "step": 3220
    },
    {
      "epoch": 2.336347197106691,
      "grad_norm": 0.6696731448173523,
      "learning_rate": 7.373358348968105e-06,
      "loss": 0.2092,
      "step": 3230
    },
    {
      "epoch": 2.3435804701627485,
      "grad_norm": 0.5513889193534851,
      "learning_rate": 7.292950951487537e-06,
      "loss": 0.1866,
      "step": 3240
    },
    {
      "epoch": 2.3508137432188065,
      "grad_norm": 0.7411826848983765,
      "learning_rate": 7.212543554006969e-06,
      "loss": 0.2091,
      "step": 3250
    },
    {
      "epoch": 2.358047016274864,
      "grad_norm": 1.0144495964050293,
      "learning_rate": 7.132136156526401e-06,
      "loss": 0.2085,
      "step": 3260
    },
    {
      "epoch": 2.365280289330922,
      "grad_norm": 0.6435429453849792,
      "learning_rate": 7.0517287590458325e-06,
      "loss": 0.2184,
      "step": 3270
    },
    {
      "epoch": 2.37251356238698,
      "grad_norm": 0.810886561870575,
      "learning_rate": 6.9713213615652636e-06,
      "loss": 0.2084,
      "step": 3280
    },
    {
      "epoch": 2.379746835443038,
      "grad_norm": 0.8700979351997375,
      "learning_rate": 6.890913964084696e-06,
      "loss": 0.2083,
      "step": 3290
    },
    {
      "epoch": 2.386980108499096,
      "grad_norm": 0.7347666621208191,
      "learning_rate": 6.810506566604127e-06,
      "loss": 0.2025,
      "step": 3300
    },
    {
      "epoch": 2.394213381555154,
      "grad_norm": 0.6721441745758057,
      "learning_rate": 6.73009916912356e-06,
      "loss": 0.2228,
      "step": 3310
    },
    {
      "epoch": 2.4014466546112114,
      "grad_norm": 0.6708276271820068,
      "learning_rate": 6.649691771642991e-06,
      "loss": 0.2191,
      "step": 3320
    },
    {
      "epoch": 2.4086799276672695,
      "grad_norm": 0.7255995869636536,
      "learning_rate": 6.569284374162423e-06,
      "loss": 0.2018,
      "step": 3330
    },
    {
      "epoch": 2.4159132007233275,
      "grad_norm": 0.7959306240081787,
      "learning_rate": 6.488876976681855e-06,
      "loss": 0.2165,
      "step": 3340
    },
    {
      "epoch": 2.423146473779385,
      "grad_norm": 0.7170647382736206,
      "learning_rate": 6.408469579201287e-06,
      "loss": 0.2176,
      "step": 3350
    },
    {
      "epoch": 2.430379746835443,
      "grad_norm": 0.7032385468482971,
      "learning_rate": 6.328062181720719e-06,
      "loss": 0.2166,
      "step": 3360
    },
    {
      "epoch": 2.4376130198915007,
      "grad_norm": 0.7414628267288208,
      "learning_rate": 6.24765478424015e-06,
      "loss": 0.2208,
      "step": 3370
    },
    {
      "epoch": 2.4448462929475587,
      "grad_norm": 0.9934431910514832,
      "learning_rate": 6.1672473867595825e-06,
      "loss": 0.2059,
      "step": 3380
    },
    {
      "epoch": 2.4520795660036168,
      "grad_norm": 0.726098358631134,
      "learning_rate": 6.0868399892790135e-06,
      "loss": 0.2086,
      "step": 3390
    },
    {
      "epoch": 2.4593128390596743,
      "grad_norm": 0.8607387542724609,
      "learning_rate": 6.006432591798446e-06,
      "loss": 0.1871,
      "step": 3400
    },
    {
      "epoch": 2.4665461121157324,
      "grad_norm": 0.8447831273078918,
      "learning_rate": 5.926025194317877e-06,
      "loss": 0.1847,
      "step": 3410
    },
    {
      "epoch": 2.4737793851717904,
      "grad_norm": 0.7192726135253906,
      "learning_rate": 5.845617796837309e-06,
      "loss": 0.2214,
      "step": 3420
    },
    {
      "epoch": 2.481012658227848,
      "grad_norm": 1.041182041168213,
      "learning_rate": 5.765210399356741e-06,
      "loss": 0.2278,
      "step": 3430
    },
    {
      "epoch": 2.488245931283906,
      "grad_norm": 0.6848338842391968,
      "learning_rate": 5.684803001876172e-06,
      "loss": 0.2188,
      "step": 3440
    },
    {
      "epoch": 2.495479204339964,
      "grad_norm": 0.48794710636138916,
      "learning_rate": 5.604395604395605e-06,
      "loss": 0.2084,
      "step": 3450
    },
    {
      "epoch": 2.5027124773960217,
      "grad_norm": 0.5513005256652832,
      "learning_rate": 5.523988206915036e-06,
      "loss": 0.2101,
      "step": 3460
    },
    {
      "epoch": 2.5099457504520797,
      "grad_norm": 0.6721189022064209,
      "learning_rate": 5.443580809434469e-06,
      "loss": 0.2048,
      "step": 3470
    },
    {
      "epoch": 2.5171790235081373,
      "grad_norm": 0.8909885287284851,
      "learning_rate": 5.3631734119539e-06,
      "loss": 0.203,
      "step": 3480
    },
    {
      "epoch": 2.5244122965641953,
      "grad_norm": 0.7449674010276794,
      "learning_rate": 5.2827660144733316e-06,
      "loss": 0.2306,
      "step": 3490
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.8554326891899109,
      "learning_rate": 5.2023586169927634e-06,
      "loss": 0.184,
      "step": 3500
    },
    {
      "epoch": 2.538878842676311,
      "grad_norm": 0.7254182696342468,
      "learning_rate": 5.121951219512195e-06,
      "loss": 0.2003,
      "step": 3510
    },
    {
      "epoch": 2.546112115732369,
      "grad_norm": 0.5607113838195801,
      "learning_rate": 5.041543822031627e-06,
      "loss": 0.2207,
      "step": 3520
    },
    {
      "epoch": 2.5533453887884265,
      "grad_norm": 0.7939742803573608,
      "learning_rate": 4.961136424551058e-06,
      "loss": 0.2052,
      "step": 3530
    },
    {
      "epoch": 2.5605786618444846,
      "grad_norm": 0.5026660561561584,
      "learning_rate": 4.880729027070491e-06,
      "loss": 0.1964,
      "step": 3540
    },
    {
      "epoch": 2.5678119349005426,
      "grad_norm": 0.774735152721405,
      "learning_rate": 4.800321629589922e-06,
      "loss": 0.1926,
      "step": 3550
    },
    {
      "epoch": 2.5750452079566006,
      "grad_norm": 0.7572070956230164,
      "learning_rate": 4.719914232109355e-06,
      "loss": 0.1686,
      "step": 3560
    },
    {
      "epoch": 2.5822784810126582,
      "grad_norm": 0.7943280339241028,
      "learning_rate": 4.639506834628786e-06,
      "loss": 0.217,
      "step": 3570
    },
    {
      "epoch": 2.5895117540687163,
      "grad_norm": 0.655066967010498,
      "learning_rate": 4.559099437148218e-06,
      "loss": 0.2347,
      "step": 3580
    },
    {
      "epoch": 2.596745027124774,
      "grad_norm": 0.9395173192024231,
      "learning_rate": 4.47869203966765e-06,
      "loss": 0.2273,
      "step": 3590
    },
    {
      "epoch": 2.603978300180832,
      "grad_norm": 0.5453190207481384,
      "learning_rate": 4.398284642187081e-06,
      "loss": 0.2218,
      "step": 3600
    },
    {
      "epoch": 2.61121157323689,
      "grad_norm": 0.8521984219551086,
      "learning_rate": 4.317877244706513e-06,
      "loss": 0.1853,
      "step": 3610
    },
    {
      "epoch": 2.6184448462929475,
      "grad_norm": 1.2338591814041138,
      "learning_rate": 4.2374698472259444e-06,
      "loss": 0.1877,
      "step": 3620
    },
    {
      "epoch": 2.6256781193490055,
      "grad_norm": 0.728900134563446,
      "learning_rate": 4.157062449745377e-06,
      "loss": 0.2167,
      "step": 3630
    },
    {
      "epoch": 2.632911392405063,
      "grad_norm": 0.558788001537323,
      "learning_rate": 4.076655052264808e-06,
      "loss": 0.183,
      "step": 3640
    },
    {
      "epoch": 2.640144665461121,
      "grad_norm": 0.5743106603622437,
      "learning_rate": 3.996247654784241e-06,
      "loss": 0.1824,
      "step": 3650
    },
    {
      "epoch": 2.647377938517179,
      "grad_norm": 0.8504476547241211,
      "learning_rate": 3.915840257303672e-06,
      "loss": 0.1943,
      "step": 3660
    },
    {
      "epoch": 2.6546112115732368,
      "grad_norm": 0.6001649498939514,
      "learning_rate": 3.835432859823104e-06,
      "loss": 0.1808,
      "step": 3670
    },
    {
      "epoch": 2.661844484629295,
      "grad_norm": 0.5434528589248657,
      "learning_rate": 3.7550254623425358e-06,
      "loss": 0.2125,
      "step": 3680
    },
    {
      "epoch": 2.6690777576853524,
      "grad_norm": 0.744484007358551,
      "learning_rate": 3.6746180648619677e-06,
      "loss": 0.2098,
      "step": 3690
    },
    {
      "epoch": 2.6763110307414104,
      "grad_norm": 0.8289836645126343,
      "learning_rate": 3.594210667381399e-06,
      "loss": 0.2418,
      "step": 3700
    },
    {
      "epoch": 2.6835443037974684,
      "grad_norm": 0.9262431263923645,
      "learning_rate": 3.513803269900831e-06,
      "loss": 0.2094,
      "step": 3710
    },
    {
      "epoch": 2.6907775768535265,
      "grad_norm": 0.5349678993225098,
      "learning_rate": 3.4333958724202625e-06,
      "loss": 0.1733,
      "step": 3720
    },
    {
      "epoch": 2.698010849909584,
      "grad_norm": 0.5734317898750305,
      "learning_rate": 3.3529884749396944e-06,
      "loss": 0.2057,
      "step": 3730
    },
    {
      "epoch": 2.705244122965642,
      "grad_norm": 1.104568600654602,
      "learning_rate": 3.2725810774591263e-06,
      "loss": 0.1939,
      "step": 3740
    },
    {
      "epoch": 2.7124773960216997,
      "grad_norm": 0.6721089482307434,
      "learning_rate": 3.192173679978558e-06,
      "loss": 0.2279,
      "step": 3750
    },
    {
      "epoch": 2.7197106690777577,
      "grad_norm": 0.9839029312133789,
      "learning_rate": 3.11176628249799e-06,
      "loss": 0.2085,
      "step": 3760
    },
    {
      "epoch": 2.7269439421338157,
      "grad_norm": 0.7907362580299377,
      "learning_rate": 3.031358885017422e-06,
      "loss": 0.2067,
      "step": 3770
    },
    {
      "epoch": 2.7341772151898733,
      "grad_norm": 0.7511817216873169,
      "learning_rate": 2.9509514875368534e-06,
      "loss": 0.2296,
      "step": 3780
    },
    {
      "epoch": 2.7414104882459314,
      "grad_norm": 0.9789502024650574,
      "learning_rate": 2.8705440900562853e-06,
      "loss": 0.1981,
      "step": 3790
    },
    {
      "epoch": 2.748643761301989,
      "grad_norm": 0.5369149446487427,
      "learning_rate": 2.7901366925757167e-06,
      "loss": 0.192,
      "step": 3800
    },
    {
      "epoch": 2.755877034358047,
      "grad_norm": 0.5291523933410645,
      "learning_rate": 2.7097292950951486e-06,
      "loss": 0.2113,
      "step": 3810
    },
    {
      "epoch": 2.763110307414105,
      "grad_norm": 1.0518848896026611,
      "learning_rate": 2.6293218976145805e-06,
      "loss": 0.2144,
      "step": 3820
    },
    {
      "epoch": 2.7703435804701626,
      "grad_norm": 0.6513825058937073,
      "learning_rate": 2.5489145001340124e-06,
      "loss": 0.1889,
      "step": 3830
    },
    {
      "epoch": 2.7775768535262206,
      "grad_norm": 0.6022379398345947,
      "learning_rate": 2.4685071026534443e-06,
      "loss": 0.1744,
      "step": 3840
    },
    {
      "epoch": 2.7848101265822782,
      "grad_norm": 0.9313238859176636,
      "learning_rate": 2.388099705172876e-06,
      "loss": 0.1926,
      "step": 3850
    },
    {
      "epoch": 2.7920433996383363,
      "grad_norm": 0.86932373046875,
      "learning_rate": 2.307692307692308e-06,
      "loss": 0.2164,
      "step": 3860
    },
    {
      "epoch": 2.7992766726943943,
      "grad_norm": 0.548047661781311,
      "learning_rate": 2.2272849102117395e-06,
      "loss": 0.2209,
      "step": 3870
    },
    {
      "epoch": 2.8065099457504523,
      "grad_norm": 0.7558495402336121,
      "learning_rate": 2.146877512731171e-06,
      "loss": 0.225,
      "step": 3880
    },
    {
      "epoch": 2.81374321880651,
      "grad_norm": 0.567314088344574,
      "learning_rate": 2.066470115250603e-06,
      "loss": 0.1808,
      "step": 3890
    },
    {
      "epoch": 2.820976491862568,
      "grad_norm": 0.6968351006507874,
      "learning_rate": 1.9860627177700348e-06,
      "loss": 0.1948,
      "step": 3900
    },
    {
      "epoch": 2.8282097649186255,
      "grad_norm": 0.532325804233551,
      "learning_rate": 1.9056553202894667e-06,
      "loss": 0.2173,
      "step": 3910
    },
    {
      "epoch": 2.8354430379746836,
      "grad_norm": 1.3151894807815552,
      "learning_rate": 1.8252479228088986e-06,
      "loss": 0.2407,
      "step": 3920
    },
    {
      "epoch": 2.8426763110307416,
      "grad_norm": 0.7790266275405884,
      "learning_rate": 1.7448405253283302e-06,
      "loss": 0.1964,
      "step": 3930
    },
    {
      "epoch": 2.849909584086799,
      "grad_norm": 0.7862390875816345,
      "learning_rate": 1.664433127847762e-06,
      "loss": 0.2164,
      "step": 3940
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.5612766742706299,
      "learning_rate": 1.5840257303671938e-06,
      "loss": 0.223,
      "step": 3950
    },
    {
      "epoch": 2.864376130198915,
      "grad_norm": 1.0828824043273926,
      "learning_rate": 1.5036183328866257e-06,
      "loss": 0.1883,
      "step": 3960
    },
    {
      "epoch": 2.871609403254973,
      "grad_norm": 0.9071750640869141,
      "learning_rate": 1.4232109354060574e-06,
      "loss": 0.1763,
      "step": 3970
    },
    {
      "epoch": 2.878842676311031,
      "grad_norm": 0.49250566959381104,
      "learning_rate": 1.342803537925489e-06,
      "loss": 0.2277,
      "step": 3980
    },
    {
      "epoch": 2.8860759493670884,
      "grad_norm": 0.9055948853492737,
      "learning_rate": 1.262396140444921e-06,
      "loss": 0.1845,
      "step": 3990
    },
    {
      "epoch": 2.8933092224231465,
      "grad_norm": 0.9150171279907227,
      "learning_rate": 1.1819887429643528e-06,
      "loss": 0.2117,
      "step": 4000
    },
    {
      "epoch": 2.900542495479204,
      "grad_norm": 0.629779577255249,
      "learning_rate": 1.1015813454837845e-06,
      "loss": 0.2263,
      "step": 4010
    },
    {
      "epoch": 2.907775768535262,
      "grad_norm": 0.5925788879394531,
      "learning_rate": 1.0211739480032162e-06,
      "loss": 0.1944,
      "step": 4020
    },
    {
      "epoch": 2.91500904159132,
      "grad_norm": 1.2123960256576538,
      "learning_rate": 9.407665505226481e-07,
      "loss": 0.2342,
      "step": 4030
    },
    {
      "epoch": 2.922242314647378,
      "grad_norm": 0.9958241581916809,
      "learning_rate": 8.6035915304208e-07,
      "loss": 0.206,
      "step": 4040
    },
    {
      "epoch": 2.9294755877034357,
      "grad_norm": 0.7895766496658325,
      "learning_rate": 7.799517555615116e-07,
      "loss": 0.2069,
      "step": 4050
    },
    {
      "epoch": 2.9367088607594938,
      "grad_norm": 0.5738506317138672,
      "learning_rate": 6.995443580809435e-07,
      "loss": 0.2118,
      "step": 4060
    },
    {
      "epoch": 2.9439421338155514,
      "grad_norm": 0.7958621978759766,
      "learning_rate": 6.191369606003752e-07,
      "loss": 0.2061,
      "step": 4070
    },
    {
      "epoch": 2.9511754068716094,
      "grad_norm": 0.9634217619895935,
      "learning_rate": 5.387295631198071e-07,
      "loss": 0.208,
      "step": 4080
    },
    {
      "epoch": 2.9584086799276674,
      "grad_norm": 0.592940628528595,
      "learning_rate": 4.5832216563923883e-07,
      "loss": 0.204,
      "step": 4090
    },
    {
      "epoch": 2.965641952983725,
      "grad_norm": 1.5532218217849731,
      "learning_rate": 3.779147681586706e-07,
      "loss": 0.2219,
      "step": 4100
    },
    {
      "epoch": 2.972875226039783,
      "grad_norm": 0.7349840998649597,
      "learning_rate": 2.975073706781024e-07,
      "loss": 0.197,
      "step": 4110
    },
    {
      "epoch": 2.9801084990958406,
      "grad_norm": 0.9676184058189392,
      "learning_rate": 2.1709997319753418e-07,
      "loss": 0.2246,
      "step": 4120
    },
    {
      "epoch": 2.9873417721518987,
      "grad_norm": 0.8768346905708313,
      "learning_rate": 1.3669257571696597e-07,
      "loss": 0.191,
      "step": 4130
    },
    {
      "epoch": 2.9945750452079567,
      "grad_norm": 0.9638978242874146,
      "learning_rate": 5.628517823639775e-08,
      "loss": 0.223,
      "step": 4140
    },
    {
      "epoch": 2.9989150090415913,
      "eval_loss": 0.28545141220092773,
      "eval_runtime": 43.1438,
      "eval_samples_per_second": 16.039,
      "eval_steps_per_second": 16.039,
      "step": 4146
    }
  ],
  "logging_steps": 10,
  "max_steps": 4146,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.072883046088704e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
