{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/hadoop-aipnlp/dolphinfs_hdd_hadoop-aipnlp/liujincheng06/utils/debugbench')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"leetcode_task.json\",\"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3014',\n",
       " '3015',\n",
       " '3016',\n",
       " '3017',\n",
       " '3019',\n",
       " '3020',\n",
       " '3021',\n",
       " '3022',\n",
       " '3028',\n",
       " '3029',\n",
       " '3030',\n",
       " '3031',\n",
       " '3033',\n",
       " '3034',\n",
       " '3035',\n",
       " '3036',\n",
       " '3042',\n",
       " '3043',\n",
       " '3044',\n",
       " '3045',\n",
       " '3046',\n",
       " '3047',\n",
       " '3048',\n",
       " '3049',\n",
       " '3069',\n",
       " '3070',\n",
       " '3071',\n",
       " '3072',\n",
       " '3074',\n",
       " '3075',\n",
       " '3076',\n",
       " '3077',\n",
       " '3083',\n",
       " '3084',\n",
       " '3085',\n",
       " '3086',\n",
       " '3090',\n",
       " '3091',\n",
       " '3092',\n",
       " '3093',\n",
       " '3099',\n",
       " '3100',\n",
       " '3101',\n",
       " '3102',\n",
       " '3105',\n",
       " '3106',\n",
       " '3107',\n",
       " '3108',\n",
       " '3114',\n",
       " '3115',\n",
       " '3116',\n",
       " '3117',\n",
       " '3120',\n",
       " '3121',\n",
       " '3122',\n",
       " '3123',\n",
       " '3131',\n",
       " '3132',\n",
       " '3133',\n",
       " '3134',\n",
       " '3136',\n",
       " '3137',\n",
       " '3138',\n",
       " '3139',\n",
       " '3146',\n",
       " '3147',\n",
       " '3148',\n",
       " '3149',\n",
       " '3151',\n",
       " '3152',\n",
       " '3153',\n",
       " '3154',\n",
       " '3162',\n",
       " '3163',\n",
       " '3164',\n",
       " '3165',\n",
       " '3168',\n",
       " '3169',\n",
       " '3170',\n",
       " '3171',\n",
       " '3178',\n",
       " '3179',\n",
       " '3180',\n",
       " '3181',\n",
       " '3184',\n",
       " '3185',\n",
       " '3186',\n",
       " '3187',\n",
       " '3194',\n",
       " '3195',\n",
       " '3196',\n",
       " '3197',\n",
       " '3200',\n",
       " '3201',\n",
       " '3202',\n",
       " '3203',\n",
       " '3210',\n",
       " '3211',\n",
       " '3212',\n",
       " '3213',\n",
       " '3216',\n",
       " '3217',\n",
       " '3218',\n",
       " '3219',\n",
       " '3024',\n",
       " '3025',\n",
       " '3026',\n",
       " '3027',\n",
       " '3038',\n",
       " '3039',\n",
       " '3040',\n",
       " '3041',\n",
       " '3065',\n",
       " '3066',\n",
       " '3067',\n",
       " '3068',\n",
       " '3079',\n",
       " '3080',\n",
       " '3081',\n",
       " '3082',\n",
       " '3095',\n",
       " '3096',\n",
       " '3097',\n",
       " '3098',\n",
       " '3110',\n",
       " '3111',\n",
       " '3112',\n",
       " '3113',\n",
       " '3127',\n",
       " '3128',\n",
       " '3129',\n",
       " '3130',\n",
       " '3142',\n",
       " '3143',\n",
       " '3144',\n",
       " '3145',\n",
       " '3158',\n",
       " '3159',\n",
       " '3160',\n",
       " '3161',\n",
       " '3174',\n",
       " '3175',\n",
       " '3176',\n",
       " '3177',\n",
       " '3190',\n",
       " '3191',\n",
       " '3192',\n",
       " '3193',\n",
       " '3206',\n",
       " '3207',\n",
       " '3208',\n",
       " '3209']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(data.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Solution {\\n    public int minimumPushes(String word) {\\n        int n = word.length();\\n        int k = n / 8;\\n        return (k * 4 + n % 8) * (k + 1);\\n    }\\n}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['3014']['codes']['java']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'public class Main {\\n    public static void main(String[] args) {\\n        Solution solution = new Solution();\\n    String word_1 = \"abcde\";\\n    int ans_1 = 5;\\n    assert solution.minimumPushes(word_1) == ans_1);\\n    String word_2 = \"xycdefghij\";\\n    int ans_2 = 12;\\n    assert solution.minimumPushes(word_2) == ans_2);\\n    }\\n}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['3014']['references']['java']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'java'\n",
    "preds = []\n",
    "refs = []\n",
    "for i,v in enumerate(keys):\n",
    "    code_str = data[v]['codes'][lang]\n",
    "    test = data[v]['references'][lang]\n",
    "    preds.append([code_str])\n",
    "    refs.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 14:26:15.338772: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 14:26:15.640970: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-17 14:26:16.660662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/lib64:/usr/lib64\n",
      "2024-07-17 14:26:16.662589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/lib64:/usr/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/java/jre/lib/amd64/server:/opt/meituan/hadoop/lib/native:/lib64:/usr/lib64\n",
      "2024-07-17 14:26:16.662608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from datasets import load_from_disk\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "os.environ['HF_ALLOW_CODE_EVAL']= '1'\n",
    "os.environ['LD_LIBRARY_PATH'] = '$LD_LIBRARY_PATH:/usr/local/lib64'\n",
    "\n",
    "code_metric = load(\"./bigcode-evaluation-harness/bigcode_eval/tasks/custom_metrics/code_eval_octopack\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, cases = code_metric.compute(\n",
    "        references=refs,\n",
    "        predictions=preds,\n",
    "        language='java',\n",
    "        timeout=10.0,\n",
    "        num_workers=8,\n",
    "        )\n",
    "print(metrics,cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liujincheng06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
